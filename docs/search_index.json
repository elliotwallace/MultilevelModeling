[["index.html", "ReCentering Psych Stats: Multilevel/Hierarchical Linear Modeling BOOK COVER", " ReCentering Psych Stats: Multilevel/Hierarchical Linear Modeling Lynette H Bikos, PhD, ABPP BOOK COVER An image of the book cover. It includes four quadrants of non-normal distributions representing gender, race/ethnicty, sustainability/global concerns, and journal articles "],["preface.html", "PREFACE Copyright with Open Access", " PREFACE If you are viewing this document, you should know that this is a book-in-progress. Early drafts are released for the purpose teaching my classes and gaining formative feedback from a host of stakeholders. The document was last updated on 17 May 2021 Screencasted Lecture Link To center a variable in regression means to set its value at zero and interpret all other values in relation to this reference point. Regarding race and gender, researchers often center male and White at zero. Further, it is typical that research vignettes in statistics textbooks are similarly seated in a White, Western (frequently U.S.), heteronormative, framework. The purpose of this project is to create a set of open educational resources (OER) appropriate for doctoral and post-doctoral training that contribute to a socially responsive pedagogy  that is, it contributes to justice, equity, diversity, and inclusion. Statistics training in doctoral programs are frequently taught with fee-for-use programs (e.g., SPSS/AMOS, SAS, MPlus) that may not be readily available to the post-doctoral professional. In recent years, there has been an increase and improvement in R packages (e.g., psych, lavaan) used for in analyses common to psychological research. Correspondingly, many graduate programs are transitioning to statistics training in R (free and open source). This is a challenge for post-doctoral psychologists who were trained with other software. This OER will offer statistics training with R and be freely available (specifically in a GitHub respository and posted through GitHub Pages) under a Creative Commons Attribution - Non Commercial - Share Alike license [CC BY-NC-SA 4.0]. Training models for doctoral programs in HSP are commonly scholar-practitioner, scientist-practitioner, or clinical-scientist. An emerging model, the scientist-practitioner-advocacy training model incorporates social justice advocacy so that graduates are equipped to recognize and address the sociocultural context of oppression and unjust distribution of resources and opportunities (Mallinckrodt et al., 2014). In statistics textbooks, the use of research vignettes engages the learner around a tangible scenario for identifying independent variables, dependent variables, covariates, and potential mechanisms of change. Many students recall examples in Fields (2012) popular statistics text: Viagra to teach one-way ANOVA, beer goggles for two-way ANOVA, and bushtucker for repeated measures. What if the research vignettes were more socially responsive? In this OER, research vignettes will be from recently published articles where: the authors identity is from a group where scholarship is historically marginalized (e.g., BIPOC, LGBTQ+, LMIC[low-middle income countries]), the research is responsive to issues of justice, equity, inclusion, diversity, the lessons statistic is used in the article, and there is sufficient information in the article to simulate the data for the chapter example(s) and practice problem(s); or it is publicly available. In training for multicultural competence, the saying, A fish doesnt know that its wet is often used to convey the notion that we are often unaware of our own cultural characteristics. In recent months and years, there has been an increased awakening to the institutional and systemic racism that our systems are perpetuating. Queuing from the water metaphor, I am hopeful that a text that is recentered in the ways I have described can contribute to changing the water in higher education and in the profession of psychology. Copyright with Open Access This book is published under a a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. This means that this book can be reused, remixed, retained, revised and redistributed (including commercially) as long as appropriate credit is given to the authors. If you remix, or modify the original version of this open textbook, you must redistribute all versions of this open textbook under the same license - CC BY-SA. A GitHub open-source repository contains all of the text and source code for the book, including data and images. References "],["acknowledgements.html", "ACKNOWLEDGEMENTS", " ACKNOWLEDGEMENTS As a doctoral student at the University of Kansas (1992-2005), I learned that a foreign language was required for graduation. Please note that as one who studies the intersections of global, vocational, and sustainable psychology, I regret that I do not have language skills beyond English. This could have been met with credit from high school my rural, mid-Missouri high school did not offer such classes. This requirement would have typically been met with courses taken during an undergraduate program  but my non-teaching degree in the University of Missouris School of Education was exempt from this. The requirement could have also been met with a computer language (fortran, C++)  I did not have any of those either. There was a tiny footnote on my doctoral degree plan that indicated that a 2-credit course, SPSS for Windows would substitute for the language requirement. Given that it was taught by my one of my favorite professors, I readily signed up. As it turns out, Samuel B. Green, PhD, was using the course to draft chapters in the textbook (Green &amp; Salkind, 2014) that has been so helpful for so many. Unfortunately, Drs. Green (1947 - 2018) and Salkind (2947 - 2017) are no longer with us. I have worn out numerous versions of their text. Another favorite text of mine was Dr. Barbara Byrnes (2016), Structural Equation Modeling with AMOS. I loved the way she worked through each problem and paired it with a published journal article, so that the user could see how the statistical evaluation fit within the larger project/article. I took my tea-stained text with me to a workshop she taught at APA and was proud of the signature she added to it (a little catfur might have fallen out). Dr. Byrne created SEM texts for a number of statistical programs (e.g., LISREL, EQS, MPlus). As I was learning R, I wrote Dr. Byrne, asking if she had an edition teaching SEM/CFA with R. She promptly wrote back, saying that she did not have the bandwidth to learn a new statistics package. We lost Dr. Byrne in December 2020. I am so grateful to these role models for their contributions to my statistical training. I am also grateful for the doctoral students who have taken my courses and are continuing to provide input for how to improve the materials. The inspiration for training materials that re*center statistics and research methods came from the Academics for Black Survival and Wellness Initiative. This project, co-founded by Della V. Mosley, Ph.D., and Pearis L. Bellamy, M.S., made clear the necessity and urgency for change in higher education and the profession of psychology. At very practical levels, I am indebted to SPUs Library, and more specifically, SPUs Education, Technology, and Media Department. Assistant Dean for Instructional Design and Emerging Technologies, R. John Robertson, MSc, MCS, has offered unlimited consultation, support, and connection. Senior Instructional Designer in Graphics &amp; Illustrations, Dominic Wilkinson, designed the logo and bookcover. Psychology and Scholarly Communications Librarian, Kristin Hoffman, MLIS, has provided consultation on topics ranging from OERS to citations. I am alo indebted to Associate Vice President, Teaching and Learning at Kwantlen Polytechnic University, Rajiv Jhangiani, PhD. Dr. Jhangianis text (2019) was the first OER I ever used and I was grateful for his encouraging conversation. Financial support for this text has been provided from the Call to Action on Equity, Inclusion, Diversity, Justice, and Social Responsivity Request for Proposals grant from the Association of Psychology Postdoctoral and Internship Centers (2021-2022). References "],["ReCintro.html", "Chapter 1 Introduction 1.1 What to expect in each chapter 1.2 Strategies for Accessing and Using this OER 1.3 If You are New to R", " Chapter 1 Introduction Screencasted Lecture Link 1.1 What to expect in each chapter This textbook is intended as applied, in that a primary goal is to help the scientist-practitioner-advocate use a variety of statistics in research problems and writing them up for a program evaluation, dissertation, or journal article. In support of that goal, I try to provide just enough conceptual information so that the researcher can select the appropriate statistic (i.e., distinguishing between when ANOVA is appropriate and when regression is appropriate) and assign variables to their proper role (e.g., covariate, moderator, mediator). This conceptual approach does include occasional, step-by-step, hand-calculations (only we calculate them arithmetically in R) to provide a visceral feeling of what is happening within the statistical algorithm that may be invisible to the researcher. Additionally, the conceptual review includes a review of the assumptions about the characteristics of the data and research design that are required for the statistic. Statistics can be daunting, so I have worked hard to establish a workflow through each analysis. When possible, I include a flowchart that is referenced frequently in each chapter and assists the the researcher keep track of their place in the many steps and choices that accompany even the simplest of analyses. As with many statistics texts, each chapter includes a research vignette. Somewhat unique to this resource is that the vignettes are selected from recently published articles. Each vignette is chosen with the intent to meet as many of the following criteria as possible: the statistic that is the focus of the chapter was properly used in the article, the authors identity is from a group where scholarship is historically marginalized (e.g., BIPOC, LGBTQ+, LMIC [low middle income countries]), the research has a justice, equity, inclusion, diversity, and social responsivity focus and will contribute positively to a social justice pedagogy, and the data is available in a repository or there is sufficient information in the article to simulate the data for the chapter example(s) and practice problem(s). In each chapter we employ R packages that will efficiently calculate the statistic and the dashboard of metrics (e.g., effect sizes, confidence intervals) that are typically reported in psychological science. 1.2 Strategies for Accessing and Using this OER There are a number of ways you can access this resource. You may wish to try several strategies and then select which works best for you. I demonstrate these in the screencast that accompanies this chapter. Simply follow along in the .html formatted document that is available on via GitHub Pages, and then open a fresh .rmd file of your own, copying (or retyping) the script and running it Locate the original documents at the GitHub repository . You can open them to simply take note of the behind the scenes script copy/download individual documents that are of interest to you fork a copy of the entire project to your own GitHub site and further download it (in its entirety) to your personal workspace. The GitHub Desktop app makes this easy! Listen to the accompanying lectures (I think sound best when the speed is 1.75). The lectures are being recorded in Panopto and should include the closed captioning. Provide feedback to me! If you fork a copy to your own GitHub repository, you can open up an editing tool and mark up the document with your edits, start a discussion by leaving comments/questions, and then sending them back to me by committing and saving. I get an e-mail notiying me of this action. I can then review (accepting or rejecting) them and, if a discussion is appropriate, reply back to you. 1.3 If You are New to R R can be oveRwhelming. Jumping right into advanced statistics might not be the easiest way to start. However, in these chapters, I provide complete code for every step of the process, starting with uploading the data. To help explain what R script is doing, I sometimes write it in the chapter text; sometimes leave hastagged-comments in the chunks; and, particularly in the accompanying screencasted lectures, try to take time to narrate what the R script is doing. Ive found that, somewhere on the internet, theres almost always a solution to what Im trying to do. I am frequently stuck and stumped and have spent hours searching the internet for even the tiniest of things. When you watch my videos, you may notice that in my R studio, there is a scRiptuRe file. I takes notes on the solutions and scripts here  using keywords that are meaningful to me so that when I need to repeat the task, I can hopefully search my own prior solutions and find a fix or a hint. 1.3.1 Base R The base program is free and is available here: https://www.r-project.org/ Because R is already on my machine (and because the instructions are sufficient), I will not walk through the instllation, but I will point out a few things. Follow the instructions for your operating system (Mac, Windows, Linux) The cran (I think cranium) is the Comprehensive R Archive Network. In order for R to run on your computer, you have to choose a location. Because proximity is somewhat related to processing speed, select one that is geographically close to you. You will see the results of this download on your desktop (or elsewhere if you chose to not have it appear there) but you wont ever use R through this platform. 1.3.2 R Studio R Studio is the desktop application I work in R. Its a separate download. Choose the free, desktop, option that is appropriate for your operating system: https://www.rstudio.com/products/RStudio/ Upper right window: Includes several tabs; we frequently monitor the Environment: it lists the objects that are available to you (e.g., dataframes) Lower right window: has a number of helpful tabs. Files: Displays the file structure in your computers environment. Make it a practice to (a) organize your work in small folders and (b) navigating to that small folder that is holding your project when you are working on it. Packages: Lists the packages that have been installed. If you navigate to it, you can see if it is on. You can also access information about the package (e.g., available functions, examples of script used with the package) in this menu. This information opens in the Help window. Viewer and Plots are helpful, later, when we can simultaneously look at our output and still work on our script. Primary window R Studio runs in the background(in the console). Very occasionally, I can find useful troubleshooting information here. More commonly, I open my R Markdown document so that it takes the whole screen and I work directly, right here. R Markdown is the way that many analysts write script, conduct analyses, and even write up results. These are saved as .rmd files. In R Studio, open an R Markdown document through File/New File/R Markdown Specify the details of your document (title, author, desired ouput) In a separate step, SAVE this document (File/Save] into a NEW FILE FOLDER that will contain anything else you need for your project (e.g., the data). Packages are at the heart of working in R. Installing and activating packages require writing script. 1.3.3 R Hygiene Many initial problems in R can be solved with good R hygiene. Here are some suggestions for basic practices. It can be tempting to skip this. However, in the first few weeks of class, these are the solutions I am presenting to my students. 1.3.3.1 Everything is documented in the .rmd file Although others do it differently, everything is in my .rmd file. That is, for uploading data and opening packages I write the code in my .rmd file. Why? Because when I read about what I did hours or years later, I have a permanent record of very critical things like (a) where my data is located, (b) what version I was using, and (c) what package was associated with the functions. 1.3.3.2 File organization File organization is a critical key to this: Create a project file folder. Put the data file in it. Open an R Markdown file. Save it in the same file folder. When your data and .rmd files are in the same folder (not your desktop, but a shared folder), they can be connected. 1.3.3.3 Chunks The R Markdown document is an incredible tool for integrating text, tables, and analyses. This entire OER is written in R Markdown. A central feature of this is chunks. The easiest way to insert a chunk is to use the INSERT/R command at the top of this editor box. You can also insert a chunk with the keyboard shortcut: CTRL/ALT/i Chunks start and end with with those three tic marks and will show up in a shaded box, like this: #hashtags let me write comments to remind myself what I did #here I am simply demonstrating arithmetic (but I would normally be running code) 2021 - 1966 ## [1] 55 Each chunk must open and close. If one or more of your tic marks get deleted, your chunk wont be read as such and your script will not run. The only thing in the chunks should be script for running R; you can hashtag-out script so it wont run. Although unnecessary, you can add a brief title for the chunk in the opening row, after the r. These create something of a table of contents of all the chunks  making it easier to find what you did. You can access them in the Chunks tab at the bottom left of R Studio. If you wish to knit a document, you cannot have identical chunk titles. You can put almost anything you want in the space outside of tics. Syntax for simple formatting in the text areas (e.g,. using italics, making headings, bold, etc.) is found here: https://rmarkdown.rstudio.com/authoring_basics.html 1.3.3.4 Packages As scientist-practitioners (and not coders), we will rely on packages to do our work for us. At first you may feel overwhelmed about the large number of packages that are available. Soon, though, you will become accustomed to the ones most applicable to our work (e.g., psych, tidyverse, lavaan, apaTables). Researchers treat packages differently. In these lectures, I list all the packages we will use in an opening chunk that asks R to check to see if the package is installed, and if not, installs it. if(!require(psych)){install.packages(&quot;psych&quot;)} ## Loading required package: psych ## Warning: package &#39;psych&#39; was built under R version 4.0.5 To make a package operable, you need to open it through the library. This process must be repeated each time you restart R. I dont open the package (through the library(package_name)) command until it is time to use it. Especially for new users, I think its important to connect the functions with the specific packages. #install.packages (&quot;psych&quot;) library (psych) If you type in your own install.packages code, hashtag it out once its been installed. It is problematic to continue to re-run this code . 1.3.3.5 Knitting An incredible feature of R Markdown is its capacity to knit to HTML, powerpoint, or word. If you access the .rmd files for this OER, you can use annotate or revise them to suit your purposes. If you redistribute them, though, please honor the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License with a citation. 1.3.4 tRoubleshooting in R maRkdown Hiccups are normal. Here are some ideas that I have found useful in getting unstuck. In an R script, you must have everything in order  Every. Single. Time. All the packages have to be in your library and activated; if you restart R, you need to reload each package. If you open an .rmd file and want a boxplot, you cannot just scroll down to that script. You need to run any prerequisite script (like loading the package, importing data, putting the data in the global environment, etc.) Do you feel lost? clear your global environment (broom) and start at the top of the R script. Frequent, fresh starts are good. Your .rmd file and your data need to be stored in the same file folder. These should be separate for separate projects, no matter how small. Type any warnings you get into a search engine. Odds are, youll get some decent hints in a manner of seconds. Especially at first, these are common errors: The package isnt loaded (if you restarted R, you need to reload your packages) The .rmd file has been saved yet, or isnt saved in the same folder as the data Errors of punctuation or spelling Restart R (its quick  not like restarting your computer) If you receive an error indicating that a function isnt working or recognized, and you have loaded the package, type the name of the package in front of the function with two colons (e.g., psych::describe(df). If multiple packages are loaded with functions that have the same name, R can get confused. 1.3.5 stRategies for success Engage with R, but dont let it overwhelm you. The mechanical is also the conceptual. Especially when it is simpler, do try to retype the script into your own .rmd file and run it. Track down the errors you are making and fix them. If this stresses you out, move to simply copying the code into the .rmd file and running it. If you continue to have errors, you may have violated one of the best practices above (Is the package loaded? Are the data and .rmd files in the same place? Is all the prerequisite script run?). Still overwhelmed? Keep moving forward by downloading a copy of the .rmd file that accompanies any given chapter and just run it along with the lecture. Spend your mental power trying to understand what each piece does. Then select a practice problem that is appropriate for your next level of growth. Copy script that works elsewhere and replace it with your datafile, variables, etc. The leaRning curve is steep, but not impossible. Gladwell(2008) reminds us that it takes about 10,000 hours to get GREAT at something (2,000 to get reasonably competent). Practice. Practice. Practice. Updates to R, R Studio, and the packages are NECESSARY, but can also be problematic. It could very well be that updates cause programs/script to fail (e.g., X has been deprecated for version X.XX). Moreover, this very well could have happened between my distribution of these resources and your attempt to use it. My personal practice is to update R, R Studio, and the packages a week or two before each academic term. Embrace your downward dog. Also, walk away, then come back. 1.3.6 Resources for getting staRted R for Data Science: https://r4ds.had.co.nz/ R Cookbook: http://shop.oreilly.com/product/9780596809164.do R Markdown homepage with tutorials: https://rmarkdown.rstudio.com/index.html R has cheatsheets for everything, heres one for R Markdown: https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf R Markdown Reference guide: https://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf Using R Markdown for writing reproducible scientific papers: https://libscie.github.io/rmarkdown-workshop/handout.html LaTeX equation editor: https://www.codecogs.com/latex/eqneditor.php References "],["wGroups.html", "Chapter 2 Nested Within Groups 2.1 Navigating this Lesson 2.2 Multilevel Modeling: Nested within Groups 2.3 Workflow 2.4 Research Vignette 2.5 Working the Problem (and learning MLM) 2.6 Residual and Related Questions 2.7 Practice Problems 2.8 Bonus Track:", " Chapter 2 Nested Within Groups Lynette H. Bikos, PhD, ABPP, and Kiet D. Huynh, PhD Co-Authors Screencasted Lecture Link options(scipen=999)#eliminates scientific notation This chapter provides an introduction to multilevel modeling (MLM). Known by a variety of names, MLM offers researchers the ability to manage data that is nested within groups (cross-sectional), within persons (longitudinal), or both. MLM is complex and powerful. This chapter will provide an introduction and worked example of MLM when data is collected in groups (churches). At the risk of oversimplification, my goal is to make it as accessible as possible. To that end, the chapter and lecture will err on the side of application. If you are interested in the more technical details of this procedure, there are tremendous resources that far exceed my capacity and the purpose of this OER (e.g., Bryk &amp; Raudenbush, 1992). At the outset of this series of chapters on MLM, let me share with you why I get so excited about this statistical approach. Remember ANOVA? And its assumptions? Among these were assumptions of balanced designs (i.e., equal cell sizes); independence (i.e., unless using repeated measures ANOVA, participants could not be related/connected in other ways); and to rule out confounds, random assignment to treatment conditions. Unless the data to be analyzed comes from an experiment, these are difficult conditions to meet. When we use a multilevel approach to analyze cross-sectional research where there is clear nesting in groups (e.g., teams, classrooms) we are no longer bound by these restrictive assumptions. Presuming there is an adequate sample (Bell et al., 2014 suggested a minimum of 10 clusters with 5 members each),even the group size can vary. Of course there are other benefits and challenges that we will address throughout the series of chapters. 2.1 Navigating this Lesson There is about 1 hour and 30 minutes of lecture. If you work through the materials with me it would be plan for an additional 2 hours. While the majority of R objects and data you will need are created within the R script that sources the chapter, occasionally there are some that cannot be created from within the R framework. Additionally, sometimes links fail. All original materials are provided at the Github site that hosts the book. More detailed guidelines for ways to access all these materials are provided in the OERs introduction 2.1.1 Learning Objectives Learning objectives from this lecture include the following: Recognize when MLM is appropriate as an analytic strategy for a particular research design and set of data. Distinguish between L1 and L2 variables. Describe the compositional effects approach to centering variables and explain how it completely captures within- and between- group variance. Write R script to group-mean center, grand-mean center, and aggregate L1 variables for their L2 representation. Utilize a sequential and systematic approach to testing a series of multilevel models. Create corresponding figures and tables. Write up the results of a cross-sectional multilevel model in APA style. 2.1.2 Planning for Practice In this chapter we offer three suggestions for practice. Each are graded in complexity. At a minimum, we recommend that you analyze a multilevel model that contains one level-1 (within-group) predictor, one level-2 (between groups) predictor, and their interaction. Rework the problem in the chapter by changing the random seed in the code that simulates the data. This should provide very minor changes to the data, but the results will likely be very similar. The research vignette analyzes a number of variables, simultaneously. We selected only two for the example. Swap out one or more variables in the multilevel model and compare your solution to the one in the chapter (and/or one you mimicked in the journal article). If you wish to increase your probability of finding statistically significant effects, look for hints in Table 2 of the (Lefevor et al., 2020) research article that sources the vignettes by selecting a variable(s) with a significant relationship with your DV. Conduct a multilevel model with data to which you have access. This could include data you simulate on your own or from a published article. 2.1.3 Readings &amp; Resources In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list. Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). Applied multiple regression/correlation analysis for the behavioral sciences, 3rd ed. Lawrence Erlbaum Associates Publishers Enders, C. K., &amp; Tofighi, D. (2007). Centering predictor variables in cross-sectional multilevel models: A new look at an old issue. Psychological Methods, 12(2), 121-138. doi:10.1037/1082-989X.12.2.121 McCoach, D. B., &amp; Adelson, J. L. (2010). Dealing with dependence (Part I): Understanding the effects of clustered data. Gifted Child Quarterly, 54(2), 152155. https://doi-org.ezproxy.spu.edu/10.1177/0016986210363076 McCoach, D. B. (2010). Dealing with dependence (Part II): A gentle introduction to hierarchical linear modeling. Gifted Child Quarterly, 54(3), 252-256. doi: 10.1177/0016986210373475 Lefevor, G. T., Paiz, J. Y., Stone, W.-M., Huynh, K. D., Virk, H. E., Sorrell, S. A., &amp; Gage, S. E. (2020). Homonegativity and the Black church: Is congregational variation the missing link? The Counseling Psychologist, 48(6), 826851. https://doi-org.ezproxy.spu.edu/10.1177/0011000020918558 2.1.4 Packages The script below will (a) check to see if the following packages are installed on your computer and, if not (b) install them. #will install the package if not already installed if(!require(lme4)){install.packages(&quot;lme4&quot;)} if(!require(nlme)){install.packages(&quot;nlme&quot;)} if(!require(sjstats)){install.packages(&quot;sjstats&quot;)} if(!require(tidyverse)){install.packages(&quot;tidyverse&quot;)} if(!require(psych)){install.packages(&quot;psych&quot;)} if(!require(lmerTest)){install.packages(&quot;lmerTest&quot;)} if(!require(robumeta)){install.packages(&quot;robumeta&quot;)} if(!require(sjstats)){install.packages(&quot;sjstats&quot;)} if(!require(PerformanceAnalytics)){install.packages(&quot;PerformanceAnalytics&quot;)} 2.2 Multilevel Modeling: Nested within Groups 2.2.1 The dilemma of aggregation and disaggregation It was the 1980s and researchers were studying group attitudes and were confused about how to analyze the data (Singer &amp; Willett, 2003).They ran into difficulties with aggregation and asked, Do we aggregate the data by summing individuals within groups (i.e., giving everyone in the group the same score)?\" Or, Do we disaggregate the data by ignoring group membership and analyzing the individual cases. Problems with aggregation (using group means) include the following: Regression equations describe the relationship of means of predictors in individual clusters to the mean of the dependent variable in those clusters. There is a decrease in variability regarding the the ability to explain what is going on with the dependent variable. It can be misleading to generalize from the group level variable to the individual. This is termed the ecological fallacy (also known as the Robinson Effect). Problems with disaggregation (using individual scores and ignoring the group influence) include: Results that ignore group level variables. There is often clustering among group members. Clustering (i.e., group effects, dependency in the data) violates the assumption of independence for most ANOVA and regression statistics. We are more likely to make a Type I error (i.e., declaring a statistically significant relationship when there is none) because Alpha inflation Standard error is based on N; standard errors are smaller than they should be. Dependency in the data may reduce within group variance. 2.2.2 Multilevel modeling: The definitional and conceptual Multilevel modeling (MLM) has a host of names: Hierarchical linear modeling (but this also references a specific, fee-for-use, package) Mixed effects Linear mixed effects (LME  youll see this acronym in our R package and functions) Random coefficient regression (RCR) Random coefficient modeling (RCM) By whatever name we call it, the random coefficient regression model is an alternative to ordinary least squares regression (OLS) that is structured to handle clustered data. Random coefficient regression differs from OLS regression in the assumptions made about the nature of the regression coefficients and the correlational structure of the individual observations. Highlights of RC regression models, individuals are clustered into groups and we can have multiple levels of measurement at the individual and group levels), the equations are mathematically different from OLS regression, they can be applied cross-sectional and repeated measures designs. In this chapter our focus is on the cross-sectional, nested analyses. Image of a three-level model Levels on these figures are important and represent the hierarchical structure of RCR. Level 1: lowest level of aggregation, the individual, a micro-level Level 2: cluster or group level, the macro-level Levels 3 +: higher-order clustering; beyond the scope of this class (and instructor). As we work through this chapter we will be reviewing essential elements to MLM. These include: Levels Fixed and random effects Variance components Centering to maximize interpretability and a complete accounting of variance Equations Because these are complicated, it makes sense to me to start introduce the research vignette a little earlier than usual so that we have a concrete example for locating these concepts. First, though, lets look at how we manage an MLM analysis. 2.3 Workflow Image of a workflow through a nested within-groups MLM 2.4 Research Vignette The research vignette comes from Lefevor et al.s (2020) article, Homonegativity and the Black Church: Is congregational variation the missing link? The article was published in The Counseling Psychlogist. I am so grateful to the authors who provided their R script. It was a terrific source of consultation as I planned the chapter. Data is from congregants in 15 Black churches (with at least 200 members in each church) in a mid-sized city in the South. Congregational participation ranged from 2 to 28. The research design allows the analysts to identify individual level and contextual (i.e., congregational) level predictors of attitudes toward same-sex sexuality. The research question asks, what individual-level and church-level predictors influence an indivdiuals attitudes toward same-sex sexuality (i.e., homonegativity). Variables used in the study included: Attitudes toward Same Sex Sexuality(ATSS/homonegativity): The short form of the Attitudes Toward Lesbian Women and Gay Men Scale (Herek, 1994) is 10 items on a 5-point likert scale of agreement. Sample items include, Sex between two men is just plan wrong and Lesbians are sick. Higher scores represent more homonegative views. Religiousness Organizational religiousness was assessed through with the single-item organizational religious activity scale of the Duke University Religiousness Index (Koenig &amp; Büssing, 2010). The item asks participants to report how often they attend church or other religious meetings on a 9-point Likert-type scale ranging from 0 (never) to 9 (several times a week). Higher scores indicate more frequent attendance. Racial homogeneity This was calculated by estimating the proportion of respondents from a single race prior to excluding those who did not meet the inclusion criteria (e.g., one criteria was that the participants self-identify as Black). Age, Education, Gender: Along with other demographic and background variables, age, education, and gender were collected. Gender is dichotomous with 0 = woman and 1 = man. In the article, Lefevor (2020) and colleagues predict attitudes toward same-sex sexuality from a number of person-level (L1) and congregation-level (L2) predictors. Because this is an instructional article, we are choosing one each: attendance (used as both L1 and L2) and homogeneity of the congregation (L2). Although the authors do not include cross-level (i.e., an interaction between L1 and L2 variables), we will test a cross-level interaction of attendance*homogeneity. 2.4.1 Simulating the data from the journal article Muldoon (2018) has provided clear and intuitive instructions for simulating multilevel data. Simulating the data gives us some information about the nature of MLM. You can see that we have identified: the number of churches the number of members from each church Note: in this simulation we have the benefit of non-missing data (unless we specify it) the b weights (and ranges) reported in the Lefevor et al. (2020) article the mean and standard deviation of the dependent variable Further down in the code, we feed R the regression equation. set.seed(200407) n_church = 15 n_mbrs = 15 b0 = 3.43 #intercept for ATSS b1 = .14 #b weight for L1 var gender b2 = .00 #b weight or L1 var age b3 = .02 #b weight for L1 var education b4 = .10 #b weight for the L1 variable religious attendance b5 = -.89 #b weight for the L2 variable, racial homogeneity ( Gender = runif(n_church*n_mbrs, -1.09, 1.67)) #calc L1 gender ( Age = runif(n_church*n_mbrs, 6.44, 93.93)) #calc L1 age ( Education = runif(n_church*n_mbrs, 0, 8.46)) #calc L1 education ( Attendance = runif(n_church*n_mbrs,5.11, 10.39)) #calc L1 attendance by grabbing its M +/- 3SD ( Homogeneity = rep (runif(n_church, .37, 1.45), each = n_mbrs)) #calc L2 homogeneity by grabbing its M +/- 3SD mu = 3.39 sds = .64 #this is the SD of the DV sd = 1 #this is the observation-level random effect variance that we set at 1 ( church = rep(LETTERS[1:n_church], each = n_mbrs) ) #( mbrs = numbers[1:(n_church*n_mbrs)] ) ( churcheff = rnorm(n_church, 0, sds) ) ( churcheff = rep(churcheff, each = n_mbrs) ) ( mbrseff = rnorm(n_church*n_mbrs, 0, sd) ) ( ATSS = b0 + b1*Gender + b2*Age + b3*Education + b4*Attendance + b5*Homogeneity + churcheff + mbrseff) ( dat = data.frame(church, churcheff, mbrseff, Gender, Age, Education, Attendance, Homogeneity, ATSS) ) library(dplyr) dat &lt;- dat %&gt;% mutate(ID = row_number()) #moving the ID number to the first column; requires dat &lt;- dat%&gt;%select(ID, everything()) Lefevor2020 &lt;- dat%&gt;% select(ID, church, Gender, Age, Education, Attendance, Homogeneity, ATSS) #rounded gender into dichotomous variable Lefevor2020$Female0 &lt;- round(Lefevor2020$Gender, 0) Lefevor2020$Female0 &lt;- as.integer(Lefevor2020$Gender) Lefevor2020$Female0 &lt;- plyr::mapvalues(Lefevor2020$Female0, from = c(-1, 0, 1), to = c(0, 0, 1)) #( dat$ATSS = with(dat, mu + churcheff + mbrseff ) ) Below is script that will allow you to export and reimport the dataset we just simulated. This may come in handy if you wish to start from the simulated data (and not wait for the simulation each time) and/or if you would like to use the dataset for further practice. write.table(Lefevor2020, file=&quot;Lefevor2020.csv&quot;, sep=&quot;,&quot;, col.names=TRUE, row.names=FALSE) Lefevor2020 &lt;- read.csv (&quot;Lefevor2020.csv&quot;, head = TRUE, sep = &quot;,&quot;) Because we are simulating data, we have the benefit of no missingness and relatively normal distributions. Because of these reasons we will skip the formal data preparation stage. We will, though, take a look at our characteristics and bivariate relations of our three variables of interest. 2.5 Working the Problem (and learning MLM) 2.5.1 Data diagnostics Multilevel modeling holds assumptions that will likely be familiar to use: linearity homogeneity of variance normal distribution of the models residuals Because I cover strategies for evaluating these assumptions in the Data Dx chapter, I wont review them here. Another helpful resource for reviewing assumptions related to MLM is provided in by Michael Palmeri. We should, though take a look at the relations between the variables in our model in their natural form. In this case natural refers to their scored, ready-to-be-analyzed (but not further centered). library(psych) psych::pairs.panels(Lefevor2020[c(&quot;ATSS&quot;, &quot;Attendance&quot;, &quot;Homogeneity&quot;)], stars = TRUE) What do we observe in this preliminary, zero-ordered relationship? As racial homogeneity increases, homonegativity decreases. Curiously, there is a non-linear curve between those two variables  but that seems to be pulled by an outlier(?) in the lower right quandrant of the ATSS/Homonegativity relationship. ATTS appears to be normally distributed Attendance has a flat distribution We can learn more by examining descriptive statistics. psych::describe(Lefevor2020[c(&quot;ATSS&quot;, &quot;Attendance&quot;, &quot;Homogeneity&quot;)]) vars n mean sd median trimmed mad min max range skew ATSS 1 225 3.32 1.18 3.43 3.34 1.11 -1.23 6.45 7.69 -0.30 Attendance 2 225 7.52 1.52 7.36 7.47 1.84 5.12 10.35 5.22 0.24 Homogeneity 3 225 1.04 0.25 1.14 1.04 0.34 0.69 1.40 0.71 -0.04 kurtosis se ATSS 0.27 0.08 Attendance -1.19 0.10 Homogeneity -1.60 0.02 These descriptives allow us a glimpse of the means and standard deviations of our study variables. Additionally, we can look at skew and kurtosis to see that our variables are within the normal ranges (i.e., below 3 for skew; below 8 for kurtosis (Kline, 2016)). 2.5.2 Levels Levels are a critical component of MLM. In the context of MLM models of nesting within groups/clusters (e.g., cross-sectional MLM): Level 1 (L1) variables belong to the person Age, race, attitudinal or behavioral assessment Level 2 (L2) variables belong to the group/cluster Leader characteristic, economic indicator that is unique to the group/cluster Aggregate/composite representation of L1 variables In our tiny model from the Lefevor et al. (2020) vignette: ATSS/homonegativity is our DV; it is an L1 observation because we are predicting individuals attitudes toward same-sex sexuality. Attendance is an L1 observation when we are using it as the individuals own church attendance. Attendance will be an L2 observation when we aggregate it an use it as a value to represent the church. Racial homogeneity is only entered as an L2 variable. It was collected at the individual level via self-identification of race and calculated to represent the proportion of Black individuals in the church. head(Lefevor2020[c(&quot;church&quot;, &quot;ATSS&quot;, &quot;Attendance&quot;, &quot;Homogeneity&quot;)], n = 30L) church ATSS Attendance Homogeneity 1 A 4.7835442 6.318674 0.7957395 2 A 5.3851521 9.391428 0.7957395 3 A 4.3722317 9.832894 0.7957395 4 A 4.8635210 7.721731 0.7957395 5 A 4.9733886 9.917289 0.7957395 6 A 4.3455429 8.844333 0.7957395 7 A 3.5357514 6.630585 0.7957395 8 A 4.1572480 8.111701 0.7957395 9 A 4.2946421 9.658424 0.7957395 10 A 3.9311877 5.743799 0.7957395 11 A 4.9380802 6.048393 0.7957395 12 A 4.6318423 5.908200 0.7957395 13 A 3.4139728 7.685524 0.7957395 14 A 2.6348562 6.900703 0.7957395 15 A 4.8415811 6.594790 0.7957395 16 B 0.9835024 6.176724 1.1691398 17 B 1.9247771 7.907341 1.1691398 18 B 3.7576164 5.469059 1.1691398 19 B 3.6992782 9.262913 1.1691398 20 B 2.9125454 9.001514 1.1691398 21 B 4.0568240 7.486189 1.1691398 22 B 1.2471085 9.417031 1.1691398 23 B 3.2280375 6.066014 1.1691398 24 B 3.7688923 7.413705 1.1691398 25 B 4.0418646 6.047803 1.1691398 26 B 5.4240898 7.157878 1.1691398 27 B 3.8355654 9.687518 1.1691398 28 B 2.6657722 5.972512 1.1691398 29 B 2.8502831 9.761905 1.1691398 30 B 2.8982202 9.689345 1.1691398 In this display of the first 30 rows, we see the data for the first two churches (i.e., A and B). The value is (potentially) different for each individual in each church for the two L1 variables: ATSS, Attendance. In contrast, the value of the variable is constant for the L2 variable, Homogeneity for churches A and B. 2.5.3 Centering Before we continue with modeling, we need to consider centering. That is, we transform our predictor variables to give the intercept parameters more useful interpretations. While there are some general practices, there are often arguments for different approaches: We usually focus centering on L1 predictors. We usually focus centering on continuously scaled variables. Dichotomous variables are considered to be centered, so long as there is a meaningful 0 (e.g., control group = 0; treatment group = 1), many do not further center. Newsom (2019), though, argues that if a binary variable is an L1 predictor, group mean centering produces intercepts weighted by the proportion of 1 to 0 values for each group; grand mean centering provides the sample weight adjustment to make the sample mean (each groups mean) proportionate to the population (full sample) Dependent variables are generally not centered we generally consider three centering strategies: The natural metric is ideal if the variable has a meaningful zero point (e.g., drug dosage, time). It is more difficult when there is a non-zero metric. When there are dichotomous variables, the natural metric works well (i.e., 0 = control group, 1 = treatment group). The natural metric is an acceptable choice when the interest is only on the effects of L1 variables, rather than on the effects of group-level variables. Grand mean centering (GCM) involves subtracting the mean from each cases score on the variable. The intercept is interpreted as the expected value of the DV for a person/group that is compared with all individuals/groups. Intercepts are adjusted group means (like an ANCOVA model) Variance in the intercepts represents between-group variance in the adjusted means (i.e., adjusted for L1 predictors) The effects of L1 predictors are partialed out (controlled for) of the between-group variance GCM is most useful when we are interested in L2 predictors with L1 covariates Interactions specified L2 GCM is a good choice when the primary interest is on the effects of L2 variables, controlling for the L1 predictors. Group mean centering or Centering within Context (CWC) involves subtracting the mean of the individuals group from each score. The L1 intercept is interpreted as the expected mean on the DV for the persons group. Group mean centering/CWC: Provides a measure of the IV that accounts for ones relative standing within the group Removes between-group variability from the model (deviations rom the group means are now the predictors) If we only use group mean centering (CWC), we lose information about between-group differences Assumes that relative standing within the group is an important factor Is most useful when we are interested in Relations among L1 variables Interactions among L1 variables Interactions between L1 and L2 variables CWC is an acceptable choice when the interest is only on the effects of L1 variables, rather than on the effects of group-level variables because it provides unbiased estimates of the pooled within group effect of an individual variable. In the case of making centering choices with our variables, we are must think about the frog pond effect. That is, for the same size frog, the experience of being in a pond with big frogs may be different from being in a pond with small frogs. When we consider our present research vignette, we might ask, Does the effect of church attendance on ATSS depend only on the individuals own church attendance. Or, Does the overall church attendance (size of the pond) also related to ATSS? Compositional effects (Enders &amp; Tofighi, 2007) involves transforming the natural metric of the score into a group-mean centered (CWC) variable at L1 and a group mean aggregate at L2. Both the CWC/L1 and aggregate/L2 are entered into the MLM. When the aggregate is added back in at L2, we get direct estimates of both the within- and between- group effects through group-mean centering We term it compositional effects because it represents the difference between the contextual-level effect and the person-level predictor. This is a great strategy when the interest is on distinguishing individual effects of variables (e.g., church attendance) from group-level effects of that same variable (e.g., overall church attendance). Following the Lefevor and colleagues (2020) example, we will use the compositional effects approach with our data. The group.center() function in the R package, robumeta will group mean center (CWC) variables. All we need to do is identify the clustering variable in our case, church. Similarly, robumetas group.mean function will aggregate variables at the groups mean. library(robumeta) Lefevor2020$AttendL1 &lt;- as.numeric(group.center(Lefevor2020$Attendance, Lefevor2020$church))#centered within context (group mean centering) Lefevor2020$AttendL2 &lt;- as.numeric(group.mean(Lefevor2020$Attendance, Lefevor2020$church))#aggregated at group mean head(Lefevor2020[c(&quot;church&quot;, &quot;ATSS&quot;, &quot;Attendance&quot;, &quot;AttendL1&quot;, &quot;AttendL2&quot;, &quot;Homogeneity&quot;)], n = 30L) church ATSS Attendance AttendL1 AttendL2 Homogeneity 1 A 4.7835442 6.318674 -1.368556846 7.687231 0.7957395 2 A 5.3851521 9.391428 1.704196481 7.687231 0.7957395 3 A 4.3722317 9.832894 2.145662408 7.687231 0.7957395 4 A 4.8635210 7.721731 0.034499326 7.687231 0.7957395 5 A 4.9733886 9.917289 2.230057976 7.687231 0.7957395 6 A 4.3455429 8.844333 1.157102115 7.687231 0.7957395 7 A 3.5357514 6.630585 -1.056646112 7.687231 0.7957395 8 A 4.1572480 8.111701 0.424469781 7.687231 0.7957395 9 A 4.2946421 9.658424 1.971192960 7.687231 0.7957395 10 A 3.9311877 5.743799 -1.943432538 7.687231 0.7957395 11 A 4.9380802 6.048393 -1.638837820 7.687231 0.7957395 12 A 4.6318423 5.908200 -1.779031167 7.687231 0.7957395 13 A 3.4139728 7.685524 -0.001707147 7.687231 0.7957395 14 A 2.6348562 6.900703 -0.786528003 7.687231 0.7957395 15 A 4.8415811 6.594790 -1.092441414 7.687231 0.7957395 16 B 0.9835024 6.176724 -1.591106297 7.767830 1.1691398 17 B 1.9247771 7.907341 0.139510679 7.767830 1.1691398 18 B 3.7576164 5.469059 -2.298771340 7.767830 1.1691398 19 B 3.6992782 9.262913 1.495083015 7.767830 1.1691398 20 B 2.9125454 9.001514 1.233683676 7.767830 1.1691398 21 B 4.0568240 7.486189 -0.281641399 7.767830 1.1691398 22 B 1.2471085 9.417031 1.649200996 7.767830 1.1691398 23 B 3.2280375 6.066014 -1.701816135 7.767830 1.1691398 24 B 3.7688923 7.413705 -0.354124518 7.767830 1.1691398 25 B 4.0418646 6.047803 -1.720027268 7.767830 1.1691398 26 B 5.4240898 7.157878 -0.609951815 7.767830 1.1691398 27 B 3.8355654 9.687518 1.919687868 7.767830 1.1691398 28 B 2.6657722 5.972512 -1.795317977 7.767830 1.1691398 29 B 2.8502831 9.761905 1.994075223 7.767830 1.1691398 30 B 2.8982202 9.689345 1.921515292 7.767830 1.1691398 If we look again at the first two churches, we can see the Natural metric (ATSS, Attendance) which differs for each person across all churches This would be an L1 variable Group-mean centering (CWC; ATSSL2) which is identifiable because if you added up each of the values in each of the churches, the sum would be zero for each church This would be an L1 variable Aggregate group mean (AttendL2) which is identifiable because the value is constant across each of the groups This would be an L2 variable You might notice, I didnt mention the homogeneity variable. This is because it was collected and entered as an L2 variable and needs no further centering/transformation. Similarly, we typically leave the dependent variable (ATSS) in the natural metric. We can also see the effects of centering in our descriptives. psych::describe(Lefevor2020[c(&quot;ATSS&quot;, &quot;Attendance&quot;, &quot;AttendL1&quot;, &quot;AttendL2&quot;, &quot;Homogeneity&quot;)]) vars n mean sd median trimmed mad min max range skew ATSS 1 225 3.32 1.18 3.43 3.34 1.11 -1.23 6.45 7.69 -0.30 Attendance 2 225 7.52 1.52 7.36 7.47 1.84 5.12 10.35 5.22 0.24 AttendL1 3 225 0.00 1.48 -0.01 -0.02 1.88 -2.93 3.01 5.94 0.10 AttendL2 4 225 7.52 0.32 7.55 7.52 0.33 7.01 8.06 1.05 0.02 Homogeneity 5 225 1.04 0.25 1.14 1.04 0.34 0.69 1.40 0.71 -0.04 kurtosis se ATSS 0.27 0.08 Attendance -1.19 0.10 AttendL1 -1.14 0.10 AttendL2 -0.93 0.02 Homogeneity -1.60 0.02 Note that the mean for the ATTSL1 and AttendL1 variables are now zero, while the aggregated group means are equal to the mean of the natural metric. Looking at the descriptives for each church also helps clarify what we have done. psych::describeBy(ATSS + Attendance + AttendL1 + AttendL2 + Homogeneity ~ church, data = Lefevor2020) Descriptive statistics by group church: A vars n mean sd median trimmed mad min max range skew ATSS 1 15 4.34 0.72 4.37 4.39 0.70 2.63 5.39 2.75 -0.78 Attendance 2 15 7.69 1.52 7.69 7.67 2.03 5.74 9.92 4.17 0.23 AttendL1 3 15 0.00 1.52 0.00 -0.02 2.03 -1.94 2.23 4.17 0.23 AttendL2 4 15 7.69 0.00 7.69 7.69 0.00 7.69 7.69 0.00 NaN Homogeneity 5 15 0.80 0.00 0.80 0.80 0.00 0.80 0.80 0.00 NaN kurtosis se ATSS -0.21 0.19 Attendance -1.63 0.39 AttendL1 -1.63 0.39 AttendL2 NaN 0.00 Homogeneity NaN 0.00 ------------------------------------------------------------ church: B vars n mean sd median trimmed mad min max range skew ATSS 1 15 3.15 1.15 3.23 3.15 0.83 0.98 5.42 4.44 -0.22 Attendance 2 15 7.77 1.59 7.49 7.79 2.24 5.47 9.76 4.29 -0.01 AttendL1 3 15 0.00 1.59 -0.28 0.02 2.24 -2.30 1.99 4.29 -0.01 AttendL2 4 15 7.77 0.00 7.77 7.77 0.00 7.77 7.77 0.00 NaN Homogeneity 5 15 1.17 0.00 1.17 1.17 0.00 1.17 1.17 0.00 NaN kurtosis se ATSS -0.50 0.30 Attendance -1.75 0.41 AttendL1 -1.75 0.41 AttendL2 NaN 0.00 Homogeneity NaN 0.00 ------------------------------------------------------------ church: C vars n mean sd median trimmed mad min max range skew ATSS 1 15 2.93 0.92 2.98 2.90 1.14 1.68 4.58 2.91 0.14 Attendance 2 15 7.01 1.01 6.78 6.95 0.87 5.83 8.96 3.13 0.75 AttendL1 3 15 0.00 1.01 -0.22 -0.06 0.87 -1.18 1.95 3.13 0.75 AttendL2 4 15 7.01 0.00 7.01 7.01 0.00 7.01 7.01 0.00 NaN Homogeneity 5 15 1.22 0.00 1.22 1.22 0.00 1.22 1.22 0.00 NaN kurtosis se ATSS -1.20 0.24 Attendance -0.88 0.26 AttendL1 -0.88 0.26 AttendL2 NaN 0.00 Homogeneity NaN 0.00 ------------------------------------------------------------ church: D vars n mean sd median trimmed mad min max range skew ATSS 1 15 2.62 1.07 2.79 2.64 1.43 0.88 4.10 3.22 -0.21 Attendance 2 15 8.06 1.85 8.41 8.12 2.27 5.12 10.20 5.08 -0.29 AttendL1 3 15 0.00 1.85 0.36 0.06 2.27 -2.93 2.14 5.08 -0.29 AttendL2 4 15 8.06 0.00 8.06 8.06 0.00 8.06 8.06 0.00 NaN Homogeneity 5 15 1.18 0.00 1.18 1.18 0.00 1.18 1.18 0.00 NaN kurtosis se ATSS -1.54 0.28 Attendance -1.71 0.48 AttendL1 -1.71 0.48 AttendL2 NaN 0.00 Homogeneity NaN 0.00 ------------------------------------------------------------ church: E vars n mean sd median trimmed mad min max range skew ATSS 1 15 3.42 0.92 3.57 3.41 0.49 1.70 5.33 3.63 -0.05 Attendance 2 15 8.00 1.70 7.95 8.02 2.27 5.50 10.33 4.82 -0.01 AttendL1 3 15 0.00 1.70 -0.05 0.01 2.27 -2.50 2.32 4.82 -0.01 AttendL2 4 15 8.00 0.00 8.00 8.00 0.00 8.00 8.00 0.00 NaN Homogeneity 5 15 1.32 0.00 1.32 1.32 0.00 1.32 1.32 0.00 NaN kurtosis se ATSS -0.49 0.24 Attendance -1.56 0.44 AttendL1 -1.56 0.44 AttendL2 NaN 0.00 Homogeneity NaN 0.00 ------------------------------------------------------------ church: F vars n mean sd median trimmed mad min max range skew ATSS 1 15 3.61 1.04 3.44 3.57 0.96 2.11 5.67 3.56 0.46 Attendance 2 15 7.27 1.18 7.27 7.19 1.04 5.68 9.90 4.22 0.69 AttendL1 3 15 0.00 1.18 0.00 -0.08 1.04 -1.59 2.63 4.22 0.69 AttendL2 4 15 7.27 0.00 7.27 7.27 0.00 7.27 7.27 0.00 NaN Homogeneity 5 15 0.93 0.00 0.93 0.93 0.00 0.93 0.93 0.00 NaN kurtosis se ATSS -0.95 0.27 Attendance -0.33 0.30 AttendL1 -0.33 0.30 AttendL2 NaN 0.00 Homogeneity NaN 0.00 ------------------------------------------------------------ church: G vars n mean sd median trimmed mad min max range skew ATSS 1 15 4.51 0.94 4.49 4.44 1.08 3.48 6.45 2.98 0.65 Attendance 2 15 7.01 0.94 7.18 7.01 1.27 5.50 8.47 2.96 -0.05 AttendL1 3 15 0.00 0.94 0.17 0.00 1.27 -1.50 1.46 2.96 -0.05 AttendL2 4 15 7.01 0.00 7.01 7.01 0.00 7.01 7.01 0.00 NaN Homogeneity 5 15 0.71 0.00 0.71 0.71 0.00 0.71 0.71 0.00 NaN kurtosis se ATSS -0.94 0.24 Attendance -1.35 0.24 AttendL1 -1.35 0.24 AttendL2 NaN 0.00 Homogeneity NaN 0.00 ------------------------------------------------------------ church: H vars n mean sd median trimmed mad min max range skew ATSS 1 15 3.55 1.19 3.48 3.55 0.84 1.20 5.83 4.63 -0.17 Attendance 2 15 7.35 1.70 7.57 7.30 2.45 5.13 10.20 5.07 0.23 AttendL1 3 15 0.00 1.70 0.22 -0.05 2.45 -2.22 2.86 5.07 0.23 AttendL2 4 15 7.35 0.00 7.35 7.35 0.00 7.35 7.35 0.00 NaN Homogeneity 5 15 0.82 0.00 0.82 0.82 0.00 0.82 0.82 0.00 NaN kurtosis se ATSS -0.43 0.31 Attendance -1.46 0.44 AttendL1 -1.46 0.44 AttendL2 NaN 0.00 Homogeneity NaN 0.00 ------------------------------------------------------------ church: I vars n mean sd median trimmed mad min max range skew ATSS 1 15 2.71 1.13 2.73 2.71 0.83 0.68 4.76 4.08 0.16 Attendance 2 15 7.26 1.63 7.25 7.20 2.26 5.14 10.17 5.03 0.12 AttendL1 3 15 0.00 1.63 -0.01 -0.06 2.26 -2.12 2.90 5.03 0.12 AttendL2 4 15 7.26 0.00 7.26 7.26 0.00 7.26 7.26 0.00 NaN Homogeneity 5 15 1.28 0.00 1.28 1.28 0.00 1.28 1.28 0.00 NaN kurtosis se ATSS -0.61 0.29 Attendance -1.43 0.42 AttendL1 -1.43 0.42 AttendL2 NaN 0.00 Homogeneity NaN 0.00 ------------------------------------------------------------ church: J vars n mean sd median trimmed mad min max range skew ATSS 1 15 3.47 0.99 3.81 3.50 1.05 1.67 4.90 3.23 -0.44 Attendance 2 15 7.86 1.89 7.89 7.88 2.89 5.25 10.25 5.00 -0.09 AttendL1 3 15 0.00 1.89 0.03 0.02 2.89 -2.62 2.39 5.00 -0.09 AttendL2 4 15 7.86 0.00 7.86 7.86 0.00 7.86 7.86 0.00 NaN Homogeneity 5 15 1.14 0.00 1.14 1.14 0.00 1.14 1.14 0.00 NaN kurtosis se ATSS -0.94 0.26 Attendance -1.70 0.49 AttendL1 -1.70 0.49 AttendL2 NaN 0.00 Homogeneity NaN 0.00 ------------------------------------------------------------ church: K vars n mean sd median trimmed mad min max range skew ATSS 1 15 2.45 1.04 2.53 2.41 1.09 0.92 4.49 3.57 0.30 Attendance 2 15 7.43 1.83 6.73 7.40 2.10 5.31 10.03 4.72 0.15 AttendL1 3 15 0.00 1.83 -0.71 -0.04 2.10 -2.12 2.59 4.72 0.15 AttendL2 4 15 7.43 0.00 7.43 7.43 0.00 7.43 7.43 0.00 NaN Homogeneity 5 15 1.37 0.00 1.37 1.37 0.00 1.37 1.37 0.00 NaN kurtosis se ATSS -0.82 0.27 Attendance -1.81 0.47 AttendL1 -1.81 0.47 AttendL2 NaN 0.00 Homogeneity NaN 0.00 ------------------------------------------------------------ church: L vars n mean sd median trimmed mad min max range skew ATSS 1 15 2.87 0.95 2.94 2.82 1.12 1.73 4.67 2.94 0.5 Attendance 2 15 7.68 1.27 7.54 7.69 1.36 5.57 9.71 4.14 0.1 AttendL1 3 15 0.00 1.27 -0.15 0.01 1.36 -2.11 2.03 4.14 0.1 AttendL2 4 15 7.68 0.00 7.68 7.68 0.00 7.68 7.68 0.00 NaN Homogeneity 5 15 1.40 0.00 1.40 1.40 0.00 1.40 1.40 0.00 NaN kurtosis se ATSS -1.06 0.25 Attendance -1.33 0.33 AttendL1 -1.33 0.33 AttendL2 NaN 0.00 Homogeneity NaN 0.00 ------------------------------------------------------------ church: M vars n mean sd median trimmed mad min max range skew ATSS 1 15 3.72 0.79 3.93 3.72 0.73 2.34 5.06 2.72 -0.27 Attendance 2 15 7.56 1.52 7.80 7.52 1.94 5.45 10.07 4.63 0.12 AttendL1 3 15 0.00 1.52 0.25 -0.03 1.94 -2.11 2.52 4.63 0.12 AttendL2 4 15 7.56 0.00 7.56 7.56 0.00 7.56 7.56 0.00 NaN Homogeneity 5 15 0.81 0.00 0.81 0.81 0.00 0.81 0.81 0.00 NaN kurtosis se ATSS -1.06 0.20 Attendance -1.42 0.39 AttendL1 -1.42 0.39 AttendL2 NaN 0.00 Homogeneity NaN 0.00 ------------------------------------------------------------ church: N vars n mean sd median trimmed mad min max range skew ATSS 1 15 2.82 1.79 3.11 2.91 1.51 -1.23 5.61 6.84 -0.48 Attendance 2 15 7.55 1.44 7.66 7.55 1.08 5.24 9.79 4.55 -0.10 AttendL1 3 15 0.00 1.44 0.11 0.01 1.08 -2.31 2.24 4.55 -0.10 AttendL2 4 15 7.55 0.00 7.55 7.55 0.00 7.55 7.55 0.00 NaN Homogeneity 5 15 0.69 0.00 0.69 0.69 0.00 0.69 0.69 0.00 NaN kurtosis se ATSS -0.38 0.46 Attendance -1.27 0.37 AttendL1 -1.27 0.37 AttendL2 NaN 0.00 Homogeneity NaN 0.00 ------------------------------------------------------------ church: O vars n mean sd median trimmed mad min max range skew ATSS 1 15 3.65 0.91 3.75 3.67 0.63 1.71 5.28 3.57 -0.67 Attendance 2 15 7.34 1.53 6.68 7.23 1.31 5.70 10.35 4.64 0.58 AttendL1 3 15 0.00 1.53 -0.65 -0.11 1.31 -1.63 3.01 4.64 0.58 AttendL2 4 15 7.34 0.00 7.34 7.34 0.00 7.34 7.34 0.00 NaN Homogeneity 5 15 0.79 0.00 0.79 0.79 0.00 0.79 0.79 0.00 NaN kurtosis se ATSS 0.11 0.23 Attendance -1.16 0.40 AttendL1 -1.16 0.40 AttendL2 NaN 0.00 Homogeneity NaN 0.00 Tables are produced for each churchs data. Again, because of group-mean centering (CWC) the mean of the ATSSL1 and AttendL1 variables are 0. The values of the ATSSL2 and AttendL1 variables equal the natural metric. These, though, are different for each of the churches. Looking at the correlations between all forms of these variables can further help clarify why the compositional effects approach is useful. #Multilevel level correlation matrix apaTables::apa.cor.table(Lefevor2020[c( &quot;ATSS&quot;, &quot;Attendance&quot;, &quot;AttendL1&quot;, &quot;AttendL2&quot;, &quot;Homogeneity&quot;)], show.conf.interval = FALSE, landscape = TRUE, table.number = 1, filename=&quot;ML_CorMatrix.doc&quot;) The ability to suppress reporting of reporting confidence intervals has been deprecated in this version. The function argument show.conf.interval will be removed in a later version. Table 1 Means, standard deviations, and correlations with confidence intervals Variable M SD 1 2 3 4 1. ATSS 3.32 1.18 2. Attendance 7.52 1.52 .10 [-.03, .23] 3. AttendL1 -0.00 1.48 .12 .98** [-.01, .25] [.97, .98] 4. AttendL2 7.52 0.32 -.10 .21** -.00 [-.23, .03] [.08, .33] [-.13, .13] 5. Homogeneity 1.04 0.25 -.33** .07 .00 .32** [-.44, -.21] [-.07, .19] [-.13, .13] [.19, .43] Note. M and SD are used to represent mean and standard deviation, respectively. Values in square brackets indicate the 95% confidence interval. The confidence interval is a plausible range of population correlations that could have caused the sample correlation (Cumming, 2014). * indicates p &lt; .05. ** indicates p &lt; .01. The AttendL2 (aggregated group means) we created correlates with the Attendance (natural metric) version. However, it has ZERO correlation with the AttendL1 (group-mean centered, CWC) version. This means that it effectively and completely separates within- and between-subjects variance. If we enter these both into the MLM prediction equation, we will completely capture the within- and between-subjects contributions of attendance. The compositional effects approach to representing L1 variables also works well with longitudinal MLM. 2.5.4 Model Building Multilevel modelers often approach model building in a systematic and sequential manner. This approach was true for Lefevor and colleagues (2020) who planned a four staged approach, but stopped after three because it appeared that adding the next term would not result in model improvement. The four planned steps include: Examining an intercept-only model Adding the L1 variables Adding the L2 variables Adding cross-level interactions 2.5.4.1 Model 1: The empty model This preliminary model has several names: unconditional cell means model, one-way ANOVA with random effects, intercept-only model, and empty model. Why? The only variable in the model is the DV. That is, it is a model with no predictors. As you can see in the script below, we are specifying its intercept (~1). The (1 | church) portion of the code indicates there is a random intercept with a fixed mean. That is, the formula acknowledges that the ATSS means will differ across churches. This model will have no slope. That is, each individual score is predicted solely from the mean. In another lecture, I talk about the transition from null hypothesis statistical testing to statistical modeling. In that lecture I reflected on Cummings (2014) notion that even the mean is a model  that it explains something and not others. In this circumstance, the mean is a model! What is, perhaps, unique about this model is that the code below allows the mean to vary across groups. There are two packages (lme4, nlme) that are primarily used for MLM. We are providing the code for both because  although the core features are identical  they are slightly different. The lmerTest package offers some handy follow-up tests that help us understand our results. Finally, the tab_model() function from the sjPlot package will help create a table that is readily usable in an APA style journal article. library(lme4) Mod1 &lt;- lmer(ATSS ~1 + (1 | church), REML = FALSE, data = Lefevor2020) summary(Mod1) Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [lmerModLmerTest] Formula: ATSS ~ 1 + (1 | church) Data: Lefevor2020 AIC BIC logLik deviance df.resid 694.7 705.0 -344.4 688.7 222 Scaled residuals: Min 1Q Median 3Q Max -3.9130 -0.6410 0.0392 0.5764 2.5252 Random effects: Groups Name Variance Std.Dev. church (Intercept) 0.2673 0.5171 Residual 1.1299 1.0630 Number of obs: 225, groups: church, 15 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 3.3214 0.1511 15.0000 21.98 0.000000000000803 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 AIC(Mod1) # request AIC [1] 694.73 BIC(Mod1) # request BIC [1] 704.9783 library(nlme) ModB1 &lt;- lme(ATSS ~ 1, random = ~ 1|church, method=&quot;ML&quot;, na.action = na.omit, data = Lefevor2020) summary(ModB1) Linear mixed-effects model fit by maximum likelihood Data: Lefevor2020 AIC BIC logLik 694.73 704.9783 -344.365 Random effects: Formula: ~1 | church (Intercept) Residual StdDev: 0.5170587 1.062978 Fixed effects: ATSS ~ 1 Value Std.Error DF t-value p-value (Intercept) 3.321371 0.1514833 210 21.92566 0 Standardized Within-Group Residuals: Min Q1 Med Q3 Max -3.91296264 -0.64096244 0.03922427 0.57637964 2.52520439 Number of Observations: 225 Number of Groups: 15 anova(ModB1) # request F-tests for fixed effects numDF denDF F-value p-value (Intercept) 1 210 480.7347 &lt;.0001 library(lmerTest) ranova(Mod1) # request test of random effects ANOVA-like table for random-effects: Single term deletions Model: ATSS ~ (1 | church) npar logLik AIC LRT Df Pr(&gt;Chisq) &lt;none&gt; 3 -344.37 694.73 (1 | church) 2 -356.89 717.79 25.06 1 0.0000005558 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 confint(Mod1) # request test of random effects (variance displayed as SD) Computing profile confidence intervals ... 2.5 % 97.5 % .sig01 0.3231248 0.8347723 .sigma 0.9688860 1.1733458 (Intercept) 3.0051108 3.6376320 # Extract Variances to compute R^2 var_table = as.data.frame(VarCorr(Mod1)) Mod1_var_tot = var_table[1,&#39;vcov&#39;] + var_table[2,&#39;vcov&#39;] # var_table[1,&#39;vcov&#39;] = L1 var; var_table[2,&#39;vcov&#39;] = L2 var; library(sjPlot) Warning: package &#39;sjPlot&#39; was built under R version 4.0.5 Learn more about sjPlot with &#39;browseVignettes(&quot;sjPlot&quot;)&#39;. tab_model(Mod1, ModB1, p.style = &quot;numeric&quot;, show.ci = FALSE, show.se = TRUE, show.df = FALSE, show.re.var = TRUE, show.aic = TRUE, show.dev = TRUE, use.viewer = TRUE, dv.labels = c(&quot;Mod1&quot;, &quot;ModB1&quot;)) Mod1 ModB1 Predictors Estimates std. Error p Estimates std. Error p (Intercept) 3.32 0.15 &lt;0.001 3.32 0.15 &lt;0.001 Random Effects 2 1.13 1.13 00 0.27 church 0.27 church ICC 0.19 0.19 N 15 church 15 church Observations 225 225 Marginal R2 / Conditional R2 0.000 / 0.191 0.000 / 0.191 Deviance 688.730 688.730 AIC 694.730 694.730 #can swap this statement with the &quot;file = &quot;TabMod_Table&quot;&quot; to get Viewer output or the outfile that you can open in Word #file = &quot;TabMod_Table.doc&quot; It is customary to report MLM models side-by-side for comparison. In this first run, I have extracted the intercept-only models from both the lmer() and nlme() runs to show that the results are identical. In subsequent runs, I will pull from the lmer() models. The unconditional cell means model is equivalent to a one-factor random effects ANOVA of attitudes toward same-sex sexuality as the sole factor; the 15 churches become the 15 levels of the churches factor. With the plot_model() function in sjPlot, we can plot the random effects. For this intercept-only model, we see the mean and range of the ATSS variable library(sjPlot) sjPlot::plot_model (Mod1, type=&quot;re&quot;) Warning in checkMatrixPackageVersion(): Package version inconsistency detected. TMB was built with Matrix version 1.3.2 Current Matrix version is 1.2.18 Please re-install &#39;TMB&#39; from source using install.packages(&#39;TMB&#39;, type = &#39;source&#39;) or ask CRAN for a binary version of &#39;TMB&#39; matching CRAN&#39;s &#39;Matrix&#39; package Focusing on the information in viewer, we can first check to see if things look right. We know we have 15 churches, each with 15 observations (225), so our data is reading correctly. The top of the output includes our fixed effects. In this case, we have only the intercept, its standard error, and p value. We see that across all individuals in all churches, the mean (the grand mean) of ATSS is 3.32 (this is consistent with the M we saw in descriptives). The values of fixed effects do not vary between L2 units. The tab_model viewer is very customizable; we can ask for different features. The section of random effects is different from OLS. Random effects include variance components; these are reported here. \\(\\sigma^{2}\\) is within-church variance; the pooled scatter of each individuals response around the churchs mean. \\(\\tau _{00}\\) is between-church variance; the scatter of each churchs data around the grand mean. The intraclass correlation coefficient (ICC) describes the proportion of variance that lies between churches. It is the essential piece of data that we need from this model. Because the total variation in Y is just the sum of the within- and between- church variance components, we could have calculated this value from \\(\\sigma^{2}\\) and \\(\\tau _{00}\\). Yet, it is handy that the lmer() function does it or us. .27/(1.13+.27) [1] 0.1928571 The ICC value of 0.19 means that 19% of the total variation in attitudes toward same-sex sexuality is attributable to differences between churches. The balance 1.00 - .19 [1] 0.81 (81%) is attributable to within-church variation (or differences in people). We will monitor these variance components to see if the terms we have added reduce the variance. They can provide some sort of guide as to whether the remaining/unaccounted for variance is within-groups (where an L1 variable could help) or between-groups (where an L2 variable might be indicated). As they approach zero, it could be there is nothing left to explain. Marginal \\(R^2\\) provides the variance provided only by the fixed effects. Conditional \\(R^2\\) provides the variance provided by both the fixed and random effects (i.e., the mean random effect variances). Thus, the conditional \\(R^2\\) is appropriate or mixed models with random slopes or nested random effects. Already, without any predictors in the model, we have accounted for 19% of the variance. How is this possible? Our empty model did include the clustering/nesting in churches. This is a random effect. The deviance statistic compares log-likelihood statistics for two models at a time: (a) the current model and (b) a saturated model (e.g., a more general model that fits the sample data perfectly). Deviance quantifies how much worse the current model is in comparison to the best possible model. The deviance is identical to the residual sums of squares used in regression. While you cannot directly interpret any particular deviance statistic, you can compare nested models; the smaller value wins. The deviance statistic has a number of conditions. After we evaluate several models, we can formally test to if the decrease in deviance statistic is statistically significant. The AIC is another fit index. The AIC (Akaike Information Criteria) allows the comparison of the relative goodness of fit of models that are not nested. That is, they can involve different sets of parameters. Like the deviance statistic, the AIC is based on the log-likelihood statistic. Instead of using the LL itself, the AIC penalizes (e.g., decreases) the LL based on the number of parameters. Why? Adding parameters (even if they have no effect) will increase the LL statistic and decrease the deviance statistic. As long as two models are fit to the identical same set of data, the AICs can be compared. The model with the smaller information critera wins. There are no established criteria for determining how large the difference is for it to matter. 2.5.4.2 Model 2: Adding the L1 predictor When we add the L1 predictor(s), we add them in their group-mean centered (CWC) form. In our specific research question, we are asking, \"What effect does an individuals church attendance (relative to the attendance of others at the same church) have on an individuals attitudes toward same-sex sexuality (homonegativity)? We update our script by: Renaming the object (Im changing from Mod1 to Mod2), including all the places it is used. Adding the L1 variable into the lmer() models Adding Mod2 to the anova() function (this will let us know if the models are statistically significantly different from each other) Replacing ModB1 with Mod2 in the tab_model() function # MODEL 2 Mod2 &lt;- lmer(ATSS ~ AttendL1 + (1 | church), REML=FALSE, data = Lefevor2020) summary(Mod2) Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [lmerModLmerTest] Formula: ATSS ~ AttendL1 + (1 | church) Data: Lefevor2020 AIC BIC logLik deviance df.resid 692.5 706.2 -342.3 684.5 221 Scaled residuals: Min 1Q Median 3Q Max -4.1385 -0.6440 0.0700 0.6112 2.4747 Random effects: Groups Name Variance Std.Dev. church (Intercept) 0.2688 0.5185 Residual 1.1075 1.0524 Number of obs: 225, groups: church, 15 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 3.32137 0.15115 15.00000 21.975 0.000000000000803 *** AttendL1 0.09763 0.04738 210.00000 2.061 0.0406 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) AttendL1 0.000 AIC(Mod2) # request AIC [1] 692.5259 BIC(Mod2) # request BIC [1] 706.1903 ModB2 &lt;- lme(ATSS ~ AttendL1, random = ~ 1|church, method=&quot;ML&quot;, na.action = na.omit, data =Lefevor2020) summary(ModB2) Linear mixed-effects model fit by maximum likelihood Data: Lefevor2020 AIC BIC logLik 692.5259 706.1903 -342.2629 Random effects: Formula: ~1 | church (Intercept) Residual StdDev: 0.5185005 1.052391 Fixed effects: ATSS ~ AttendL1 Value Std.Error DF t-value p-value (Intercept) 3.321371 0.15182255 209 21.876668 0.0000 AttendL1 0.097630 0.04758854 209 2.051538 0.0415 Correlation: (Intr) AttendL1 0 Standardized Within-Group Residuals: Min Q1 Med Q3 Max -4.13849479 -0.64398455 0.07003128 0.61124359 2.47473671 Number of Observations: 225 Number of Groups: 15 anova(Mod2) # request F-tests for fixed effects Type III Analysis of Variance Table with Satterthwaite&#39;s method Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F) AttendL1 4.7032 4.7032 1 210 4.2466 0.04056 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ranova(Mod2) # request test of random effects ANOVA-like table for random-effects: Single term deletions Model: ATSS ~ AttendL1 + (1 | church) npar logLik AIC LRT Df Pr(&gt;Chisq) &lt;none&gt; 4 -342.26 692.53 (1 | church) 3 -355.20 716.40 25.873 1 0.0000003647 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 confint(Mod2) # request test of random effects (variance displayed as SD) Computing profile confidence intervals ... 2.5 % 97.5 % .sig01 0.325488416 0.8356621 .sigma 0.959236271 1.1616597 (Intercept) 3.005111274 3.6376316 AttendL1 0.004347046 0.1909124 DevM2 &lt;- anova(Mod1, Mod2) # Extract Variances to compute R^2 var_table = as.data.frame(VarCorr(Mod2)) Mod2_var_tot = var_table[1,&#39;vcov&#39;] + var_table[2,&#39;vcov&#39;] # var_table[1,&#39;vcov&#39;] = L1 var; var_table[2,&#39;vcov&#39;] = L2 var; tab_model(Mod1, Mod2, p.style = &quot;numeric&quot;, show.ci = FALSE, show.df = FALSE, show.re.var = TRUE, show.aic = TRUE, show.dev = TRUE, use.viewer = TRUE, dv.labels = c(&quot;Mod1&quot;, &quot;Mod2&quot;)) Mod1 Mod2 Predictors Estimates p Estimates p (Intercept) 3.32 &lt;0.001 3.32 &lt;0.001 AttendL1 0.10 0.039 Random Effects 2 1.13 1.11 00 0.27 church 0.27 church ICC 0.19 0.20 N 15 church 15 church Observations 225 225 Marginal R2 / Conditional R2 0.000 / 0.191 0.015 / 0.207 Deviance 688.730 684.526 AIC 694.730 692.526 #can swap this statement with the &quot;file = &quot;TabMod_Table&quot;&quot; to get Viewer output or the outfile that you can open in Word #file = &quot;TabMod_Table.doc&quot; Looking at the Viewer we can look a the models side by side. We observe: There is now a row that includes our AttendL1 predictor. This is a statistically significant predictor. The value of the intercept is interpreted as meaning the ATSS value when all other predictors are 0.00. When an individual (relative to others in their church) increases church attendance by 1 unit, ATSS scores increase by 0.10 units. \\(\\sigma^{2}\\) is an indicator of within-church variance. This value has declined (1.13 to 1.11). Given that we added an L1 (within-church) variable, this is sensible. Because there is within-church variance remaining, we might consider adding another L1 variable. \\(\\tau _{00}\\) is an indicator of between-group variance. This value remains constant at 0.27. Given that AttendL1 was a within-church variable, this is sensible. Because there is between-church variance remaining, we are justified in proceeding to adding L2 variables. The ICC has nudged up, indicating that 20% of the remaining (unaccounted for) variance is between groups. Marginal \\(R^2\\), the variance attributed to the fixed effects (in this case, the AttendL1 variable) has increased a smidge. Similarly, Conditional \\(R^2\\), the variance attributed to both the fixed and random effects has nudged upward. AIC values that are lower indicate a better fitting model. There is no formal way to compare these values, but we see that the Mod2 value is a little lower. If we meet the requirements to do so (listed below) we can formally evaluate the decrease of the deviance statistic by looking at the ANOVA model comparison we specified. The requirements include: Identical dataset; there can be no missing or additional observations or variables. The model must be nested within the other. Every parameter must be in both models; the difference is in the constraints. If we use FML (we did when we set REML = FALSE), a deviance comparison describes the fit of the entire model (both fixed and random effects). Thus, deviance statistics test hypotheses about any combination of parameters, fixed effects, or variance components. ed. DevM2 Data: Lefevor2020 Models: Mod1: ATSS ~ 1 + (1 | church) Mod2: ATSS ~ AttendL1 + (1 | church) npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) Mod1 3 694.73 704.98 -344.37 688.73 Mod2 4 692.53 706.19 -342.26 684.53 4.2042 1 0.04032 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Deviance statistics can be formally with a chi-square test. The new value is subtracted from the older value. If the difference is greater than the test critical value associated with the change in degrees of freedom, then the model with the lower deviance value is statistically significantly improved. Our deviance values differed by 4.20 units and this was a statistically significant differnce (p = .040). Plots can help us further understand what is happening. The pred (predicted values) type of plot from sjPlot echoes statistically significant, positive, fixed effect result of individual church attendance (relative to their church attendance) on ATSS (homonegativity). sjPlot::plot_model (Mod2, type=&quot;pred&quot;, terms= c(&quot;AttendL1&quot;)) MLM is a little different than other statistics in that our evaluation of the statistical assumptions continues through the evaluative process. The diagnostic plots (type = diag) provide a check of the model assumptions. Each of the plots provides some guidance of how to interpret them to see if we have violated the assumptions. In the QQ plots, the points generally track along the lines. In the non-normality of residuals, our distribution approximates the superimposed normal curve. In the homoscedasticity plot, the points are scattered above/blow the line in a reasonably equal amounts with random spread. sjPlot::plot_model (Mod2, type=&quot;diag&quot;) [[1]] `geom_smooth()` using formula &#39;y ~ x&#39; [[2]] [[2]]$church `geom_smooth()` using formula &#39;y ~ x&#39; [[3]] [[4]] `geom_smooth()` using formula &#39;y ~ x&#39; With the plot_model() function in sjPlot, we can plot the random effects. For this intercept-only model, we see the mean and range of the ATSS variable. Summarizing what we learned in Mod2: An individuals church attendance (relative to others in their church) has a significant effect on homonegativity. The addition of this L1 variable accounted for a little of the within-church variance, but there is justification for adding additional L1 variables. There appears to be between-church variance. Thus, adding L2 variables is justified. The L1 model is an improvement over the empty model. Although Lefevor and colleagues (2020) included more L1 variables (you can choose one or more of them for practice), because the purpose of this is instructional, we will proceed by adding two, L2 variables. The first is the aggregate form of church attendance (AttendL2), the second is an exclusive L2 variable, homogeneity (proportion of Black congregants). 2.5.4.3 Model 3: Adding the L2 predictors # MODEL 3 Mod3 &lt;- lmer(ATSS ~ AttendL1 + AttendL2 + Homogeneity + (1 | church), REML=FALSE, data = Lefevor2020) summary(Mod3) Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [lmerModLmerTest] Formula: ATSS ~ AttendL1 + AttendL2 + Homogeneity + (1 | church) Data: Lefevor2020 AIC BIC logLik deviance df.resid 687.5 708.0 -337.8 675.5 219 Scaled residuals: Min 1Q Median 3Q Max -4.4350 -0.6238 0.0782 0.6362 2.2297 Random effects: Groups Name Variance Std.Dev. church (Intercept) 0.1141 0.3378 Residual 1.1075 1.0524 Number of obs: 225, groups: church, 15 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 4.85555 2.70843 15.00000 1.793 0.09320 . AttendL1 0.09763 0.04738 210.00000 2.061 0.04056 * AttendL2 0.01658 0.37518 15.00000 0.044 0.96533 Homogeneity -1.59347 0.47613 15.00000 -3.347 0.00441 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) AttnL1 AttnL2 AttendL1 0.000 AttendL2 -0.984 0.000 Homogeneity 0.147 0.000 -0.317 AIC(Mod3) # request AIC [1] 687.5166 BIC(Mod3) # request BIC [1] 708.0132 ModB3 &lt;- lme(ATSS ~ AttendL1 + AttendL2 + Homogeneity, random = ~ 1|church, method=&quot;ML&quot;, na.action = na.omit, data =Lefevor2020) summary(Mod3) Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [lmerModLmerTest] Formula: ATSS ~ AttendL1 + AttendL2 + Homogeneity + (1 | church) Data: Lefevor2020 AIC BIC logLik deviance df.resid 687.5 708.0 -337.8 675.5 219 Scaled residuals: Min 1Q Median 3Q Max -4.4350 -0.6238 0.0782 0.6362 2.2297 Random effects: Groups Name Variance Std.Dev. church (Intercept) 0.1141 0.3378 Residual 1.1075 1.0524 Number of obs: 225, groups: church, 15 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 4.85555 2.70843 15.00000 1.793 0.09320 . AttendL1 0.09763 0.04738 210.00000 2.061 0.04056 * AttendL2 0.01658 0.37518 15.00000 0.044 0.96533 Homogeneity -1.59347 0.47613 15.00000 -3.347 0.00441 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) AttnL1 AttnL2 AttendL1 0.000 AttendL2 -0.984 0.000 Homogeneity 0.147 0.000 -0.317 anova(Mod3) # request F-tests for fixed effects Type III Analysis of Variance Table with Satterthwaite&#39;s method Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F) AttendL1 4.7032 4.7032 1 210 4.2466 0.040562 * AttendL2 0.0022 0.0022 1 15 0.0020 0.965326 Homogeneity 12.4049 12.4049 1 15 11.2005 0.004415 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ranova(Mod3) # request test of random effects ANOVA-like table for random-effects: Single term deletions Model: ATSS ~ AttendL1 + AttendL2 + Homogeneity + (1 | church) npar logLik AIC LRT Df Pr(&gt;Chisq) &lt;none&gt; 6 -337.76 687.52 (1 | church) 5 -341.78 693.57 8.0497 1 0.004551 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 confint(Mod3) # request test of random effects (variance displayed as SD) Computing profile confidence intervals ... 2.5 % 97.5 % .sig01 0.153249528 0.5914827 .sigma 0.959236807 1.1616599 (Intercept) -0.811596834 10.5226949 AttendL1 0.004347107 0.1909123 AttendL2 -0.768446894 0.8016149 Homogeneity -2.589725095 -0.5972141 devM3 &lt;- anova(Mod1, Mod2, Mod3) tab_model(Mod1, Mod2, Mod3, p.style = &quot;numeric&quot;, show.ci = FALSE, show.df = FALSE, show.re.var = TRUE, show.aic = TRUE, show.dev = TRUE, use.viewer = TRUE, dv.labels = c(&quot;Mod1&quot;, &quot;Mod2&quot;, &quot;Mod3&quot;)) Mod1 Mod2 Mod3 Predictors Estimates p Estimates p Estimates p (Intercept) 3.32 &lt;0.001 3.32 &lt;0.001 4.86 0.073 AttendL1 0.10 0.039 0.10 0.039 AttendL2 0.02 0.965 Homogeneity -1.59 0.001 Random Effects 2 1.13 1.11 1.11 00 0.27 church 0.27 church 0.11 church ICC 0.19 0.20 0.09 N 15 church 15 church 15 church Observations 225 225 225 Marginal R2 / Conditional R2 0.000 / 0.191 0.015 / 0.207 0.126 / 0.208 Deviance 688.730 684.526 675.517 AIC 694.730 692.526 687.517 #can swap this statement with the &quot;file = &quot;TabMod_Table&quot;&quot; to get Viewer output or the outfile that you can open in Word #file = &quot;TabMod_Table.doc&quot; Again, looking at the Viewer we can look at the three models side by side. We observe: The intercept changes values. The value of 4.86 is the mean when AttendL1 is average for its church (recall we mean centered it so that 0.0 is the church mean), AttendL2 is the mean across churches, and racial homogeneity is 0.00. There is now a row that includes our two L2 predictors: AttendL2 (aggregate of AttendL1) and Homogeneity (racial homogeneity of each church). AttendL1 remains significant (with the values of the \\(B\\) and \\(p\\) remaining the same; but the L2 aggregate does not add in a significant manner AttendL2 is not a significant predictor. Homogeneity is a significant predictor. For every 1 unit increase in racial homogeneity, ATSS values decrease (i.e., there is a decrease in homonegativity). \\(\\sigma^{2}\\) is an indicator of within-church variance. This value declined from Mod1 to Mod2 (1.13 to 1.11), but has held constant. Given that we added an L2 (between-church) variables, this is sensible. Because there is within-church variance remaining, we might consider adding another L1 variable. \\(\\tau _{00}\\) is an indicator of between-group variance. This value dropped from 0.27 to .11. Given that AttendL2 and Homogeneity were between-church variables, this is sensible. There is some between church variance remaining. The ICC dropped, indicating that 9% of the remaining (unaccounted for) variance is between groups. Marginal \\(R^2\\), the variance attributed to the fixed effects (in this case, the AttendL1 variable) increased to 13%. Similarly, Conditional \\(R^2\\), the variance attributed to both the fixed and random effects increased to 21%. AIC values that are lower indicate a better fitting model. There is no formal way to compare these values, but we see that the Mod3 value is lower. We can call up the object we created to formally compare the deviance statistics. devM3 Data: Lefevor2020 Models: Mod1: ATSS ~ 1 + (1 | church) Mod2: ATSS ~ AttendL1 + (1 | church) Mod3: ATSS ~ AttendL1 + AttendL2 + Homogeneity + (1 | church) npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) Mod1 3 694.73 704.98 -344.37 688.73 Mod2 4 692.53 706.19 -342.26 684.53 4.2042 1 0.04032 * Mod3 6 687.52 708.01 -337.76 675.52 9.0093 2 0.01106 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 This repeats the comparison of Mod2 to Mod1 (it was significant). The comparison of Mod3 to Mod2 suggests even more statistically significant improvement. Specifically, \\(\\chi ^{2}(2) = 9.009, p = .011\\) Lets look at plots. With three predictors, we can examine each of their relations with the dependent variable. Of course they are consistent with the fixed effects: as individual church attendance (relative to others in their church) increases, homonegativity increases, overall church attendance has no apparent effect on homonegativity, and as racial homogeneity increases, homonegativity decreases. sjPlot::plot_model (Mod3, type=&quot;pred&quot;) $AttendL1 $AttendL2 $Homogeneity Because the next phase of model building will include cross-level interactions, lets display this mode by examining the relationship between individual attendance and homonegativity, chunked into clusters that let us also examine the influene of church-level attendance and racial homogeneity. This is not a formal test of an interaction; however, I dont sense that there will be interacting effects. sjPlot::plot_model (Mod3, type=&quot;pred&quot;,terms=c(&quot;AttendL1&quot;, &quot;Homogeneity&quot;, &quot;AttendL2&quot;)) Our diagnostic plots continue to support our modeling. In the QQ plots, the points generally track along the lines. In the non-normality of residuals, our distribution approximates the superimposed normal curve. In the homoscedasticity plot, the points are scattered above/blow the line in a reasonably equal amounts with random spread. sjPlot::plot_model (Mod3, type=&quot;diag&quot;) [[1]] `geom_smooth()` using formula &#39;y ~ x&#39; [[2]] [[2]]$church `geom_smooth()` using formula &#39;y ~ x&#39; [[3]] [[4]] `geom_smooth()` using formula &#39;y ~ x&#39; Lefevor and colleagues (Lefevor et al., 2020) had intended to include interaction terms. However, because only one predictor was significant at each of the individual and congregational levels, their final model did not include interaction effects. I am guessing they tried it and trimmed it out. We add the interaction term by placing an asterisk between the two variables. There is no need (also no harm in) to enter them separately. 2.5.4.4 Model 4: Adding a cross-level interaction term In multilevel modeling, we have the opportunity to cross the levels (individual, group) when we specify interactions. In this model, we include an interaction between individual attendance and racial homogeneity of the church. # MODEL 4 Mod4 &lt;- lmer(ATSS ~ AttendL2 + AttendL1*Homogeneity +(1 | church), REML=FALSE, data = Lefevor2020) summary(Mod4) Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [lmerModLmerTest] Formula: ATSS ~ AttendL2 + AttendL1 * Homogeneity + (1 | church) Data: Lefevor2020 AIC BIC logLik deviance df.resid 689.5 713.4 -337.7 675.5 218 Scaled residuals: Min 1Q Median 3Q Max -4.4652 -0.6250 0.0838 0.6268 2.2495 Random effects: Groups Name Variance Std.Dev. church (Intercept) 0.1141 0.3378 Residual 1.1073 1.0523 Number of obs: 225, groups: church, 15 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 4.85555 2.70843 15.00000 1.793 0.09320 . AttendL2 0.01658 0.37518 15.00000 0.044 0.96533 AttendL1 0.14098 0.21674 210.00000 0.650 0.51612 Homogeneity -1.59347 0.47613 15.00000 -3.347 0.00441 ** AttendL1:Homogeneity -0.04061 0.19816 210.00000 -0.205 0.83782 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) AttnL2 AttnL1 Hmgnty AttendL2 -0.984 AttendL1 0.000 0.000 Homogeneity 0.147 -0.317 0.000 AttndL1:Hmg 0.000 0.000 -0.976 0.000 AIC(Mod4) # request AIC [1] 689.4746 BIC(Mod4) # request BIC [1] 713.3873 ModB3 &lt;- lme(ATSS ~ AttendL2 + AttendL1*Homogeneity, random = ~ 1|church, method=&quot;ML&quot;, na.action = na.omit, data =Lefevor2020) summary(Mod4) Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [lmerModLmerTest] Formula: ATSS ~ AttendL2 + AttendL1 * Homogeneity + (1 | church) Data: Lefevor2020 AIC BIC logLik deviance df.resid 689.5 713.4 -337.7 675.5 218 Scaled residuals: Min 1Q Median 3Q Max -4.4652 -0.6250 0.0838 0.6268 2.2495 Random effects: Groups Name Variance Std.Dev. church (Intercept) 0.1141 0.3378 Residual 1.1073 1.0523 Number of obs: 225, groups: church, 15 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 4.85555 2.70843 15.00000 1.793 0.09320 . AttendL2 0.01658 0.37518 15.00000 0.044 0.96533 AttendL1 0.14098 0.21674 210.00000 0.650 0.51612 Homogeneity -1.59347 0.47613 15.00000 -3.347 0.00441 ** AttendL1:Homogeneity -0.04061 0.19816 210.00000 -0.205 0.83782 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) AttnL2 AttnL1 Hmgnty AttendL2 -0.984 AttendL1 0.000 0.000 Homogeneity 0.147 -0.317 0.000 AttndL1:Hmg 0.000 0.000 -0.976 0.000 anova(Mod4) # request F-tests for fixed effects Type III Analysis of Variance Table with Satterthwaite&#39;s method Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F) AttendL2 0.0022 0.0022 1 15 0.0020 0.965326 AttendL1 0.4685 0.4685 1 210 0.4231 0.516125 Homogeneity 12.4024 12.4024 1 15 11.2005 0.004415 ** AttendL1:Homogeneity 0.0465 0.0465 1 210 0.0420 0.837816 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ranova(Mod4) # request test of random effects ANOVA-like table for random-effects: Single term deletions Model: ATSS ~ AttendL2 + AttendL1 + Homogeneity + (1 | church) + AttendL1:Homogeneity npar logLik AIC LRT Df Pr(&gt;Chisq) &lt;none&gt; 7 -337.74 689.47 (1 | church) 6 -341.76 695.53 8.0536 1 0.004541 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 confint(Mod4) # request test of random effects (variance displayed as SD) Computing profile confidence intervals ... 2.5 % 97.5 % .sig01 0.1533133 0.5914950 .sigma 0.9591409 1.1615437 (Intercept) -0.8115834 10.5226817 AttendL2 -0.7684450 0.8016131 AttendL1 -0.2857791 0.5677291 Homogeneity -2.5897227 -0.5972164 AttendL1:Homogeneity -0.4307735 0.3495523 devM4 &lt;- anova(Mod1, Mod2, Mod3, Mod4) tab_model(Mod1, Mod2, Mod3, Mod4, p.style = &quot;numeric&quot;, show.ci = FALSE, show.df = FALSE, show.re.var = TRUE, show.aic = TRUE, show.dev = TRUE, use.viewer = TRUE, dv.labels = c(&quot;Mod1&quot;, &quot;Mod2&quot;, &quot;Mod3&quot;, &quot;Mod4&quot;)) Mod1 Mod2 Mod3 Mod4 Predictors Estimates p Estimates p Estimates p Estimates p (Intercept) 3.32 &lt;0.001 3.32 &lt;0.001 4.86 0.073 4.86 0.073 AttendL1 0.10 0.039 0.10 0.039 0.14 0.515 AttendL2 0.02 0.965 0.02 0.965 Homogeneity -1.59 0.001 -1.59 0.001 AttendL1 * Homogeneity -0.04 0.838 Random Effects 2 1.13 1.11 1.11 1.11 00 0.27 church 0.27 church 0.11 church 0.11 church ICC 0.19 0.20 0.09 0.09 N 15 church 15 church 15 church 15 church Observations 225 225 225 225 Marginal R2 / Conditional R2 0.000 / 0.191 0.015 / 0.207 0.126 / 0.208 0.126 / 0.208 Deviance 688.730 684.526 675.517 675.475 AIC 694.730 692.526 687.517 689.475 #can swap this statement with the &quot;file = &quot;TabMod_Table&quot;&quot; to get Viewer output or the outfile that you can open in Word #file = &quot;TabMod_Table.doc&quot; Again, looking at the Viewer we can look at the four models side by side. We observe: Although the B weight increases from 0.10 to 0.14, we lose the significance associated with AttendL1. The AttendL1*Homogeneity interaction effect is non-significant. There are no changes in our random effects (e.g., \\(\\sigma^{2}\\) and \\(\\tau _{00}\\), nor the Marginal and Conditional \\(R^2\\) The AIC value increases  meaning that Mod4 is worse than Mod3. Examining the formal comparison of Mod4 to Mod3 suggests no statistically significant difference (\\(\\chi_{2}(1) = 0.838\\)). devM4 Data: Lefevor2020 Models: Mod1: ATSS ~ 1 + (1 | church) Mod2: ATSS ~ AttendL1 + (1 | church) Mod3: ATSS ~ AttendL1 + AttendL2 + Homogeneity + (1 | church) Mod4: ATSS ~ AttendL2 + AttendL1 * Homogeneity + (1 | church) npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) Mod1 3 694.73 704.98 -344.37 688.73 Mod2 4 692.53 706.19 -342.26 684.53 4.2042 1 0.04032 * Mod3 6 687.52 708.01 -337.76 675.52 9.0093 2 0.01106 * Mod4 7 689.47 713.39 -337.74 675.47 0.0420 1 0.83763 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Not surprisingly, our resultant models are consistent with the peek we took at an interaction term after Mod3. sjPlot::plot_model (Mod4, type=&quot;pred&quot;,terms=c(&quot;AttendL1&quot;, &quot;Homogeneity&quot;, &quot;AttendL2&quot;), mdrt.values = &quot;meansd&quot;) Another way to view this is to request the int (interaction) model type. sjPlot::plot_model (Mod4, type=&quot;int&quot;, terms=c(&quot;AttendL1&quot;, &quot;AttendL2&quot;, &quot;Homogeneity&quot;), mdrt.values = &quot;meansd&quot;) Even though the addition of the interaction term did not improve our model, it does not look like it harmed it. These diagnostics remain consistent with those we saw before. sjPlot::plot_model (Mod4, type=&quot;diag&quot;) [[1]] `geom_smooth()` using formula &#39;y ~ x&#39; [[2]] [[2]]$church `geom_smooth()` using formula &#39;y ~ x&#39; [[3]] [[4]] `geom_smooth()` using formula &#39;y ~ x&#39; 2.5.5 Final Model Our analysis is consistent with Lefevor and colleagues decision to stop after Mod3. Therefore I will trim the interaction term out. # MODEL 3 Mod3 &lt;- lmer(ATSS ~ AttendL1 + AttendL2 + Homogeneity + (1 | church), REML=FALSE, data = Lefevor2020) summary(Mod3) Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [lmerModLmerTest] Formula: ATSS ~ AttendL1 + AttendL2 + Homogeneity + (1 | church) Data: Lefevor2020 AIC BIC logLik deviance df.resid 687.5 708.0 -337.8 675.5 219 Scaled residuals: Min 1Q Median 3Q Max -4.4350 -0.6238 0.0782 0.6362 2.2297 Random effects: Groups Name Variance Std.Dev. church (Intercept) 0.1141 0.3378 Residual 1.1075 1.0524 Number of obs: 225, groups: church, 15 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 4.85555 2.70843 15.00000 1.793 0.09320 . AttendL1 0.09763 0.04738 210.00000 2.061 0.04056 * AttendL2 0.01658 0.37518 15.00000 0.044 0.96533 Homogeneity -1.59347 0.47613 15.00000 -3.347 0.00441 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) AttnL1 AttnL2 AttendL1 0.000 AttendL2 -0.984 0.000 Homogeneity 0.147 0.000 -0.317 #AIC(Mod3) # request AIC #BIC(Mod3) # request BIC #ModB3 &lt;- lme(ATSS ~ AttendL1 + AttendL2 + Homogeneity, random = ~ 1|church, method=&quot;ML&quot;, na.action = na.omit, data =Lefevor2020) #summary(Mod3) #anova(Mod3) # request F-tests for fixed effects #ranova(Mod3) # request test of random effects #confint(Mod3) # request test of random effects (variance displayed as SD) devM3 &lt;- anova(Mod1, Mod2, Mod3) tab_model(Mod1, Mod2, Mod3, p.style = &quot;numeric&quot;, show.ci = FALSE, show.df = FALSE, show.re.var = TRUE, show.aic = TRUE, show.dev = TRUE, use.viewer = TRUE, dv.labels = c(&quot;Model 1&quot;, &quot;Model 2&quot;, &quot;Model 3&quot;), file = &quot;Lefevor_Table.doc&quot;) Model 1 Model 2 Model 3 Predictors Estimates p Estimates p Estimates p (Intercept) 3.32 &lt;0.001 3.32 &lt;0.001 4.86 0.073 AttendL1 0.10 0.039 0.10 0.039 AttendL2 0.02 0.965 Homogeneity -1.59 0.001 Random Effects 2 1.13 1.11 1.11 00 0.27 church 0.27 church 0.11 church ICC 0.19 0.20 0.09 N 15 church 15 church 15 church Observations 225 225 225 Marginal R2 / Conditional R2 0.000 / 0.191 0.015 / 0.207 0.126 / 0.208 Deviance 688.730 684.526 675.517 AIC 694.730 692.526 687.517 #can swap this statement with the &quot;file = &quot;TabMod_Table&quot;&quot; to get Viewer output or the outfile that you can open in Word #file = &quot;TabMod_Table.doc&quot; 2.5.6 Oh right, the Formulae Finally, the formulae (yes, plural) Recall the simplicity of the OLS regresion equation with a single predictor: \\[\\hat{Y}_{i} = \\beta_{0} + \\beta_{1}X_{i} + \\epsilon_{i}\\] Where: \\(\\hat{Y}_{i}\\) (the outcome) has a subscript \\(i\\), indicating that it is predicted for each individual. \\(\\beta_{0}\\) is the population intercept \\(\\beta_{1}X_{i}\\) is the population unstandardized regression slope \\(X\\) is a linear predictor of \\(Y\\) \\(\\epsilon_{i}\\) is the random error in prediction for case i Importantly, the intercept and slope are both fixed in a basic linear regression model. You can recognize that the intercept and slope are fixed because they do not include a subscript \\(i\\) or \\(j\\) (as we will see later). The lack of a subscript indicates that these parameters each only take on a single value that is meant to represent the entire population intercept or slope, respectively. Now lets take a look at the most basic multilevel model and compare it to the simple linear regression model above: \\[ Y_{ij} = \\beta_{0j} + \\beta_{1j}X_{ij} + \\epsilon_{ij} \\] Where \\(Y_{ij}\\) outcome measure for individual i in group j \\(X_{ij}\\) is the value of the predictor for individual i in group j \\(\\beta_{0j}\\) is the intercept for group j \\(\\beta_{1j}\\) is the slope for group j \\(\\epsilon_{ij}\\) is the residual Does it look familiar? The only difference in between this MLM equation and the linear regression equation is that the MLM equation contains more subscripts. As you will see, this simple update provides us with much more information. For the purpose of defining the model, lets assume that the subscript \\(j\\) represents a group of individuals. In the multilevel model, \\(i\\) can take on any value in \\((1, ..., N)\\), where \\(N\\) is the number of individuals in the study. The subscript \\(j\\) may take on values in \\((1, ..., J)\\), where \\(J\\) is the number of groups in the study. In this model, recognize that each group is allowed its own unique intercept and slope. You could read the entire model as: The outcome value for person \\(i\\) in group \\(j\\) is equal to the intercept for group \\(j\\), plus the slope for group \\(j\\) multiplied by the x-value for person \\(i\\) in group \\(j\\), plus some error that cannot be explained by the model for person \\(i\\) in group \\(j\\). The errors in \\(\\epsilon_{ij}\\) are typically assumed to be independently and identically distributed \\((iid)\\) ~\\(N(0, \\sigma^2)\\). Level 2 (macro-level) regression equations carry the group structure. \\[\\beta _{0j}=\\gamma _{00}+\\mu _{0j}\\] \\[\\beta _{1j}=\\gamma _{10}+\\mu_{1j}\\] \\(\\beta _{0j}\\) models the differences in the group intercepts, predicting the intercept for group j \\(\\gamma _{00}\\) is the population regression intercept the grand mean \\(\\gamma _{00}\\) assesses how much group j differs from the grand mean a measure of variance \\(\\beta _{1j}\\) models the differences in group slopes \\(\\gamma _{10}\\) is a fixed or constant population slopes \\(u_{1j}\\) assesses the extent to which group js slope differs from the grand slope. \\(\\mu _{0j}\\) and \\(\\mu_{1j}\\) are the residuals from trying to predict the intercepts and slopes, respectively. So far it lwe have treated the L1 and L2 equations are treated separately. We combine them to form a single multilevel regression equation referred to as the mixed model. This is Cohen et al.s (2003) rendition. As you view it, you may wonder what happened to the B- or beta weights. There are some curious traditions in MLM. When modeling nesting in groups, some researchers use the \\(\\gamma\\) (g is for group) and when modeling nesting within people, some researchers use the \\(\\pi\\) (p is for people): \\[Y_{ij}=\\gamma _{10}X_{ij}+\\gamma _{00}+U_{0j}+U_{ij}X_{ij}+r_{ij}\\] 2.5.7 APA Style Writeup In this write-up, please presume that the apa.cor.table of L1 and L2 variables and the tab_model() table (Mod3) we created will serve as the basis for the APA style tables. I would use one of the Mod3 predictions as the graph. Method/Analytic Strategy The nested structure of our data (congregants [L1] nested within churches [L2]), multilevel modeling was appropriate because it allows for (a) the dependent nature of the congregants within their churches and (b) varying numbers of church members within each church. We analyzed the data with the lme4 (v. 1.1-26) in R (v. 4.0.5) using full maximum likelihood. We used a compositional effect (Enders &amp; Tofighi, 2007) approach to center our variables. Specifically, we used group-mean centering (centering within context) for our L1 variables. Calculating their group aggregate, we entered them back into the model as L2 predictors. This allowed each predictor to completely capture within- and between-group variance. Model development and evaluation waas approached in a systematic and sequential manner. This exploratory approach is consistent with recommendations to pursue model generating approaches in complex models (Joreskog, 1993) by first understanding the relatively simpler relations between the variables (e.g., McCoach, 2010; OConnell et al., 2013) and assessing the viability of more complexity based on the results. Accordingly, we began with an intercept-only model. We followed sequentially by entering L1 (Model 2), L2 (Model 3), and a cross-level interaction (Model 4). Throughout we monitored variance components and fit decisions to determine our final model. Results Preliminary Analyses Missing data analysis and managing missing data Bivariate correlations, means, SDs Address assumptions; in MLM this includes linearity homogeneity of variance normal distribution of the models residuals Address any apriorily known limitations and concerns Primary Analyses Table # reports the the bivariate correlations between ATSS/homonegative attitudes and the L1 and L2 predictors. Our first model was an intercept-only, empty, model with ATSS/homonegative attitudes as the dependent variable and no predictors in the model. The intraclass correlation (ICC) suggested that 19% of the variance in homonegative attitudes was between congregations; correspondingly, 81% was within congregations (i.e., between individuals). We added the L1 predictor of individual church attendance in the second model. As shown in Table #, there was a significant effect such that as individual church attendance increased, so did homonegative attitudes. We added the L2 variables of the aggregate form of church attendance and racial homogeneity in our third model. The L2 form of church attendance had a non-significant effect, however racial homogeneity was significant. Specifically, as homogeneity increased, homonegativity decreased; this relationship is illustrated in Figure #. Our fourth model (not shown) included a cross-level interaction between individual church attendance and homogeneity. Because it was non-significant, made no changes in the variance components, and caused the AIC to increase, we trimmed it from the model. Thus, Model 3 is our final model. Further support for this model is noted by the corresponding decreases in \\(\\sigma^{2}\\) and \\(\\tau _{00}\\) when L1 and L2 variables were added, respectively. Additionally, marginal and conditional \\(R^2\\) increased and formal evaluation of the deviance statistic suggested that each addition was a statistically significant improvement. 2.6 Residual and Related Questions ..that you might have; or at least I had, but if had answered them earlier it would have disrupt the flow. STAY TUNED 2.7 Practice Problems The suggested practice problem for this chapter is to conduct a MLM that includes at least one L1 predictor, at least one L2 predictor, and a cross-level interaction. 2.7.1 Problem #1: Rework the research vignette as demonstrated, but change the random seed If this topic feels a bit overwhelming, simply change the random seed in the data simulation, then rework the problem. This should provide minor changes to the data (maybe in the second or third decimal point), but the results will likely be very similar. Assignment Component 1. Assign each variable to the L1 or L2 roles 5 _____ 2. Use a compositional effects approach to centering to group-mean center the L1 variables and then bring back their aggregate as an L2 variable 5 _____ 3. Model 1: empty model 5 _____ 4. Model 2: L1 predictors 5 _____ 5. Model 3: L2 predictors 5 _____ 6. Model 4: A cross-level interaction 5 _____ 7. Create a tab_model table with the final set of models 5 _____ 8. Create a figure to represent the result 5 _____ 9. APA Style writeup 5 _____ 10. Explanation to grader 5 _____ Totals 50 _____ 2.7.2 Problem #2: Rework the research vignette, but swap one or more variables The research vignette analyzes a number of variables, simultaneously. We selected only two for the example. Swap out one or more variables in the multilevel model and compare your solution to the one in the chapter (and/or oNe you mimicked in the journal article). If you wish to increase your probability of finding statistically significant effects, look for hints in Table 2 of the (Lefevor et al., 2020) research article that sources the vignettes by selecting a variable(s) with a significant relationship with your DV. Assignment Component 1. Assign each variable to the L1 or L2 roles 5 _____ 2. Use a compositional effects approach to centering to group-mean center the L1 variables and then bring back their aggregate as an L2 variable 5 _____ 3. Model 1: empty model 5 _____ 4. Model 2: L1 predictors 5 _____ 5. Model 3: L2 predictors 5 _____ 6. Model 4: A cross-level interaction 5 _____ 7. Create a tab_model table with the final set of models 5 _____ 8. Create a figure to represent the result 5 _____ 9. APA Style writeup 5 _____ 10. Explanation to grader 5 _____ Totals 50 _____ 2.7.3 Problem #3: Use other data that is available to you Conduct a multilevel model with data to which you have access. This could include data you simulate on your own or from a published article. Assignment Component 1. Assign each variable to the L1 or L2 roles 5 _____ 2. Use a compositional effects approach to centering to group-mean center the L1 variables and then bring back their aggregate as an L2 variable 5 _____ 3. Model 1: empty model 5 _____ 4. Model 2: L1 predictors 5 _____ 5. Model 3: L2 predictors 5 _____ 6. Model 4: A cross-level interaction 5 _____ 7. Create a tab_model table with the final set of models 5 _____ 8. Create a figure to represent the result 5 _____ 9. APA Style writeup 5 _____ 10. Explanation to grader 5 _____ Totals 50 _____ 2.8 Bonus Track: Image of a filmstrip 2.8.1 Working the Entire Vignette Below is the script that works the entire vignette in the Lefevor et al. (2020) article. library(psych) psych::pairs.panels(Lefevor2020[c(&quot;ATSS&quot;, &quot;Female0&quot;, &quot;Age&quot;, &quot;Education&quot;, &quot;Attendance&quot;, &quot;Homogeneity&quot;)], stars = TRUE) psych::describe(Lefevor2020[c(&quot;ATSS&quot;, &quot;Female0&quot;, &quot;Age&quot;, &quot;Education&quot;, &quot;Attendance&quot;, &quot;Homogeneity&quot;)]) vars n mean sd median trimmed mad min max range skew ATSS 1 225 3.32 1.18 3.43 3.34 1.11 -1.23 6.45 7.69 -0.30 Female0 2 225 0.24 0.43 0.00 0.18 0.00 0.00 1.00 1.00 1.21 Age 3 225 51.78 24.62 52.80 52.15 30.05 6.91 93.76 86.85 -0.11 Education 4 225 4.37 2.35 4.62 4.42 2.76 0.01 8.44 8.43 -0.18 Attendance 5 225 7.52 1.52 7.36 7.47 1.84 5.12 10.35 5.22 0.24 Homogeneity 6 225 1.04 0.25 1.14 1.04 0.34 0.69 1.40 0.71 -0.04 kurtosis se ATSS 0.27 0.08 Female0 -0.54 0.03 Age -1.11 1.64 Education -1.06 0.16 Attendance -1.19 0.10 Homogeneity -1.60 0.02 #Single level correlation matrix apaTables::apa.cor.table(Lefevor2020[c( &quot;ATSS&quot;, &quot;Female0&quot;, &quot;Age&quot;, &quot;Education&quot;, &quot;Attendance&quot;, &quot;Homogeneity&quot;)], show.conf.interval = FALSE, landscape = TRUE, table.number = 1, filename=&quot;CorMatrix.doc&quot;) The ability to suppress reporting of reporting confidence intervals has been deprecated in this version. The function argument show.conf.interval will be removed in a later version. Table 1 Means, standard deviations, and correlations with confidence intervals Variable M SD 1 2 3 4 1. ATSS 3.32 1.18 2. Female0 0.24 0.43 -.04 [-.17, .09] 3. Age 51.78 24.62 .06 -.03 [-.07, .19] [-.16, .10] 4. Education 4.37 2.35 -.07 .12 -.01 [-.20, .06] [-.01, .25] [-.14, .12] 5. Attendance 7.52 1.52 .10 .03 .02 .24** [-.03, .23] [-.10, .16] [-.11, .15] [.11, .36] 6. Homogeneity 1.04 0.25 -.33** .09 -.07 .10 [-.44, -.21] [-.04, .22] [-.19, .07] [-.03, .23] 5 .07 [-.07, .19] Note. M and SD are used to represent mean and standard deviation, respectively. Values in square brackets indicate the 95% confidence interval. The confidence interval is a plausible range of population correlations that could have caused the sample correlation (Cumming, 2014). * indicates p &lt; .05. ** indicates p &lt; .01. library(robumeta) Lefevor2020$ATSSL1 &lt;- as.numeric(group.center(Lefevor2020$ATSS, Lefevor2020$church))#centered within context (group mean centering) Lefevor2020$ATSSL2 &lt;- as.numeric(group.mean(Lefevor2020$ATSS, Lefevor2020$church))#aggregated at group mean Lefevor2020$AttendL1 &lt;- as.numeric(group.center(Lefevor2020$Attendance, Lefevor2020$church))#centered within context (group mean centering) Lefevor2020$AttendL2 &lt;- as.numeric(group.mean(Lefevor2020$Attendance, Lefevor2020$church))#aggregated at group mean Lefevor2020$AgeL1 &lt;- as.numeric(group.center(Lefevor2020$Age, Lefevor2020$church))#centered within context (group mean centering) Lefevor2020$AgeL2 &lt;- as.numeric(group.mean(Lefevor2020$Age, Lefevor2020$church))#aggregated at group mean Lefevor2020$GenderL1 &lt;- as.numeric(group.center(Lefevor2020$Female0, Lefevor2020$church))#centered within context (group mean centering) Lefevor2020$GenderL2 &lt;- as.numeric(group.mean(Lefevor2020$Female0, Lefevor2020$church))#aggregated at group mean Lefevor2020$EducL1 &lt;- as.numeric(group.center(Lefevor2020$Education, Lefevor2020$church))#centered within context (group mean centering) Lefevor2020$EducL2 &lt;- as.numeric(group.mean(Lefevor2020$Education, Lefevor2020$church))#aggregated at group mean CALCULATE L1 AND L2 ATTS #Multilevel level correlation matrix apaTables::apa.cor.table(Lefevor2020[c( &quot;ATSSL1&quot;, &quot;GenderL1&quot;, &quot;AgeL1&quot;, &quot;EducL1&quot;, &quot;AttendL1&quot;, &quot;ATSSL2&quot;,&quot;GenderL2&quot;, &quot;AgeL2&quot;, &quot;EducL2&quot;, &quot;AttendL2&quot;, &quot;Homogeneity&quot;)], show.conf.interval = FALSE, landscape = TRUE, table.number = 1, filename=&quot;ML_CorMatrix.doc&quot;) The ability to suppress reporting of reporting confidence intervals has been deprecated in this version. The function argument show.conf.interval will be removed in a later version. Table 1 Means, standard deviations, and correlations with confidence intervals Variable M SD 1 2 3 4 1. ATSSL1 0.00 1.03 2. GenderL1 0.00 0.41 -.01 [-.14, .12] 3. AgeL1 0.00 24.07 .05 -.04 [-.08, .18] [-.17, .09] 4. EducL1 -0.00 2.25 .01 .09 .00 [-.12, .14] [-.04, .22] [-.13, .13] 5. AttendL1 -0.00 1.48 .14* .02 .04 .22** [.01, .27] [-.11, .15] [-.09, .17] [.09, .34] 6. ATSSL2 3.32 0.59 .00 .00 -.00 -.00 [-.13, .13] [-.13, .13] [-.13, .13] [-.13, .13] 7. GenderL2 0.24 0.13 -.00 -.00 -.00 -.00 [-.13, .13] [-.13, .13] [-.13, .13] [-.13, .13] 8. AgeL2 51.78 5.19 .00 -.00 -.00 .00 [-.13, .13] [-.13, .13] [-.13, .13] [-.13, .13] 9. EducL2 4.37 0.69 -.00 .00 -.00 .00 [-.13, .13] [-.13, .13] [-.13, .13] [-.13, .13] 10. AttendL2 7.52 0.32 -.00 .00 .00 -.00 [-.13, .13] [-.13, .13] [-.13, .13] [-.13, .13] 11. Homogeneity 1.04 0.25 -.00 .00 .00 -.00 [-.13, .13] [-.13, .13] [-.13, .13] [-.13, .13] 5 6 7 8 9 10 -.00 [-.13, .13] -.00 -.17** [-.13, .13] [-.30, -.04] .00 .15* .22** [-.13, .13] [.02, .28] [.10, .34] .00 -.51** .39** -.15* [-.13, .13] [-.60, -.41] [.27, .49] [-.27, -.02] -.00 -.20** .16* -.32** .45** [-.13, .13] [-.33, -.08] [.03, .28] [-.44, -.20] [.34, .55] .00 -.67** .31** -.31** .34** .32** [-.13, .13] [-.74, -.59] [.19, .43] [-.42, -.19] [.22, .45] [.19, .43] Note. M and SD are used to represent mean and standard deviation, respectively. Values in square brackets indicate the 95% confidence interval. The confidence interval is a plausible range of population correlations that could have caused the sample correlation (Cumming, 2014). * indicates p &lt; .05. ** indicates p &lt; .01. library(lme4) ATSSm1 &lt;- lmer(ATSS ~1 + (1 | church), REML = FALSE, data = Lefevor2020) summary(ATSSm1) Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [lmerModLmerTest] Formula: ATSS ~ 1 + (1 | church) Data: Lefevor2020 AIC BIC logLik deviance df.resid 694.7 705.0 -344.4 688.7 222 Scaled residuals: Min 1Q Median 3Q Max -3.9130 -0.6410 0.0392 0.5764 2.5252 Random effects: Groups Name Variance Std.Dev. church (Intercept) 0.2673 0.5171 Residual 1.1299 1.0630 Number of obs: 225, groups: church, 15 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 3.3214 0.1511 15.0000 21.98 0.000000000000803 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 AIC(ATSSm1) # request AIC [1] 694.73 BIC(ATSSm1) # request BIC [1] 704.9783 library(nlme) ATSSmb1 &lt;- lme(ATSS ~ 1, random = ~ 1|church, method=&quot;ML&quot;, na.action = na.omit, data = Lefevor2020) summary(ATSSmb1) Linear mixed-effects model fit by maximum likelihood Data: Lefevor2020 AIC BIC logLik 694.73 704.9783 -344.365 Random effects: Formula: ~1 | church (Intercept) Residual StdDev: 0.5170587 1.062978 Fixed effects: ATSS ~ 1 Value Std.Error DF t-value p-value (Intercept) 3.321371 0.1514833 210 21.92566 0 Standardized Within-Group Residuals: Min Q1 Med Q3 Max -3.91296264 -0.64096244 0.03922427 0.57637964 2.52520439 Number of Observations: 225 Number of Groups: 15 anova(ATSSmb1) # request F-tests for fixed effects numDF denDF F-value p-value (Intercept) 1 210 480.7347 &lt;.0001 library(lmerTest) ranova(ATSSm1) # request test of random effects ANOVA-like table for random-effects: Single term deletions Model: ATSS ~ (1 | church) npar logLik AIC LRT Df Pr(&gt;Chisq) &lt;none&gt; 3 -344.37 694.73 (1 | church) 2 -356.89 717.79 25.06 1 0.0000005558 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 confint(ATSSm1) # request test of random effects (variance displayed as SD) Computing profile confidence intervals ... 2.5 % 97.5 % .sig01 0.3231248 0.8347723 .sigma 0.9688860 1.1733458 (Intercept) 3.0051108 3.6376320 # Extract Variances to compute R^2 var_table = as.data.frame(VarCorr(ATSSm1)) ATSSm1_var_tot = var_table[1,&#39;vcov&#39;] + var_table[2,&#39;vcov&#39;] # var_table[1,&#39;vcov&#39;] = L1 var; var_table[2,&#39;vcov&#39;] = L2 var; library(sjPlot) tab_model(ATSSm1, ATSSmb1, p.style = &quot;stars&quot;, show.ci = TRUE, show.se = TRUE, show.df = FALSE, show.re.var = TRUE, show.aic = TRUE, show.dev = TRUE, use.viewer = TRUE, dv.labels = c(&quot;ATSSm1&quot;, &quot;ATSSmb1&quot;)) ATSSm1 ATSSmb1 Predictors Estimates std. Error CI Estimates std. Error CI (Intercept) 3.32 *** 0.15 -Inf  Inf 3.32 *** 0.15 -Inf  Inf Random Effects 2 1.13 1.13 00 0.27 church 0.27 church ICC 0.19 0.19 N 15 church 15 church Observations 225 225 Marginal R2 / Conditional R2 0.000 / 0.191 0.000 / 0.191 Deviance 688.730 688.730 AIC 694.730 694.730 p&lt;0.05 ** p&lt;0.01 *** p&lt;0.001 #can swap this statement with the &quot;file = &quot;TabMod_Table&quot;&quot; to get Viewer output or the outfile that you can open in Word #file = &quot;TabMod_Table.doc&quot; # MODEL 2 ATSSm2 &lt;- lmer(ATSS ~ GenderL1 + AgeL1 + EducL1 + AttendL1 + (1 | church), REML=FALSE, data = Lefevor2020) summary(ATSSm2) Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [lmerModLmerTest] Formula: ATSS ~ GenderL1 + AgeL1 + EducL1 + AttendL1 + (1 | church) Data: Lefevor2020 AIC BIC logLik deviance df.resid 697.9 721.8 -341.9 683.9 218 Scaled residuals: Min 1Q Median 3Q Max -4.1484 -0.6541 0.0720 0.6251 2.4179 Random effects: Groups Name Variance Std.Dev. church (Intercept) 0.2691 0.5187 Residual 1.1040 1.0507 Number of obs: 225, groups: church, 15 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 3.321371 0.151146 15.000000 21.975 0.000000000000803 *** GenderL1 -0.032468 0.172588 210.000000 -0.188 0.8510 AgeL1 0.002031 0.002922 210.000000 0.695 0.4878 EducL1 -0.011469 0.032158 210.000000 -0.357 0.7217 AttendL1 0.100379 0.048559 210.000000 2.067 0.0399 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) GndrL1 AgeL1 EducL1 GenderL1 0.000 AgeL1 0.000 0.044 EducL1 0.000 -0.091 0.002 AttendL1 0.000 -0.003 -0.041 -0.222 AIC(ATSSm2) # request AIC [1] 697.8517 BIC(ATSSm2) # request BIC [1] 721.7644 ATSSmb2 &lt;- lme(ATSS ~ GenderL1 + AgeL1 + EducL1 + AttendL1, random = ~ 1|church, method=&quot;ML&quot;, na.action = na.omit, data =Lefevor2020) summary(ATSSmb2) Linear mixed-effects model fit by maximum likelihood Data: Lefevor2020 AIC BIC logLik 697.8517 721.7644 -341.9259 Random effects: Formula: ~1 | church (Intercept) Residual StdDev: 0.5187287 1.050703 Fixed effects: ATSS ~ GenderL1 + AgeL1 + EducL1 + AttendL1 Value Std.Error DF t-value p-value (Intercept) 3.321371 0.15285420 206 21.729017 0.0000 GenderL1 -0.032468 0.17453771 206 -0.186024 0.8526 AgeL1 0.002031 0.00295477 206 0.687232 0.4927 EducL1 -0.011469 0.03252185 206 -0.352657 0.7247 AttendL1 0.100379 0.04910769 206 2.044049 0.0422 Correlation: (Intr) GndrL1 AgeL1 EducL1 GenderL1 0.000 AgeL1 0.000 0.044 EducL1 0.000 -0.091 0.002 AttendL1 0.000 -0.003 -0.041 -0.222 Standardized Within-Group Residuals: Min Q1 Med Q3 Max -4.14841995 -0.65405081 0.07201772 0.62509925 2.41789073 Number of Observations: 225 Number of Groups: 15 anova(ATSSm2) # request F-tests for fixed effects Type III Analysis of Variance Table with Satterthwaite&#39;s method Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F) GenderL1 0.0391 0.0391 1 210 0.0354 0.85096 AgeL1 0.5332 0.5332 1 210 0.4830 0.48783 EducL1 0.1404 0.1404 1 210 0.1272 0.72172 AttendL1 4.7174 4.7174 1 210 4.2731 0.03995 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ranova(ATSSm2) # request test of random effects ANOVA-like table for random-effects: Single term deletions Model: ATSS ~ GenderL1 + AgeL1 + EducL1 + AttendL1 + (1 | church) npar logLik AIC LRT Df Pr(&gt;Chisq) &lt;none&gt; 7 -341.93 697.85 (1 | church) 6 -354.93 721.86 26.005 1 0.0000003406 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 confint(ATSSm2) # request test of random effects (variance displayed as SD) Computing profile confidence intervals ... 2.5 % 97.5 % .sig01 0.325859422 0.835802678 .sigma 0.957698392 1.159796802 (Intercept) 3.005112413 3.637630470 GenderL1 -0.372286324 0.307349771 AgeL1 -0.003722209 0.007783432 EducL1 -0.074787815 0.051849686 AttendL1 0.004767776 0.195989247 anova(ATSSmb1, ATSSmb2) Model df AIC BIC logLik Test L.Ratio p-value ATSSmb1 1 3 694.7300 704.9783 -344.3650 ATSSmb2 2 7 697.8517 721.7644 -341.9259 1 vs 2 4.87833 0.3 # Extract Variances to compute R^2 var_table = as.data.frame(VarCorr(ATSSm2)) m2_var_tot = var_table[1,&#39;vcov&#39;] + var_table[2,&#39;vcov&#39;] # var_table[1,&#39;vcov&#39;] = L1 var; var_table[2,&#39;vcov&#39;] = L2 var; tab_model(ATSSm1, ATSSm2, p.style = &quot;numeric&quot;, show.ci = FALSE, show.df = FALSE, show.re.var = TRUE, show.aic = TRUE, show.dev = TRUE, use.viewer = TRUE, dv.labels = c(&quot;ATSSm1&quot;, &quot;ATSSm2&quot;)) ATSSm1 ATSSm2 Predictors Estimates p Estimates p (Intercept) 3.32 &lt;0.001 3.32 &lt;0.001 GenderL1 -0.03 0.851 AgeL1 0.00 0.487 EducL1 -0.01 0.721 AttendL1 0.10 0.039 Random Effects 2 1.13 1.10 00 0.27 church 0.27 church ICC 0.19 0.20 N 15 church 15 church Observations 225 225 Marginal R2 / Conditional R2 0.000 / 0.191 0.017 / 0.210 Deviance 688.730 683.852 AIC 694.730 697.852 #can swap this statement with the &quot;file = &quot;TabMod_Table&quot;&quot; to get Viewer output or the outfile that you can open in Word #file = &quot;TabMod_Table.doc&quot; # MODEL 3 ATSSm3 &lt;- lmer(ATSS ~ GenderL1 + AgeL1 + EducL1 + AttendL1 + GenderL2 + AgeL2 + EducL2 + AttendL2 + Homogeneity + (1 | church), REML=FALSE, data = Lefevor2020) summary(ATSSm3) Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [lmerModLmerTest] Formula: ATSS ~ GenderL1 + AgeL1 + EducL1 + AttendL1 + GenderL2 + AgeL2 + EducL2 + AttendL2 + Homogeneity + (1 | church) Data: Lefevor2020 AIC BIC logLik deviance df.resid 694.4 735.4 -335.2 670.4 213 Scaled residuals: Min 1Q Median 3Q Max -4.5681 -0.6456 0.1041 0.6341 2.1664 Random effects: Groups Name Variance Std.Dev. church (Intercept) 0.06591 0.2567 Residual 1.10398 1.0507 Number of obs: 225, groups: church, 15 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 5.289974 3.064703 15.000000 1.726 0.10486 GenderL1 -0.032468 0.172588 210.000000 -0.188 0.85096 AgeL1 0.002031 0.002922 210.000000 0.695 0.48783 EducL1 -0.011469 0.032158 210.000000 -0.357 0.72172 AttendL1 0.100379 0.048559 210.000000 2.067 0.03995 * GenderL2 1.018112 0.923092 15.000000 1.103 0.28744 AgeL2 -0.014487 0.022000 15.000000 -0.659 0.52018 EducL2 -0.377632 0.170601 15.000000 -2.214 0.04277 * AttendL2 0.243757 0.362136 15.000000 0.673 0.51112 Homogeneity -1.580202 0.458259 15.000000 -3.448 0.00358 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) GndrL1 AgeL1 EducL1 AttnL1 GndrL2 AgeL2 EducL2 AttnL2 GenderL1 0.000 AgeL1 0.000 0.044 EducL1 0.000 -0.091 0.002 AttendL1 0.000 -0.003 -0.041 -0.222 GenderL2 0.235 0.000 0.000 0.000 0.000 AgeL2 -0.634 0.000 0.000 0.000 0.000 -0.388 EducL2 0.083 0.000 0.000 0.000 0.000 -0.317 0.075 AttendL2 -0.877 0.000 0.000 0.000 0.000 -0.041 0.249 -0.352 Homogeneity -0.136 0.000 0.000 0.000 0.000 -0.317 0.330 -0.119 -0.102 AIC(ATSSm3) # request AIC [1] 694.372 BIC(ATSSm3) # request BIC [1] 735.3652 #running the nlme ogtained an error indicating there is singularity in the variables #the stack exchange conversation referenced below indicates that nlme/lmer is sensitive to this # https://stackoverflow.com/questions/50505290/singularity-in-backsolve-at-level-0-block-1-in-lme-model #ATSSmb3 &lt;- lme(ATSS ~ Female0L1 + AgeL1 + EducL1 + AttendL1 + Female0L2 + AgeL2 + EducL2 + AttendL2 + Homogeneity, random = ~ 1|church, method=&quot;ML&quot;, na.action = na.omit, data =Lefevor2020) summary(ATSSm3) Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s method [lmerModLmerTest] Formula: ATSS ~ GenderL1 + AgeL1 + EducL1 + AttendL1 + GenderL2 + AgeL2 + EducL2 + AttendL2 + Homogeneity + (1 | church) Data: Lefevor2020 AIC BIC logLik deviance df.resid 694.4 735.4 -335.2 670.4 213 Scaled residuals: Min 1Q Median 3Q Max -4.5681 -0.6456 0.1041 0.6341 2.1664 Random effects: Groups Name Variance Std.Dev. church (Intercept) 0.06591 0.2567 Residual 1.10398 1.0507 Number of obs: 225, groups: church, 15 Fixed effects: Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 5.289974 3.064703 15.000000 1.726 0.10486 GenderL1 -0.032468 0.172588 210.000000 -0.188 0.85096 AgeL1 0.002031 0.002922 210.000000 0.695 0.48783 EducL1 -0.011469 0.032158 210.000000 -0.357 0.72172 AttendL1 0.100379 0.048559 210.000000 2.067 0.03995 * GenderL2 1.018112 0.923092 15.000000 1.103 0.28744 AgeL2 -0.014487 0.022000 15.000000 -0.659 0.52018 EducL2 -0.377632 0.170601 15.000000 -2.214 0.04277 * AttendL2 0.243757 0.362136 15.000000 0.673 0.51112 Homogeneity -1.580202 0.458259 15.000000 -3.448 0.00358 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) GndrL1 AgeL1 EducL1 AttnL1 GndrL2 AgeL2 EducL2 AttnL2 GenderL1 0.000 AgeL1 0.000 0.044 EducL1 0.000 -0.091 0.002 AttendL1 0.000 -0.003 -0.041 -0.222 GenderL2 0.235 0.000 0.000 0.000 0.000 AgeL2 -0.634 0.000 0.000 0.000 0.000 -0.388 EducL2 0.083 0.000 0.000 0.000 0.000 -0.317 0.075 AttendL2 -0.877 0.000 0.000 0.000 0.000 -0.041 0.249 -0.352 Homogeneity -0.136 0.000 0.000 0.000 0.000 -0.317 0.330 -0.119 -0.102 anova(ATSSm3) # request F-tests for fixed effects Type III Analysis of Variance Table with Satterthwaite&#39;s method Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F) GenderL1 0.0391 0.0391 1 210 0.0354 0.850959 AgeL1 0.5332 0.5332 1 210 0.4830 0.487825 EducL1 0.1404 0.1404 1 210 0.1272 0.721718 AttendL1 4.7174 4.7174 1 210 4.2731 0.039946 * GenderL2 1.3430 1.3430 1 15 1.2165 0.287436 AgeL2 0.4787 0.4787 1 15 0.4337 0.520182 EducL2 5.4092 5.4092 1 15 4.8998 0.042775 * AttendL2 0.5002 0.5002 1 15 0.4531 0.511117 Homogeneity 13.1269 13.1269 1 15 11.8906 0.003585 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ranova(ATSSm3) # request test of random effects ANOVA-like table for random-effects: Single term deletions Model: ATSS ~ GenderL1 + AgeL1 + EducL1 + AttendL1 + GenderL2 + AgeL2 + EducL2 + AttendL2 + Homogeneity + (1 | church) npar logLik AIC LRT Df Pr(&gt;Chisq) &lt;none&gt; 12 -335.19 694.37 (1 | church) 11 -336.91 695.83 3.455 1 0.06306 . --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 confint(ATSSm3) # request test of random effects (variance displayed as SD) Computing profile confidence intervals ... 2.5 % 97.5 % .sig01 0.000000000 0.490967315 .sigma 0.957698031 1.159796607 (Intercept) -1.122609232 11.702556036 GenderL1 -0.372286415 0.307349862 AgeL1 -0.003722211 0.007783434 EducL1 -0.074787832 0.051849703 AttendL1 0.004767750 0.195989272 GenderL2 -0.913365344 2.949589723 AgeL2 -0.060519620 0.031544903 EducL2 -0.734596215 -0.020667110 AttendL2 -0.513976611 1.001489745 Homogeneity -2.539062899 -0.621340312 anova(ATSSm1, ATSSm2, ATSSm3) Data: Lefevor2020 Models: ATSSm1: ATSS ~ 1 + (1 | church) ATSSm2: ATSS ~ GenderL1 + AgeL1 + EducL1 + AttendL1 + (1 | church) ATSSm3: ATSS ~ GenderL1 + AgeL1 + EducL1 + AttendL1 + GenderL2 + AgeL2 + ATSSm3: EducL2 + AttendL2 + Homogeneity + (1 | church) npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ATSSm1 3 694.73 704.98 -344.37 688.73 ATSSm2 7 697.85 721.76 -341.93 683.85 4.8783 4 0.30001 ATSSm3 12 694.37 735.37 -335.19 670.37 13.4797 5 0.01928 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 tab_model(ATSSm1, ATSSm2, ATSSm3, p.style = &quot;numeric&quot;, show.ci = FALSE, show.df = FALSE, show.re.var = TRUE, show.aic = TRUE, show.dev = TRUE, use.viewer = TRUE, dv.labels = c(&quot;ATSSm1&quot;, &quot;ATSSm2&quot;, &quot;ATSSm3&quot;)) ATSSm1 ATSSm2 ATSSm3 Predictors Estimates p Estimates p Estimates p (Intercept) 3.32 &lt;0.001 3.32 &lt;0.001 5.29 0.084 GenderL1 -0.03 0.851 -0.03 0.851 AgeL1 0.00 0.487 0.00 0.487 EducL1 -0.01 0.721 -0.01 0.721 AttendL1 0.10 0.039 0.10 0.039 GenderL2 1.02 0.270 AgeL2 -0.01 0.510 EducL2 -0.38 0.027 AttendL2 0.24 0.501 Homogeneity -1.58 0.001 Random Effects 2 1.13 1.10 1.10 00 0.27 church 0.27 church 0.07 church ICC 0.19 0.20 0.06 N 15 church 15 church 15 church Observations 225 225 225 Marginal R2 / Conditional R2 0.000 / 0.191 0.017 / 0.210 0.163 / 0.210 Deviance 688.730 683.852 670.372 AIC 694.730 697.852 694.372 #can swap this statement with the &quot;file = &quot;TabMod_Table&quot;&quot; to get Viewer output or the outfile that you can open in Word #file = &quot;TabMod_Table.doc&quot; 2.8.2 Just the Code Please STAY TUNED sessionInfo() R version 4.0.4 (2021-02-15) Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 10 x64 (build 18362) Matrix products: default locale: [1] LC_COLLATE=English_United States.1252 [2] LC_CTYPE=English_United States.1252 [3] LC_MONETARY=English_United States.1252 [4] LC_NUMERIC=C [5] LC_TIME=English_United States.1252 attached base packages: [1] stats graphics grDevices utils datasets methods base other attached packages: [1] sjPlot_2.8.7 PerformanceAnalytics_2.0.4 [3] xts_0.12.1 zoo_1.8-9 [5] robumeta_2.0 lmerTest_3.1-3 [7] forcats_0.5.1 stringr_1.4.0 [9] dplyr_1.0.5 purrr_0.3.4 [11] readr_1.4.0 tidyr_1.1.3 [13] tibble_3.1.1 ggplot2_3.3.3 [15] tidyverse_1.3.1 sjstats_0.18.1 [17] nlme_3.1-151 lme4_1.1-26 [19] Matrix_1.2-18 psych_2.1.3 loaded via a namespace (and not attached): [1] TH.data_1.0-10 minqa_1.2.4 colorspace_2.0-0 [4] ellipsis_0.3.1 sjlabelled_1.1.7 estimability_1.3 [7] snakecase_0.11.0 parameters_0.13.0 fs_1.5.0 [10] rstudioapi_0.13 farver_2.1.0 glmmTMB_1.0.2.1 [13] fansi_0.4.2 mvtnorm_1.1-1 lubridate_1.7.10 [16] xml2_1.3.2 codetools_0.2-18 splines_4.0.4 [19] mnormt_2.0.2 knitr_1.33 sjmisc_2.8.6 [22] jsonlite_1.7.2 nloptr_1.2.2.2 ggeffects_1.1.0 [25] broom_0.7.6 dbplyr_2.1.1 effectsize_0.4.4-1 [28] compiler_4.0.4 httr_1.4.2 emmeans_1.6.0 [31] backports_1.2.1 assertthat_0.2.1 cli_2.5.0 [34] htmltools_0.5.1.1 tools_4.0.4 coda_0.19-4 [37] gtable_0.3.0 glue_1.4.2 Rcpp_1.0.6 [40] cellranger_1.1.0 jquerylib_0.1.4 vctrs_0.3.7 [43] svglite_2.0.0 apaTables_2.0.8 insight_0.13.2 [46] xfun_0.22 rvest_1.0.0 lifecycle_1.0.0 [49] statmod_1.4.35 MASS_7.3-53.1 scales_1.1.1 [52] hms_1.0.0 parallel_4.0.4 sandwich_3.0-0 [55] TMB_1.7.20 RColorBrewer_1.1-2 yaml_2.2.1 [58] sass_0.3.1 stringi_1.5.3 highr_0.9 [61] bayestestR_0.9.0 boot_1.3-27 rlang_0.4.11 [64] pkgconfig_2.0.3 systemfonts_1.0.1 evaluate_0.14 [67] lattice_0.20-41 labeling_0.4.2 tidyselect_1.1.1 [70] plyr_1.8.6 magrittr_2.0.1 bookdown_0.22 [73] R6_2.5.0 generics_0.1.0 multcomp_1.4-17 [76] DBI_1.1.1 mgcv_1.8-35 pillar_1.6.0 [79] haven_2.4.1 withr_2.4.2 survival_3.2-11 [82] performance_0.7.1 modelr_0.1.8 crayon_1.4.1 [85] utf8_1.2.1 tmvnsim_1.0-2 rmarkdown_2.7 [88] grid_4.0.4 readxl_1.3.1 reprex_2.0.0 [91] digest_0.6.27 xtable_1.8-4 numDeriv_2016.8-1.1 [94] munsell_0.5.0 bslib_0.2.4 quadprog_1.5-8 References "],["MLMexplore.html", "Chapter 3 Preliminary (OLS style) Exploration of Longitudinal Growth 3.1 Navigating this Lesson 3.2 Change-Over-Time Analytics 3.3 Workflow for Longitudinal MLM 3.4 Research Vignette 3.5 Longitudinal Exploration 3.6 Observations about the Social and Cultural Responsivity of the Project 3.7 Residual and Related Questions 3.8 Practice Problems 3.9 Bonus Track:", " Chapter 3 Preliminary (OLS style) Exploration of Longitudinal Growth Screencasted Lecture Link options(scipen=999)#eliminates scientific notation This lesson is an introduction to longitudinal modeling when time is a factor. In this lecture we explore the longitudinal data using OLS tools. Doing so provides the proper screening/vetting of the data to ensure that it is appropriate for multilevel analysis. Simultaneously, it provides an orientation to the types of questions that MLM will address. 3.1 Navigating this Lesson There is about 1 hour and 20 minutes of lecture. If you work through the materials with me it would be plan for an additional two hours While the majority of R objects and data you will need are created within the R script that sources the chapter, occasionally there are some that cannot be created from within the R framework. Additionally, sometimes links fail. All original materials are provided at the Github site that hosts the book. More detailed guidelines for ways to access all these materials are provided in the OERs introduction 3.1.1 Learning Objectives Learning objectives from this lecture include the following: Identify the 3 criteria for longitudinal analysis (in an HLM/MLM framework) Know the key variable (type) requirements of a longitudinal dataset. Know the distinction (and lingo) between level-1 and level-2. Recognize the difference between wide and long files by instantaneous sight. Speculate about the findings by looking at the figures, means(SD), and correlations we produced. Interpret a correlation coefficient of intercepts and slopes. 3.1.2 Planning for Practice The suggestions for homework are graded in complexity and I encourage you to select an option(s) that will stretch you  at least a bit. The more complete descriptions at the end of the chapter follow these suggestions. The assignment is intended to span several lessons. Using a dataset that is provided (or one of your own), walk through exploring, conducting, and writing up a complete multilevel model for change with each step below. Minimally, predictors must include time and an L2 variable. FROM THIS LESSON Restructure the dataset from wide to long. Provide three examples of data exploration An unfitted model A model fitted with a linear growth trajectory The fitted (or unfitted) data identified by the L2 predictor FROM SUBSEQUENT LESSONS Using a staged approach to model development, report on at least four models, these must include An unconditional means model An unconditional growth model An intermediary model (please test both a time variable and an L2 variable) A final model Write up the Results as demonstrated in the lecture Table (use the tab_model outfile) and Figure are required Rework the problem in the chapter by changing the random seed in the code that simulates the data. This should provide minor changes to the data, but the results will likely be very similar. SINCE IM NOT CONVINCED THAT CHANGING THE RANDOM SEED DOES MUCH, I MAY CHANGE THIS ONE TO AN EXAMPLE I WORK WITH ANSWERS AT THE END. Data from a second MLM analysis from the research vignette are provided at the end. The only difference in the scenario is that the outcome variable changes from anxiety to depression. Use this data. Conduct a multi-level analysis with data to which you have access. This could include data you simulate on your own or from a published article. It is quite possible the conditions of your data will necessitate deviations from this approach. Investigate what they are and apply them. 3.1.3 Readings &amp; Resources In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list. Singer, J. D., &amp; Willett, J. B. (2003). A framework for investigating change over time/Chapter 1 and Exporing longitudinal data on change/Chapter 2 in Applied longitudinal data analysis: Modeling change and event occurrence. Oxford University Press. https://doi-org.ezproxy.spu.edu/10.1093/acprof:oso/9780195152968.001.0001 The UCLA IDRE website hosts R solutions (as well as SPSS, SAS, MPlus, and HLM) to many of the examples in this text. Lefevor, G. T., Janis, R. A., &amp; Park, S. Y. (2017). Religious and sexual identities: An intersectional, longitudinal examination of change in therapy. The Counseling Psychologist, 45(3), 387413. https://doi-org.ezproxy.spu.edu/10.1177/0011000017702721 I love the Singer and Willett (2003) text for so many reasons. Singer and Willet have published a number of articles together. In the Preface of their text they indicated that they were hired at Harvard at about he same time. Their colleagues expected them to voracious competitors. In contrast, they became great collaborators and made decisions about authorship early on. Their agreement was that in any collaboration they would randomly select who was first author, and they have (including for their text). 3.1.4 Packages The script below will (a) check to see if the following packages are installed on your computer and, if not (b) install them. #will install the package if not already installed if(!require(robumeta)){install.packages(&quot;robumeta&quot;)} if(!require(tidyverse)){install.packages(&quot;tidyverse&quot;)} if(!require(psych)){install.packages(&quot;psych&quot;)} if(!require(lme4)){install.packages(&quot;lme4&quot;)} if(!require(nlme)){install.packages(&quot;nlme&quot;)} if(!require(sjstats)){install.packages(&quot;sjstats&quot;)} if(!require(scales)){install.packages(&quot;scales&quot;)} 3.2 Change-Over-Time Analytics There are a host of ways to investigate change over time: longitudinal SEM, latent growth curve modeling, latent mixture models, and so forth. We are focused on the subset of this approach that has so many names: individual growth curve models, random coefficient models, multilevel models, linear mixed effects models, hierachical linear models. Before we start down the longitudinal/repeated measures path, a note to say that this class of statistics was born out of a need to deal with dependency in the data and it applies to both cross-sectional and longitudinal/repeated measures models. Remember ANOVA? (Excepting repeated measure or mixed design ANOVA) One of the statistical assumptions was that the data had to be independent. That is, you could not have family members, co-workers, etc., in the dataset because their data would likely be correlated. In the context of these related circumstances (students in a classroom, supervisees of a manager) researchers were confused about how to handle the data. Should they aggregate the dependent data (effectively reduce the sample size by taking the mean of all those in a dependent cluster and using it with the non-dependent data)? Should they keep it disaggregated (effectively repeating/copying the non-dependent data for each member of the cluster)? Each approach was fraught with difficulty. Random coefficient regression models (RCR or RCM) are an effective alternative to ordinary least squares (OLS) to account for dependencies within the data. The math and approach toward longitudinal modeling is largely the same as when we manage dependencies cross-sectional studies (e.g., members of a team, supervisors reporting to a leader/manager). A more thorough review of aggregation and disaggregation can be found in the ReCentering Psych Stats chapter devoted to cross-sectional data. This class of analysis allows us to address questions about: Within-individual change: How does each person change over time? These are descriptive questions: Is change linear? nonlinear? consistent? fluctuating? level-1 concerns within-individual change over time individual growth trajectory  the way outcome values rise and fall over time Goal is to describe the shape of each persons growth trajectory Interindividual differences in change: What predicts differences among people in their changes? A relational question: What is the association between predictors and patterns of change? Are these relations moderated? level-2 concerns interindividual differences in change Do different people manifest different patterns of within-individual change? What predicts these differences? Goal is to detect heterogeneity in change across individuals and to determine the relationship between predictors and the shape of each persons individual growth trajectory. Together, we map the research questions onto a linked pair of statistical models known as the multilevel model for change: a level-1 (L1) model, describing within-individual change over time; and a level-2 (L2) model, relating predictors to any interindividual differences in change Asking these questions requires three criteria of the research design/data: Multiple waves of data Contrast with a developmental psychologist analyzing cross-sectional data composed of children of differing ages. In spite of compelling (and totally fine) research designs, the cross-sectional nature of the design can not rule out plausible rival hypotheses. Contrast with two waves of data. Singer and Willett (2003) state that these data, are only marginally better (p. 10). Two-wave researchers argued in favor of their increment (i.e, the simple difference between scores assessed on the two measurement occasions). Even if the increment is large, Singer and Willett (2003) argue that the increment cannot describe the process of change because it cannot describe the shape (the focus of the level-1 question). Singer and Willett further argue that two-wave studies cannot describe individual change trajectories because they confound true change with measurement error. How many waves? Within cost and logistical constraints, more waves are always better. More allows more complex modeling. The statistical rule is that you need one-more-wave than the shape you wish to model. For example, you need 2 waves for a straight line (linear model), 3 waves for a quadratic (1 hump) model, 4 waves for a cubic (2 curves) model, and so forth. A substantively meaningful metric for time Time is the fundamental predictor in every study of change; it must be measured reliably and validly in a sensible metric (p. 10). What is sensible? ages, grades, months-since-intake, miles, etc. The choice of metric affects related decisions including number and spacing of waves. Consider the cadence you expect in the outcome. Weeks or number of sessions is sensible for psychotherapy studies. Grade or age is sensible for education. Parental or child age might make sense for parenting. The temporal variable can change only monotonically (p. 12), that is, it cannot reverse diretions. This means you can have height as a temporal variable, but not weight. There is NOTHING SACRED about evenly spaced variables. In fact, if you expect rapid nonlinear change during some periods, you should collect mored data at those times. If you expect little movement, you can maybe space them urther apart. Time-structured schedules assess all participants on an identical schedule (cb equally or unequally spaced). Time-unstructured schedules allow data collection schedules to vary across individuals. Multi-level modeling can accomodate both. No requirement for balance. That is, each person can have a different number of waves. While non-random attrition can be problematic for drawing inferences, individual growth modeling does not require balanced data. An outcome that changes systematically The content of measurement is a substantive, not statistical decision. However How the construct is measured is a statistical decision and not all variables are equally suited (p. 13). Individual growth models are designed for continuous outcomes whose values change systematically over time. Continuous outcomes are those that support all the usual manipulations of arithmetic (p. 13). That is, you can take differences between pairs of scores, add, subtract, multiply, divide. Most psychometrically credible instruments will work. BUT! the metric, validity, and precision of the outcome must be preserved across time. That is, the outcome scores must be equatable over time. That is, a given value of the outcome on any occasion must represent the same amount of the outcome on every occasion. Outcome equatability is supported (in part) by using the identical instrument each time. Standardization in the longitudinal context is hotly debated and not a simple solution for equating shifty metrics. Why? the SD units likely have different size/meaning at different intervals. Transforming the M to 0.0 and the SD to 1.0 masks the variance differences that may exist. The raw metric preserves the variance and avoids all the issues. Outcomes should be equally valid across all measurement occasions. For example, a multiplication test may be a valid measure of mathematical skill among young children, but a measure of memory among teenagers. Although precision need not be identical at every occasion, the goal is to minimize errors introduced by instrument administration. Look for reliabilities of .8 and above. Structuring up a longitudinal data set and engaging in preliminary data anlaysis is a great way to further understand this approach to statistical modeling. So, lets transition to our research vignette. 3.3 Workflow for Longitudinal MLM Workflow for a longitudinal MLM 3.4 Research Vignette Our research vignette (Lefevor et al., 2017) examines the intersection of religious and sexual identities of clients in therapy. With 12,825 participants from the Center for Collegiate Mental Health 2012-2014 data set, the project is an example of working with big data. Because the data is available to members only (and behind a paywall), I simulated the data. In the simulation, categorical variables (e.g., sexual identity, session number, religious identity) were rendered as continuous variables and in the simulation, I needed to transform them back into categorical ones. Inevitably, this will have introduced a great deal of error. Thus, we can expect that the results from the simulated data will be different from those obtained by the authors. The Method section of the article provides detailed information about the inclusion criteria ofr the study and the coding of the variables. This included data about the religious and sexual identities as well as a minimum of three separate scores on the Counseling Center Assessment of Psychologial Sympsoms (CCAPS, Locke et al., 2012) measure. For the final dataset, clients attended an average of 10.58 sessions (SD = 7.65) and had an average of 5.36 CCAPS administrations (SD = 4.04). This means that in the original dataset, each client was represented by a varying number of observations (likely ranging from 3 [the minimum required for inclusion] and, perhaps as many as 17 [adding +3SDs to the mean CCAPS administrations]). In simulating the data, I specified five observations for each of the 12,825 clients. Lets take a look at the variables in the study Anxiety and Depression: The anxiety and depression ratings were taken from the CCAPS measure (Locke et al., 2012) that assesses psychological distress across seven domains. Clients rate themselves over the past two weeks on a 5-point Likert-type scale ranging from 0 (not at all like me) to 4 (extremely like me). Higher scores indicate more distress. The dataset comes from multiple institutions with different procedures around assessment CCAPS there is not a 1:1 correspondence with session number and CCAPS assessment. Sexual Identity: Sexual identity was dichotomized into heterosexual (-1, 85.5%) and LGBQQ (1, 14.5%). Relious Identity: Religious identity was coded into three categories including dominant religious (DR; Christian, Catholic), nondominant religious (NDR; Muslim, Hindu, Buddhist, Jewish), and nondominant unaffiliated (NDU; agnostic, atheist, no preference). The three categories were contrast coded with an orthogonal contrast-coding scheme with two variables. The first variable compared DR(coded as 2) to NDU and NDR (coded as -1); the second variable compared the two nondominant groups (NDU = -1, DR = 0, NDR = 1). 3.4.1 Simulating the data from the journal article set.seed(200513) n_client = 12825 n_session = 5 b0 = 2.03 #intercept for anxiety b1 = -.22 #b weight for L1 session b2 = .13 #b weight for L2 sexual identity b3 = -.03 #b weight for L2 Rel1 (D-R vs ND-R &amp; ND-U) b4 = .01 #b weight for the L2 Rel2 (ND-R vs ND-U) #the values used below are the +/- 3SD they produce continuous variables which later need to be transformed to categorical ones; admittedly this introduces a great deal of error/noise into the simulation #the article didn&#39;t include a correlation matrix or M/SDs so this was a clunky process ( Session = runif(n_client*n_session, -3.61, 3.18)) #calc L1 Session, values are the +/3 3SD ( SexualIdentity = runif(n_client*Session, -6.66, 6.92)) #calc L2 Sexual Identity, values are the +/3 3SD ( Religion1 = runif(n_client*Session, -3.43, 3.37)) #calc L2 Religion1, values are the +/3 3SD ( Religion2 = rep (runif(n_session, -3.38, 3.41), each = n_session)) #calc L2 Religion2, values are the +/3 3SD mu = 1.76 #intercept of empty model sds = 2.264 #this is the SD of the DV sd = 1 #this is the observation-level random effect variance that we set at 1 #( church = rep(LETTERS[1:n_church], each = n_mbrs) ) #this worked in the prior ( client = rep(LETTERS[1:n_client], each = n_session) ) #( session = numbers[1:(n_client*n_session)] ) ( clienteff = rnorm(n_client, 0, sds) ) ( clienteff = rep(clienteff, each = n_session) ) ( sessioneff = rnorm(n_client*n_session, 0, sd) ) ( Anxiety = b0 + b1*Session + b2*SexualIdentity + b3*Religion1 + b4*Religion2 + clienteff + sessioneff) ( dat = data.frame(client, clienteff, sessioneff, Session, SexualIdentity, Religion1, Religion2, Anxiety) ) library(dplyr) dat &lt;- dat %&gt;% mutate(ID = row_number()) #moving the ID number to the first column; requires dat &lt;- dat%&gt;%select(ID, everything()) Lefevor2017 &lt;- dat%&gt;% select(ID, client, Session, SexualIdentity, Religion1, Religion2, Anxiety) Lefevor2017$ClientID &lt;- rep(c(1:12825), each = 5) #rounded Sexual Identity into dichotomous variable #85% were heterosexual, library(robumeta) #The following variables should be L2, but were simulated as if they were L1 Lefevor2017$Rel1 &lt;- as.numeric(group.mean(Lefevor2017$Religion1,Lefevor2017$ClientID))#aggregated at group mean Lefevor2017$Rel2 &lt;- as.numeric(group.mean(Lefevor2017$Religion2,Lefevor2017$ClientID))#aggregated at group mean Lefevor2017$SxID &lt;- as.numeric(group.mean(Lefevor2017$SexualIdentity,Lefevor2017$ClientID))#aggregated at group mean #Rel2 has contrast codes for dominant religion (DR, 0), nondominant religious (NDR, 1) and nondominant unspecified (NDU, -1) #Strategy is to figure out the raw score associated with the percentile rank of -1 and 0, to set the breakpoints for the coding #NDU coded as -1 #19.2+13.5+9.6 #NDU has bottom 42.3 percent #DR coded as 0, so quantile cut will be 42.3 + 52.7 = 95th #33.4 + 19.3 #52.7% of sample (according to article) was DR #must look up percentile ranks for 5% and 57.5% #NDR #2.3+1+1+.7 #NDR has 5% of sample #42.3+52.7 #quantile(Lefevor2017$Religion2, probs = c(.423, .95)) #effects coding the second Religion variable so that NDU = -1, DR = 0, NDR = 1 Lefevor2017$Rel2L2 &lt;- ifelse(Lefevor2017$Religion2 &lt;= -3.0877087, -1, ifelse(Lefevor2017$Religion2 &gt;= -3.0877087 &amp; Lefevor2017$Religion2 &lt;= 0.9299491, 0,1)) #checking work #Rel2L2_table &lt;- table(Lefevor2017$Rel2L2) #prop.table(Rel2L2_table) #Lefevor2017 %&gt;% #count(Rel2L2) #creating the first religion variable where DR is 2 and NDR and NDU are both -1 Lefevor2017$Rel1L2 &lt;- plyr::mapvalues(Lefevor2017$Rel2L2, from = c(-1, 0, 1), to = c(-1, 2, -1)) Lefevor2017$DRel0 &lt;- plyr::mapvalues(Lefevor2017$Rel2L2, from = c(-1, 0, 1), to = c(1, 0, 1)) #checking to make sure that 52.7% are coded 2 (DR) #Rel1L2_table &lt;- table(Lefevor2017$Rel1L2) #prop.table(Rel1L2_table) #heterosexual is -1 #LGBTQIA+ is 1 #quantile(Lefevor2017$SxID, probs = c(.85)) Lefevor2017$SexID &lt;- ifelse(Lefevor2017$SxID &lt;= 1.203468, -1,1) Lefevor2017$Het0 &lt;- plyr::mapvalues(Lefevor2017$SexID, from = c(-1,1), to = c(0,1)) #SexID_table &lt;- table(Lefevor2017$SexID) #prop.table(SexID_table) #creating a variable representing the session number for each client, in the article up to 20 sessions were allowed. #install.packages(&quot;scales&quot;) library(scales) #Right from the beginning I centered this so that 0 would represent intake Lefevor2017$Session0 &lt;- as.integer(scales::rescale(Lefevor2017$Session, to = c(0, 19))) #creating session waves (1 thru 5) by rank ordering within each person&#39;s variable the continuous variable Session that was created in the original simulation library(dplyr) Lefevor2017 &lt;- Lefevor2017%&gt;% dplyr::group_by(ClientID) %&gt;% mutate(Index = rank(Session)) #selecting the simulated variables Lefevor2017_sim &lt;- Lefevor2017%&gt;% select(ClientID, Index, Session0, Anxiety, DRel0, Het0) #In the transition from long-to-wide, it seems like you can only do one L1 variable at a time #When there are multiple L1 and L2 vars, put all L2 vars on left of tilde #The wave/index function should come next; this should be finite (like integers of 1,2,3,4) with a maximum #Put the name of the SINGLE L1 variable in the concatonated list library(data.table) Warning: package &#39;data.table&#39; was built under R version 4.0.5 Attaching package: &#39;data.table&#39; The following objects are masked from &#39;package:xts&#39;: first, last The following objects are masked from &#39;package:dplyr&#39;: between, first, last The following object is masked from &#39;package:purrr&#39;: transpose LfvrWp1&lt;-reshape2::dcast(Lefevor2017_sim, ClientID + DRel0 + Het0 ~ Index, value.var = c(&quot;Index&quot;)) #rename the anxiety variable LfvrWp1&lt;- rename(LfvrWp1, Index1 = &quot;1&quot;, Index2 = &quot;2&quot;, Index3 = &quot;3&quot;, Index4 = &quot;4&quot;, Index5 = &quot;5&quot;) LfvrWp2&lt;-reshape2::dcast(Lefevor2017_sim, ClientID ~ Index, value.var = c(&quot;Anxiety&quot;)) #rename the anxiety variable LfvrWp2&lt;- rename(LfvrWp2, Anx1 = &quot;1&quot;, Anx2 = &quot;2&quot;, Anx3 = &quot;3&quot;, Anx4 = &quot;4&quot;, Anx5 = &quot;5&quot;) #For remaining L1 variable, do them one at a time -- key them from the person-level ID and the wave/index. LfvrWp3&lt;-reshape2::dcast(Lefevor2017_sim, ClientID ~ Index, value.var = c(&quot;Session0&quot;)) LfvrWp3&lt;- rename(LfvrWp3, Sess1 = &quot;1&quot;, Sess2 = &quot;2&quot;, Sess3 = &quot;3&quot;, Sess4 = &quot;4&quot;, Sess5 = &quot;5&quot;) #Next, join the dataframes by the person-level ID #Only two can be joined at a time LfvrWide &lt;- dplyr::full_join(LfvrWp1, LfvrWp2, by = c(&quot;ClientID&quot;)) LfvrWide &lt;- dplyr::full_join(LfvrWide, LfvrWp3, by = c(&quot;ClientID&quot;)) To increase the portability of the OER, this chapter uses simulated data. Here is script for exporting/downloading the data as a .csv file to your local computer and then importing/uploading it again. I find that saving the .csv file (data) in the same place as the .rmd file(s) is essential for R to connect the two. Because this simulation can take a few minutes, you may wish to do this, even as you work through this chapter, so that resimulations take less time and comuting resources. write.table(LfvrWide, file=&quot;LefevorWide.csv&quot;, sep=&quot;,&quot;, col.names=TRUE, row.names=FALSE) LfvrWide &lt;- read.csv (&quot;LefevorWide.csv&quot;, head = TRUE, sep = &quot;,&quot;) 3.5 Longitudinal Exploration 3.5.1 The Structure of the Data File as the First Step in Understanding Longitudinal Modeling We are accustomed to viewing data in its wide format. The wide format is also technically termed the person-level data set or the multivariate format of data. It is characterized by the following: Each person has one record and multiple variables contain the data from each measurement occasion; a 16-person set has 16 records while a 20,000 person set has 20,000 records. As you collect additional waves, a person-level file gains new variables (not new cases). In the context of longitudinal modeling, data in this form allows us to visually examing an empirical growth record (the temporally sequenced outcomes). This wide file arrays each persons empirical growth record horizontally There are disadvantages to the wide format: The summmaries are noninformative. It omits an explicit time variable. It is inefficient/useless when the number and spacing of waves varies It cannot handle the presence of time-varying predictors. library(psych) round(psych::describe(LfvrWide),3) vars n mean sd median trimmed mad min max ClientID 1 12825 6413.00 3702.40 6413.00 6413.00 4753.22 1.00 12825.00 DRel0 2 12825 0.60 0.49 1.00 0.62 0.00 0.00 1.00 Het0 3 12825 0.28 0.45 0.00 0.22 0.00 0.00 1.00 Index1 4 12825 1.00 0.00 1.00 1.00 0.00 1.00 1.00 Index2 5 12825 2.00 0.00 2.00 2.00 0.00 2.00 2.00 Index3 6 12825 3.00 0.00 3.00 3.00 0.00 3.00 3.00 Index4 7 12825 4.00 0.00 4.00 4.00 0.00 4.00 4.00 Index5 8 12825 5.00 0.00 5.00 5.00 0.00 5.00 5.00 Anx1 9 12825 2.58 2.54 2.56 2.58 2.52 -7.88 11.88 Anx2 10 12825 2.32 2.55 2.31 2.33 2.56 -8.13 12.31 Anx3 11 12825 2.08 2.56 2.06 2.08 2.57 -7.36 12.87 Anx4 12 12825 1.82 2.52 1.82 1.83 2.52 -7.29 10.72 Anx5 13 12825 1.58 2.52 1.56 1.58 2.55 -7.58 11.23 Sess1 14 12825 2.66 2.64 2.00 2.27 2.96 0.00 16.00 Sess2 15 12825 5.83 3.37 5.00 5.64 2.96 0.00 17.00 Sess3 16 12825 8.99 3.58 9.00 8.98 4.45 0.00 18.00 Sess4 17 12825 12.15 3.38 12.00 12.33 4.45 0.00 18.00 Sess5 18 12825 15.31 2.68 16.00 15.72 2.96 2.00 19.00 range skew kurtosis se ClientID 12824.00 0.00 -1.20 32.69 DRel0 1.00 -0.41 -1.83 0.00 Het0 1.00 0.99 -1.02 0.00 Index1 0.00 NaN NaN 0.00 Index2 0.00 NaN NaN 0.00 Index3 0.00 NaN NaN 0.00 Index4 0.00 NaN NaN 0.00 Index5 0.00 NaN NaN 0.00 Anx1 19.76 0.03 0.06 0.02 Anx2 20.44 -0.02 -0.01 0.02 Anx3 20.23 -0.01 -0.03 0.02 Anx4 18.01 -0.03 -0.04 0.02 Anx5 18.81 0.00 -0.07 0.02 Sess1 16.00 1.20 1.20 0.02 Sess2 17.00 0.46 -0.34 0.03 Sess3 18.00 0.02 -0.65 0.03 Sess4 18.00 -0.46 -0.36 0.03 Sess5 17.00 -1.21 1.20 0.02 We could (but it is not advised in this specific instance) use the wide format to create the multilevel correlation matrix, allowing us to see the correlations between the person-level (L2) variables of religious identity and sexual identity with the repeated measures variable (L1), anxiety. The bivariate correlations tell us little about change-over-time for individuals or groups. However, in this dataset we can see a strong correlation (they are all r = .80) between anxiety at one session and the next.. Thinking of what it takes to get a positive and strong correlation (e.g., relative rankings must stay stable), we learn that the rank order of clients (relative to anxiety) remains relatively stable across occasions, but it does not tell us how each person changes over time nor about the direction of change. #Multilevel level correlation matrix apaTables::apa.cor.table(LfvrWide[c( &quot;DRel0&quot;, &quot;Het0&quot;, &quot;Anx1&quot;, &quot;Anx2&quot;, &quot;Anx3&quot;, &quot;Anx4&quot;, &quot;Anx5&quot;)], show.conf.interval = FALSE, landscape = TRUE, table.number = 1, filename=&quot;Lfvr2017_CorMatrix.doc&quot;) The ability to suppress reporting of reporting confidence intervals has been deprecated in this version. The function argument show.conf.interval will be removed in a later version. Table 1 Means, standard deviations, and correlations with confidence intervals Variable M SD 1 2 3 4 5 1. DRel0 0.60 0.49 2. Het0 0.28 0.45 -.01 [-.02, .01] 3. Anx1 2.58 2.54 .00 .05** [-.01, .02] [.03, .07] 4. Anx2 2.32 2.55 -.00 .05** .80** [-.02, .02] [.03, .07] [.79, .81] 5. Anx3 2.07 2.56 .00 .06** .80** .80** [-.01, .02] [.04, .07] [.80, .81] [.80, .81] 6. Anx4 1.82 2.52 .00 .05** .80** .80** .80** [-.01, .02] [.03, .07] [.79, .80] [.79, .80] [.80, .81] 7. Anx5 1.58 2.52 -.01 .05** .80** .80** .80** [-.02, .01] [.03, .07] [.79, .81] [.79, .80] [.79, .81] 6 .80** [.79, .80] Note. M and SD are used to represent mean and standard deviation, respectively. Values in square brackets indicate the 95% confidence interval. The confidence interval is a plausible range of population correlations that could have caused the sample correlation (Cumming, 2014). * indicates p &lt; .05. ** indicates p &lt; .01. I should note that a bivariate matrix created from the wide format is rather useless when the assessments are unevenly spaced (time-unstructured; ours are) and the dataset is unbalanced (ours is). 3.5.2 Job#1 is to get our data from person-level into person-period Person-period data set aka a long or univariate file: Each person has multiple records  one for each measurement occasion. As you collect additional waves,the file gains new records, but no new variables This long file arrays each persons empirical growth record vertically 4 types of variables Subject identifier  typically in the first column and identical across waves; required for sorting and grouping Time indicator  often labeled AGE, WAVE, or TIME (or something sensible); it is fine to have unstructured time (e.g., 0.5, 1.2, 3.4 months) Outcome variable(s)  time-varying, but represented by a single variable/column Predictor variable(s)  each individual predictor (whether time-covarying or time-invariant) is represented by a single variable/column Lets restructure (shapeshift) our dataset with the technique known as melting. Each set of variables being melted in each set being restructured need to be on the same scale. In this problem, the Anx# and Sess# variables should be on the same scale. str(LfvrWide) &#39;data.frame&#39;: 12825 obs. of 18 variables: $ ClientID: int 1 2 3 4 5 6 7 8 9 10 ... $ DRel0 : int 0 1 1 1 0 0 1 1 1 0 ... $ Het0 : int 0 0 0 0 0 0 0 1 0 0 ... $ Index1 : int 1 1 1 1 1 1 1 1 1 1 ... $ Index2 : int 2 2 2 2 2 2 2 2 2 2 ... $ Index3 : int 3 3 3 3 3 3 3 3 3 3 ... $ Index4 : int 4 4 4 4 4 4 4 4 4 4 ... $ Index5 : int 5 5 5 5 5 5 5 5 5 5 ... $ Anx1 : num 3.71 3.49 1.19 2.94 2.72 ... $ Anx2 : num 3.58 3.09 2.21 2.35 4.75 ... $ Anx3 : num 3.87 2.02 -1.25 5.11 3.47 ... $ Anx4 : num 3.799 2.747 0.338 2.625 5.002 ... $ Anx5 : num 1.56 4 -1.48 2.17 4.83 ... $ Sess1 : int 0 5 1 2 5 6 3 0 3 6 ... $ Sess2 : int 7 6 2 6 6 8 4 2 8 8 ... $ Sess3 : int 8 7 12 9 14 8 6 4 13 10 ... $ Sess4 : int 13 8 12 13 15 13 8 16 13 10 ... $ Sess5 : int 16 10 18 13 17 14 16 18 17 11 ... They are. Each is numeric. library(data.table) #the package for melting (better than reshape2 because it can accommodate multiple repeated measures variables) #add the name of the wide df after &quot;setDT&quot; #id.vars are L2 variables that do not change over time #measure.vars are those that change over time; if there is more than one that is time-covarying, add a comma followed by another another concatonated list. LfvrLong &lt;- (data.table::melt(setDT(LfvrWide), id.vars = c(&quot;ClientID&quot;, &quot;DRel0&quot;, &quot;Het0&quot;), measure.vars =list(c(&quot;Anx1&quot;, &quot;Anx2&quot;, &quot;Anx3&quot;, &quot;Anx4&quot;, &quot;Anx5&quot;), c(&quot;Sess1&quot;, &quot;Sess2&quot;, &quot;Sess3&quot;, &quot;Sess4&quot;, &quot;Sess5&quot;)))) Take a peek at LfvrLong: Anx1 through Anx5 and Sess1 through Sess5 are gone Two new variables have appeared variable is the former variable name; it represents the unit of time (or condition) associated with the repeated measure value is the value of that measurement for that person We must rename these #This process does not preserve the variable names, so we need to rename them LfvrLong&lt;- rename(LfvrLong&lt;- rename(LfvrLong&lt;- rename(LfvrLong, Index = variable, Anxiety = &quot;value1&quot;, SesNum = &quot;value2&quot;))) It can be helpful to have this written to your local file so you can bring it back in without having to re-prep it. write.table(LfvrLong, file=&quot;LfvrLong.csv&quot;, sep=&quot;,&quot;, col.names=TRUE, row.names=FALSE) LfvrLong &lt;- read.csv (&quot;LfvrLong.csv&quot;, head = TRUE, sep = &quot;,&quot;) Although we can manually resort our viewer, it can be helpful (historically, some programs required it) to create a permanent sort by person and wave/index. #rearanging variables so that IDs are together LfvrLong &lt;- LfvrLong%&gt;% select(ClientID, Index, SesNum, Anxiety, DRel0, Het0) #resorting data so that each person is together LfvrLong &lt;- arrange(LfvrLong, ClientID, Index) Lets peek at the characteristics and descriptives as a result of this restructuring from wide to long. str(LfvrLong) &#39;data.frame&#39;: 64125 obs. of 6 variables: $ ClientID: int 1 1 1 1 1 2 2 2 2 2 ... $ Index : int 1 2 3 4 5 1 2 3 4 5 ... $ SesNum : int 0 7 8 13 16 5 6 7 8 10 ... $ Anxiety : num 3.71 3.58 3.87 3.8 1.56 ... $ DRel0 : int 0 0 0 0 0 1 1 1 1 1 ... $ Het0 : int 0 0 0 0 0 0 0 0 0 0 ... round(psych::describe(LfvrLong),3) vars n mean sd median trimmed mad min max ClientID 1 64125 6413.00 3702.29 6413.00 6413.00 4753.22 1.00 12825.00 Index 2 64125 3.00 1.41 3.00 3.00 1.48 1.00 5.00 SesNum 3 64125 8.99 5.47 9.00 8.98 7.41 0.00 19.00 Anxiety 4 64125 2.08 2.56 2.08 2.08 2.56 -8.13 12.87 DRel0 5 64125 0.60 0.49 1.00 0.62 0.00 0.00 1.00 Het0 6 64125 0.28 0.45 0.00 0.22 0.00 0.00 1.00 range skew kurtosis se ClientID 12824 0.00 -1.20 14.62 Index 4 0.00 -1.30 0.01 SesNum 19 0.01 -1.20 0.02 Anxiety 21 0.00 -0.01 0.01 DRel0 1 -0.41 -1.83 0.00 Het0 1 0.99 -1.02 0.00 Evaluating longitudinal growth trajectories in MLM means that we invest in substantial preliminary exporation. 3.5.3 Empirical Growth Plots library(lattice) library(ggplot2) Researchers commonly look at individual dataplots to see if there are clear trends/patterns across the individuals. Do they rise? Is there a curve? Do some rise and some fall? With the lattice package we are asking for the anxiety scores to be plotted by session, for each person (noted with ClientID). Especially in large datasets it is common to create a smaller subset of data for this inspection. The easiest way I found to do this was to grab a set of 30 from the wide file and then quickly turn it to a long file. set.seed(210515) RndmSmpl30 &lt;- LfvrWide[sample(1:nrow(LfvrWide), 30, replace=FALSE),] RndmLong &lt;- (data.table::melt(setDT(RndmSmpl30), id.vars = c(&quot;ClientID&quot;, &quot;DRel0&quot;, &quot;Het0&quot;), measure.vars =list(c(&quot;Anx1&quot;, &quot;Anx2&quot;, &quot;Anx3&quot;, &quot;Anx4&quot;, &quot;Anx5&quot;), c(&quot;Sess1&quot;, &quot;Sess2&quot;, &quot;Sess3&quot;, &quot;Sess4&quot;, &quot;Sess5&quot;)))) RndmLong&lt;- rename(RndmLong&lt;- rename(RndmLong&lt;- rename(RndmLong, Index = variable, Anxiety = &quot;value1&quot;, Session0 = &quot;value2&quot;))) #resorting data so that each person is together RndmLong &lt;- arrange(RndmLong, ClientID, Index) 3.5.4 Plotting a Trajectory as Summary of Each Persons Empirical Growth Record Singer and Willett (2003) suggest that we do this two ways: nonparametric models let the data speak for themselves by smoothing across temporal idiosyncracies without imposing a specific functional form parametric models impose a researcher-selected common functional form (e.g., linear, quadratic, cubic) and then fit a separate regression model to each persons data, yielding a fitted trajectory While our multilevel modeling will use maximum likelihood, these individual plots are fitted with OLS regression models. A better group-by tool: http://r4stats.com/2017/04/18/group-by-modeling-in-r-made-easy/ 3.5.4.1 Nonparametrical Smoothing of the Empirical Growth Trajectory** The smoothed nonparametric trajectory is superimposed on the data. To evaluate, focus on elevation, shape, and title. Where do scores hover at the low, medium, or high end? Does everyone change over time or do some remain the same? Is there an overall pattern of change: linear, curvilinear, smooth, steplike? Is the rate of change similar or different across people. Below I have shown how to plot these with variable, Index variable and then again with the variable, Session. Recall that Index is a structured form of counting across the 5 client sessions. In contrast, Session is time-unstructured because the intervals are unevenly spaced. Our Index variable clocks 1 through 5; Session0 starts at 0.0, providing a better intercept at the first session. Singer and Willett (2003) recommend also staring at the entire set together as a group. Notice anything? xyplot(Anxiety~Session0 | ClientID, data=RndmLong, prepanel = function(x, y) prepanel.loess(x, y, family=&quot;gaussian&quot;), xlab = &quot;Session&quot;, ylab = &quot;Anxiety&quot;, panel = function(x, y) { panel.xyplot(x, y) panel.loess(x,y, family=&quot;gaussian&quot;) }, as.table=T) xyplot(Anxiety~Index | ClientID, data=RndmLong, prepanel = function(x, y) prepanel.loess(x, y, family=&quot;gaussian&quot;), xlab = &quot;Index&quot;, ylab = &quot;Anxiety&quot;, panel = function(x, y) { panel.xyplot(x, y) panel.loess(x,y, family=&quot;gaussian&quot;) }, as.table=T) When we examine these, we simply look for patterns: Are there general trends? Seems like anxiety tends to go downward Are the levels at the start of the study (Wave 1, intercept) at the same place? Or differenct? In this dataset, they are definitely different. Is the change-over-time (slope) linear or curvilinear? The general trend seems to be linear  a decline or staying flat Some show bump ups in anxiety before it declines again One case shows a bump down in anxiety and then it rises again Because clients (a) start at different points and (b) change differently, MLM is a reasonable approach to analyzing the data. Our choice of L1 (time-covarying) and L2 (person-level) variables may help disentangle these differences. As we continue the preliminary exploration, I will use the Session0 variable as our representation of time because it is truer to the data. 3.5.4.2 Parametric Smoothing of the Empirical Growth Trajectory w OLS Regression** Here we fit a separate parametric model to each persons data; OLS is appropriate for this preliminary exploration. Next we can summarize each persons growth trajectory by fitting a separate parametric model to each persons data. Singer and Willett (2003) indicate that this is hardly the most efficient use of longitudinal data[but] it connects empirical researchers with their data in a direct and intimate way (p. 28). We must identify a common functional form (e.g., linear, quadratic, cubic) to fit to all the individuals. Clearly, this is an oversimplification. However, it allows us to easily spot folks for whom the model works and does not. Often the best choice is a straight line and thats what we will do here. There are three steps: Estimate a within-person regression model for each person. This means we regress the outcome [Anxiety] on some representation of time(well use Session0 around 0). In order to conduct separate analyses for each person, we conduct the regression analysis by Client Use summary statistics from all the within-person regression models into a separate data set. For a linear change model, the intercept and slope summarize their growth trajectory; the \\(R^2\\) and residual variance statistics summarize the goodness of fit. Superimpose each persons fitted regression line on a plot of their empirical growth record. Lets start with step #1: This little script produces individual regression models for each person. ANX_OLS &lt;- function (RndmLong){ summary(lm(Anxiety ~ Session0, data = RndmLong)) } by(RndmLong, RndmLong$ClientID, ANX_OLS) RndmLong$ClientID: 175 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 1 2 3 4 5 0.05038 -0.29755 0.08804 0.47882 -0.31968 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 6.75056 0.54322 12.427 0.00112 ** Session0 -0.07347 0.04779 -1.537 0.22181 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.3787 on 3 degrees of freedom Multiple R-squared: 0.4407, Adjusted R-squared: 0.2542 F-statistic: 2.363 on 1 and 3 DF, p-value: 0.2218 ------------------------------------------------------------ RndmLong$ClientID: 343 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 6 7 8 9 10 -0.1008 0.2721 0.6444 -1.1712 0.3555 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -0.49676 0.75416 -0.659 0.557 Session0 -0.07398 0.06735 -1.098 0.352 Residual standard error: 0.816 on 3 degrees of freedom Multiple R-squared: 0.2868, Adjusted R-squared: 0.04912 F-statistic: 1.207 on 1 and 3 DF, p-value: 0.3523 ------------------------------------------------------------ RndmLong$ClientID: 755 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 11 12 13 14 15 0.2702 -0.5245 0.2561 0.9874 -0.9893 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 2.68707 0.92956 2.891 0.063 . Session0 -0.04112 0.07372 -0.558 0.616 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.8883 on 3 degrees of freedom Multiple R-squared: 0.09397, Adjusted R-squared: -0.208 F-statistic: 0.3112 on 1 and 3 DF, p-value: 0.6159 ------------------------------------------------------------ RndmLong$ClientID: 818 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 16 17 18 19 20 -1.1235 -0.4274 1.1499 1.6847 -1.2837 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 0.2063 1.0700 0.193 0.859 Session0 -0.2684 0.2140 -1.254 0.299 Residual standard error: 1.555 on 3 degrees of freedom Multiple R-squared: 0.3439, Adjusted R-squared: 0.1253 F-statistic: 1.573 on 1 and 3 DF, p-value: 0.2986 ------------------------------------------------------------ RndmLong$ClientID: 1435 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 21 22 23 24 25 0.5863 -0.9380 -0.3808 1.2743 -0.5418 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 4.29380 0.80645 5.324 0.0129 * Session0 -0.05622 0.07818 -0.719 0.5240 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 1.047 on 3 degrees of freedom Multiple R-squared: 0.147, Adjusted R-squared: -0.1373 F-statistic: 0.5171 on 1 and 3 DF, p-value: 0.524 ------------------------------------------------------------ RndmLong$ClientID: 1540 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 26 27 28 29 30 1.8238 -1.7020 0.0878 -1.4607 1.2512 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 4.6373 1.6804 2.760 0.0702 . Session0 -0.2185 0.1838 -1.189 0.3199 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 1.819 on 3 degrees of freedom Multiple R-squared: 0.3203, Adjusted R-squared: 0.09379 F-statistic: 1.414 on 1 and 3 DF, p-value: 0.3199 ------------------------------------------------------------ RndmLong$ClientID: 2039 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 31 32 33 34 35 0.5442 -1.1692 -0.6984 -0.1480 1.4715 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 2.09163 1.44704 1.445 0.244 Session0 -0.02286 0.10834 -0.211 0.846 Residual standard error: 1.203 on 3 degrees of freedom Multiple R-squared: 0.01463, Adjusted R-squared: -0.3138 F-statistic: 0.04454 on 1 and 3 DF, p-value: 0.8464 ------------------------------------------------------------ RndmLong$ClientID: 2578 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 36 37 38 39 40 0.1239 0.3173 -0.7597 0.6067 -0.2881 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 5.11349 0.46553 10.984 0.00162 ** Session0 -0.08044 0.04164 -1.932 0.14889 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.6176 on 3 degrees of freedom Multiple R-squared: 0.5544, Adjusted R-squared: 0.4058 F-statistic: 3.732 on 1 and 3 DF, p-value: 0.1489 ------------------------------------------------------------ RndmLong$ClientID: 2983 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 41 42 43 44 45 -0.16092 0.14607 0.03212 0.53772 -0.55499 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 5.127752 0.399302 12.842 0.00102 ** Session0 0.009937 0.046107 0.216 0.84319 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.4638 on 3 degrees of freedom Multiple R-squared: 0.01525, Adjusted R-squared: -0.313 F-statistic: 0.04644 on 1 and 3 DF, p-value: 0.8432 ------------------------------------------------------------ RndmLong$ClientID: 3600 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 46 47 48 49 50 -0.29675 0.03494 -0.97922 1.89035 -0.64932 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 3.39206 1.52325 2.227 0.112 Session0 0.04242 0.13288 0.319 0.771 Residual standard error: 1.297 on 3 degrees of freedom Multiple R-squared: 0.03285, Adjusted R-squared: -0.2895 F-statistic: 0.1019 on 1 and 3 DF, p-value: 0.7705 ------------------------------------------------------------ RndmLong$ClientID: 3748 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 51 52 53 54 55 -0.45080 0.93546 0.09437 -0.52268 -0.05635 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 1.03581 0.57534 1.800 0.170 Session0 -0.21264 0.09074 -2.343 0.101 Residual standard error: 0.6742 on 3 degrees of freedom Multiple R-squared: 0.6467, Adjusted R-squared: 0.5289 F-statistic: 5.491 on 1 and 3 DF, p-value: 0.1009 ------------------------------------------------------------ RndmLong$ClientID: 4017 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 56 57 58 59 60 0.26714 -0.15368 0.00644 -0.61559 0.49568 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 2.23595 0.45737 4.889 0.0164 * Session0 -0.16471 0.03788 -4.349 0.0225 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.4898 on 3 degrees of freedom Multiple R-squared: 0.8631, Adjusted R-squared: 0.8174 F-statistic: 18.91 on 1 and 3 DF, p-value: 0.02246 ------------------------------------------------------------ RndmLong$ClientID: 4488 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 61 62 63 64 65 0.001669 0.521712 -0.510843 -0.045551 0.033013 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 8.67916 0.29167 29.757 0.0000834 *** Session0 -0.05812 0.02776 -2.094 0.127 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.4228 on 3 degrees of freedom Multiple R-squared: 0.5937, Adjusted R-squared: 0.4582 F-statistic: 4.383 on 1 and 3 DF, p-value: 0.1273 ------------------------------------------------------------ RndmLong$ClientID: 4854 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 66 67 68 69 70 0.4984 -0.7896 -0.2480 0.8098 -0.2706 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 6.40250 0.80019 8.001 0.00407 ** Session0 -0.11262 0.06997 -1.610 0.20586 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.7444 on 3 degrees of freedom Multiple R-squared: 0.4634, Adjusted R-squared: 0.2845 F-statistic: 2.591 on 1 and 3 DF, p-value: 0.2059 ------------------------------------------------------------ RndmLong$ClientID: 5320 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 71 72 73 74 75 -0.4121 0.2233 -0.1676 0.5102 -0.1538 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -0.62417 0.33518 -1.862 0.1595 Session0 -0.14753 0.05135 -2.873 0.0639 . --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.421 on 3 degrees of freedom Multiple R-squared: 0.7334, Adjusted R-squared: 0.6445 F-statistic: 8.253 on 1 and 3 DF, p-value: 0.0639 ------------------------------------------------------------ RndmLong$ClientID: 6114 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 76 77 78 79 80 -0.04382 -0.32102 2.24396 -0.52170 -1.35743 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 6.3648 2.5328 2.513 0.0867 . Session0 -0.2398 0.1903 -1.260 0.2966 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 1.555 on 3 degrees of freedom Multiple R-squared: 0.3462, Adjusted R-squared: 0.1283 F-statistic: 1.589 on 1 and 3 DF, p-value: 0.2966 ------------------------------------------------------------ RndmLong$ClientID: 6407 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 81 82 83 84 85 0.6233 -0.9159 -0.1976 1.0334 -0.5433 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 1.78203 1.02976 1.731 0.182 Session0 -0.07499 0.12379 -0.606 0.587 Residual standard error: 0.9362 on 3 degrees of freedom Multiple R-squared: 0.109, Adjusted R-squared: -0.188 F-statistic: 0.367 on 1 and 3 DF, p-value: 0.5874 ------------------------------------------------------------ RndmLong$ClientID: 6559 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 86 87 88 89 90 0.09503 -0.03545 -0.62788 0.27986 0.28844 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 4.49464 0.44869 10.017 0.00212 ** Session0 0.01978 0.03487 0.567 0.61016 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.4344 on 3 degrees of freedom Multiple R-squared: 0.0969, Adjusted R-squared: -0.2041 F-statistic: 0.3219 on 1 and 3 DF, p-value: 0.6102 ------------------------------------------------------------ RndmLong$ClientID: 7142 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 91 92 93 94 95 -0.2880 0.5761 0.2737 0.1724 -0.7343 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -0.06634 0.56654 -0.117 0.914 Session0 -0.05314 0.04468 -1.189 0.320 Residual standard error: 0.5941 on 3 degrees of freedom Multiple R-squared: 0.3205, Adjusted R-squared: 0.09396 F-statistic: 1.415 on 1 and 3 DF, p-value: 0.3198 ------------------------------------------------------------ RndmLong$ClientID: 7767 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 96 97 98 99 100 1.0376 0.6314 -2.2630 0.4364 0.1577 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 3.61480 1.16058 3.115 0.0527 . Session0 -0.03206 0.10499 -0.305 0.7801 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 1.507 on 3 degrees of freedom Multiple R-squared: 0.03014, Adjusted R-squared: -0.2931 F-statistic: 0.09323 on 1 and 3 DF, p-value: 0.7801 ------------------------------------------------------------ RndmLong$ClientID: 9066 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 101 102 103 104 105 -0.8117 0.1204 1.3825 0.2906 -0.9818 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 6.46252 0.82127 7.869 0.00428 ** Session0 0.01625 0.07645 0.213 0.84533 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 1.1 on 3 degrees of freedom Multiple R-squared: 0.01483, Adjusted R-squared: -0.3136 F-statistic: 0.04516 on 1 and 3 DF, p-value: 0.8453 ------------------------------------------------------------ RndmLong$ClientID: 9097 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 106 107 108 109 110 0.1710 0.1344 -1.4475 0.3723 0.7698 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 6.7369 1.2504 5.388 0.0125 * Session0 -0.1322 0.0901 -1.468 0.2385 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.9787 on 3 degrees of freedom Multiple R-squared: 0.4179, Adjusted R-squared: 0.2239 F-statistic: 2.154 on 1 and 3 DF, p-value: 0.2385 ------------------------------------------------------------ RndmLong$ClientID: 9814 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 111 112 113 114 115 1.5780 -0.1342 -2.2272 0.2243 0.5592 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 3.8789 1.9063 2.035 0.135 Session0 -0.1239 0.1495 -0.829 0.468 Residual standard error: 1.616 on 3 degrees of freedom Multiple R-squared: 0.1864, Adjusted R-squared: -0.08483 F-statistic: 0.6872 on 1 and 3 DF, p-value: 0.4679 ------------------------------------------------------------ RndmLong$ClientID: 9998 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 116 117 118 119 120 0.3646 -0.8017 1.1655 -0.5472 -0.1813 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 3.40739 1.32511 2.571 0.0824 . Session0 0.01101 0.11264 0.098 0.9283 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.9067 on 3 degrees of freedom Multiple R-squared: 0.003173, Adjusted R-squared: -0.3291 F-statistic: 0.00955 on 1 and 3 DF, p-value: 0.9283 ------------------------------------------------------------ RndmLong$ClientID: 10398 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 121 122 123 124 125 -1.1381 0.9662 1.3901 -1.5399 0.3217 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 3.53102 1.21714 2.901 0.0624 . Session0 0.07828 0.15927 0.491 0.6568 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 1.487 on 3 degrees of freedom Multiple R-squared: 0.07452, Adjusted R-squared: -0.234 F-statistic: 0.2416 on 1 and 3 DF, p-value: 0.6568 ------------------------------------------------------------ RndmLong$ClientID: 11153 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 126 127 128 129 130 0.3641 0.1975 0.4548 -2.2425 1.2261 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 1.9946 1.1061 1.803 0.169 Session0 -0.1025 0.1248 -0.821 0.472 Residual standard error: 1.518 on 3 degrees of freedom Multiple R-squared: 0.1836, Adjusted R-squared: -0.08852 F-statistic: 0.6747 on 1 and 3 DF, p-value: 0.4716 ------------------------------------------------------------ RndmLong$ClientID: 11639 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 131 132 133 134 135 -0.5633 0.3197 1.2701 0.3633 -1.3898 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -3.35216 0.94537 -3.546 0.0382 * Session0 0.01803 0.07878 0.229 0.8337 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 1.169 on 3 degrees of freedom Multiple R-squared: 0.01716, Adjusted R-squared: -0.3104 F-statistic: 0.05239 on 1 and 3 DF, p-value: 0.8337 ------------------------------------------------------------ RndmLong$ClientID: 11713 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 136 137 138 139 140 0.27002 1.08393 -1.06589 -0.38107 0.09301 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 2.46789 0.63760 3.871 0.0305 * Session0 -0.02542 0.07165 -0.355 0.7462 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.9197 on 3 degrees of freedom Multiple R-squared: 0.04028, Adjusted R-squared: -0.2796 F-statistic: 0.1259 on 1 and 3 DF, p-value: 0.7462 ------------------------------------------------------------ RndmLong$ClientID: 12081 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 141 142 143 144 145 -1.4042 0.8308 0.6680 1.3966 -1.4913 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 0.385038 1.021952 0.377 0.731 Session0 -0.001875 0.093447 -0.020 0.985 Residual standard error: 1.558 on 3 degrees of freedom Multiple R-squared: 0.0001342, Adjusted R-squared: -0.3332 F-statistic: 0.0004026 on 1 and 3 DF, p-value: 0.9853 ------------------------------------------------------------ RndmLong$ClientID: 12409 Call: lm(formula = Anxiety ~ Session0, data = RndmLong) Residuals: 146 147 148 149 150 -0.715243 2.248873 -0.389445 0.001022 -1.145207 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 3.95251 1.53686 2.572 0.0824 . Session0 0.02669 0.14956 0.178 0.8697 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 1.531 on 3 degrees of freedom Multiple R-squared: 0.01051, Adjusted R-squared: -0.3193 F-statistic: 0.03185 on 1 and 3 DF, p-value: 0.8697 Looking at our data, we might observe: \\(R^2\\) values range from 0 to 74% Level of anxiety starts at different places For many, anxiety decreases as a function of session but not for all, and for a few it goes negative Next we superimpose each clients fitted OLS trajectory on their empirical growth plot. xyplot(Anxiety ~ Session0 | ClientID, data=RndmLong, panel = function(x, y){ panel.xyplot(x, y) panel.lmline(x, y) }, as.table=T) What do we observe? A linear change trajectory is ideal for a few members reasonable for many others The \\(R^2\\) coincides well with those for whom the line is the best fit Singer and Willett (2003) can read your minds, Dont OLS regression methods assume independence and homoscedastic residuals? Why, yes! They do. Singer and Willett indicate OLS estimates are very useful for exploratory purposes in that they provide an unbiased estimate of the intercept and slope of the individual change. 3.5.4.3 Snapshot of the Entire Set of Smooth Trajectories** We can plop all our trajectories in a set of smoothed individual trajectories. This first plot is simply the raw data. This first plot is just a smoothed (there is a line for each client) plot of the raw/natural metric of the data. #plot of raw data for every case #Session0 provided splotchy data; Index0 gives some indication of change interaction.plot(RndmLong$Index, RndmLong$ClientID, RndmLong$Anxiety) The next two sets of code plot our fitted trajectories into a single plot. First, we fit the model. #fitting the linear model by ID fit &lt;- by(RndmLong, RndmLong$ClientID, function(bydata) fitted.values(lm(Anxiety ~ Session0, data=bydata))) fit &lt;- unlist(fit) Then make the plot. #plotting the linear fit by ID interaction.plot(RndmLong$Index, RndmLong$ClientID, fit, xlab=&quot;Sessions&quot;, ylab=&quot;Anxiety&quot;) What do we observe? Clients present with varying levels of anxiety. On average, change in anxiety declined (at least a little) from the first wave to the fifth. 3.5.5 Examining intercepts, slopes, and their relationship Sample means of the estimated intercepts and slopes (level-1 OLS estimated intercepts and slopes) are unbiased estimates of initial status and rate of change for each person. Their sample means are, therefore, unbiased estimates of the key features of the average observed change trajectory. Sample variances (SDs) of the estimated intercepts and slopes quantify the amount of observed interindividual heterogeneity in change. #obtaining the intercept from the linear model by ClientID ints &lt;- by(RndmLong, RndmLong$ClientID, function(data) coefficients(lm(Anxiety ~ Session0, data=data))[[1]]) ints1 &lt;- unlist(ints) names(ints1) &lt;- NULL mean(ints1) [1] 3.239564 sqrt(var(ints1)) [1] 2.688367 Our calculations tell us that at Session 1, anxiety is 3.23 (SD = 2.69). The next two values calculate the slope and its variation. #obtaining the slopes from linear model by id slopes &lt;- by(RndmLong, RndmLong$ClientID, function(data) coefficients(lm(Anxiety ~ Session0, data=data))[[2]]) slopes1 &lt;- unlist(slopes) names(slopes1) &lt;- NULL mean(slopes1) [1] -0.06980594 sqrt(var(slopes1)) [1] 0.08853341 Here we learn that the average slope is -0.07 (SD = 0.08). On average, anxiety decreases by .07 points per session. Relative to their means, the magnitudes of the SDs around the slope and intercept are pretty big, so there is a great deal of variation. Sample correlation between the estimated intercepts and slopes summarizes the association between the fitted initial status and fitted rate of change. It answers the question, Are observed initial status and rate of change related? cor( ints1, slopes1) [1] 0.008575535 Not really. r = 0.01. 3.5.6 Exploring the relationship between Change and Time-Invariant Predictors Looking at our level-2 predictors can help uncover systematic interindividual differences in change. In this vignette religious affiliation and sexual identity are our L2 predictors. Lets start with religious affiliation Is there a difference in intercept (initial tolerance) or slope (rate of change) as a function of religious affiliation? We start by selecting DR, fitting a regression model, and plotting it. #fitting the linear model by ID, DR only DR &lt;- filter(RndmLong, DRel0==&quot;0&quot;) fitmlist &lt;- by(DR, DR$ClientID, function(bydata) fitted.values(lm(Anxiety ~ Session0, data=bydata))) fitDR &lt;- unlist(fitmlist) #appending the average for the whole group of DR lm.DR &lt;- fitted( lm(Anxiety ~ Session0, data=DR) ) names(lm.DR) &lt;- NULL fit.DR2 &lt;- c(fitDR, lm.DR[1:5]) Sess1.DR &lt;- c(DR$Index, seq(1,5))#Note that I used Session0 to create the lm, but plotted by Index0 id.DR &lt;- c(DR$ClientID, rep(30, 5)) #plotting the linear fit by id, males #id.m=111 denotes the average value for males interaction.plot(Sess1.DR, id.DR, fit.DR2, ylim=c(-2, 8), xlab=&quot;Sessions&quot;, ylab=&quot;Anxiety&quot;, lwd=1) title(main=&quot;Dominant Religious&quot;) Trajectories for those from dominantreligions stay flat; a few decline. Now for non-dominant religious (including those that are affiliated and unaffiliated). #fitting the linear model by ID, DR only NDR &lt;- filter(RndmLong, DRel0==&quot;1&quot;) fitmlist &lt;- by(NDR, NDR$ClientID, function(bydata) fitted.values(lm(Anxiety ~ Session0, data=bydata))) fitNDR &lt;- unlist(fitmlist) #appending the average for the whole group of males lm.NDR &lt;- fitted( lm(Anxiety ~ Session0, data=NDR) ) names(lm.NDR) &lt;- NULL fit.NDR2 &lt;- c(fitNDR, lm.NDR[1:5]) Sess1.NDR &lt;- c(NDR$Index, seq(1,5))#Note that I used Session0 to create the lm, but plotted by Index0 id.NDR &lt;- c(NDR$ClientID, rep(30, 5)) #plotting the linear fit by id, males #id.m=111 denotes the average value for males interaction.plot(Sess1.NDR, id.NDR, fit.NDR2, ylim=c(-2, 8), xlab=&quot;Sessions&quot;, ylab=&quot;Anxiety&quot;, lwd=1) title(main=&quot;Non-Dominant Religious&quot;) It appears that there is more decline in anxiety for those who claim non-dominant religions. What about the effects of sexual identity? #fitting the linear model by ID, HET = 0 only HET &lt;- filter(RndmLong, Het0==&quot;0&quot;) fitmlist &lt;- by(HET, HET$ClientID, function(bydata) fitted.values(lm(Anxiety ~ Session0, data=bydata))) fitHET &lt;- unlist(fitmlist) #appending the average for the whole group of males lm.HET &lt;- fitted( lm(Anxiety ~ Session0, data=HET) ) names(lm.HET) &lt;- NULL fit.HET &lt;- c(fitHET, lm.HET[1:5]) Sess1.HET &lt;- c(HET$Index, seq(1,5))#Note that I used Session0 to create the lm, but plotted by Index0 id.HET &lt;- c(HET$ClientID, rep(30, 5)) #plotting the linear fit by id, males #id.m=111 denotes the average value for males interaction.plot(Sess1.HET, id.HET, fit.HET, ylim=c(-2, 8), xlab=&quot;Sessions&quot;, ylab=&quot;Anxiety&quot;, lwd=1) title(main=&quot;Heterosexual&quot;) Among clients who identify as heterosexual, there is a mixed profile. Clients start with varying degrees of anxiety and we see it stay the same, increase, and decrease. #fitting the linear model by ID, DR only LGBQQ &lt;- filter(RndmLong, Het0==&quot;1&quot;) fitmlist &lt;- by(LGBQQ, LGBQQ$ClientID, function(bydata) fitted.values(lm(Anxiety ~ Session0, data=bydata))) fitLGBQQ &lt;- unlist(fitmlist) #appending the average for the whole group of males lm.LGBQQ &lt;- fitted( lm(Anxiety ~ Session0, data=LGBQQ) ) names(lm.LGBQQ) &lt;- NULL fit.LGBQQ &lt;- c(fitLGBQQ, lm.LGBQQ[1:5]) Sess1.LGBQQ &lt;- c(LGBQQ$Index, seq(1,5)) #Note that I used Session0 to create the lm, but plotted by Index0 id.LGBQQ &lt;- c(LGBQQ$ClientID, rep(30, 5)) #plotting the linear fit by id, males #id.m=111 denotes the average value for males interaction.plot(Sess1.LGBQQ, id.LGBQQ, fit.LGBQQ, ylim=c(-2, 8), xlab=&quot;Sessions&quot;, ylab=&quot;Anxiety&quot;, lwd=1) title(main=&quot;LGBQQ&quot;) What do we observe? Clients who identify as LGBQQ start at different levels of anxiety; most decline somewhere in the middle and then maintain in a consistent/level manner. 3.5.7 The Relationship between OLS-Estimated Trajectories and Substantive Predictors Below are two plots (and corresponding correlation coefficients) for religious affiliation and sexual identity regarding intercept (or initial status). They help us answer the question, is initial status different as a function of gender (then, exposure level). NOTE that these are calculated from the the wide-format. First, is anxiety at Session0 (our initial, or intercept) different for those from dominant and nondominant religions? For these analyses of intercepts, the fitted model that we are using for the plot and correlation keeps the assessment at the Session0 intercept. #Using the slopes and intercepts from the linear model fitted by id #generated for use in table 2.3 plot(RndmSmpl30$DRel0, ints1, xlab=&quot;Religion&quot;, ylab=&quot;Fitted initial status&quot;) cor(RndmSmpl30$DRel0, ints1) [1] 0.1587707 For religion, looking at the dots on 0 and 1 and the correlation, it looks like the anxiety intercept is lower for those from the dominant religion. Next, is Anxiety at Session 1 different as a function of level of sexual identity? plot(RndmSmpl30$Het0, ints1, xlab=&quot;Sexual Identity&quot;, ylab=&quot;Fitted initial status&quot;) The plot of this random sample of data emphasizes that those who identify as LGBQQ are, proportionately, much smaller. Their range of anxiety is more restricted, but higher. cor(RndmSmpl30$Het0, ints1) [1] 0.1309987 Looking at the correlation of intercepts and plot together, wee see that anxiety is higher for those who identify as LGBQQ. Next, we look at 2 more plots and correlations for religion and sexual identity regarding slope/rate of change. plot(RndmSmpl30$DRel0, slopes1, xlab=&quot;Religion&quot;, ylab=&quot;Fitted rate of change&quot;) cor(RndmSmpl30$DRel0, slopes1) [1] 0.09496023 The plot is the rate of change or slope. Its maybe a little more difficult to plot. We see that dominant religions have a slower rate of change than those who claim a nondominant religion (or no religion). What about change in anxiety as a function of sexual identity? plot(RndmSmpl30$Het0, slopes1, xlab = &quot;Sexual Identity&quot;, ylab = &quot;Fitted rate of change&quot;) cor(RndmSmpl30$Het0, slopes1) [1] 0.1113146 Those with who identify as LGBQQ have sharper rates of change. 3.5.8 APA Style Writeup Method/Analytic Strategy COMING SOON: Will be completed in next lesson Results Preliminary Analyses Preliminary analysis involved the creation and visual inspection of empirical growth plots with parametrical and nonparmetrical smoothing. We also calculated and plotted intercepts, slopes, and their relationship. Results suggested that intercepts and slopes differed across the clients. Thus, utilizing multi-level modeling as the framework for analyzing the data is justified. Primary Analyses COMING SOON: Will be completed as we work the problem in the next lesson(s). 3.6 Observations about the Social and Cultural Responsivity of the Project Accessing and analyzing big data is a strength; it is through these collaborative endeavors that we get greater access to sample sizes representing populations that are marginalized in numbers for which it is possible to analyze. Heterosexual and dominant religions are still the basis for comparison. Is this a strength or limitation? It depends on the goal of the project. This dataset, though, may have sufficient representation among marginalized groups for within-group analysis without comparison. In the simulation, nondominant religions disappeared. They had been only 5% of the original sample. The authors describe how they ran the models with and without this subgroup and chose to leave them in the dataset. 3.7 Residual and Related Questions ..that you might have; or at least I had, but if had answered them earlier it would have disrupt the flow. 3.8 Practice Problems The assignment is designed to span several lessons. Therefore, at this stage, please select a longitudinal dataset that will allow you to engage in the preliminary exploring, model building (including both exploration of an unconditional growth model and adding at least one L2 variables), and writing up a complete multilevel model for change (as specified below). Minimally, you should have a time-changing dependent variable and corresponding time-covarying (L1) predictor with a minimum of three waves each; our time-covarying predictor is Session. Variables will be clocked with a sensible time metric. You should also have a time invariant L2 predictor. FROM THIS LESSON Restructure the dataset from wide to long. Provide three examples of data exploration An unfitted model A model fitted with a linear growth trajectory The fitted (or unfitted) data identified by the L2 predictor FROM SUBSEQUENT LESSONS Using a staged approach to model development, report on at least four models, these must include An unconditional means model An unconditional growth model An intermediary model (please test both a time variable and an L2 variable) A final model Write up the Results as demonstrated in the lecture Table (use the tab_model outfile) and Figure are required 3.8.1 Problem #1: Rework the research vignette as demonstrated, but change the random seed If this topic feels a bit overwhelming, simply change the random seed in the data simulation, then rework the problem. This should provide minor changes to the data (maybe in the second or third decimal point), but the results will likely be very similar. Assignment Component 1. Restructure the dataset from wide to long (or from long to wide) 5 _____ 2. Provide three examples of data exploration: an unfitted model, a model fitted with a linear growth trajectory, and the fitted (or unfitted) data identified by the L2 predictor 5 _____ 3. Provide a write-up of what you found in this process 5 _____ 6. Explanation to grader 5 _____ Totals 20 _____ 3.8.2 Problem #2: Rework the research vignette using the second set of simulated data where depression is the outcome variable Use the simulated data, but select one of the other models that was evaluated in the Lewis et al. (Lewis et al., 2017) study. Compare your results to those reported in the mansucript. Assignment Component 1. Restructure the dataset from wide to long (or from long to wide) 5 _____ 2. Provide three examples of data exploration: an unfitted model, a model fitted with a linear growth trajectory, and the fitted (or unfitted) data identified by the L2 predictor 5 _____ 3. Provide a write-up of what you found in this process 5 _____ 6. Explanation to grader 5 _____ Totals 3.8.3 Problem #3: Use other data that is available to you Using data for which you have permission and access (e.g., IRB approved data you have collected or from your lab; data you simulate from a published article; data from an open science repository; data from other chapters in this OER), complete the exploratory analyses. Assignment Component 1. Restructure the dataset from wide to long (or from long to wide) 5 _____ 2. Provide three examples of data exploration: an unfitted model, a model fitted with a linear growth trajectory, and the fitted (or unfitted) data identified by the L2 predictor 5 _____ 3. Provide a write-up of what you found in this process 5 _____ 6. Explanation to grader 5 _____ Totals 3.9 Bonus Track: Image of a filmstrip 3.9.1 Simulated Data when Depression is the Outcome One suggestion for practice is to work the second MLM example in the Lefevor et al. (Lefevor et al., 2017) example. The code below will simulate the data. set.seed(200513) n_client = 12825 n_session = 5 b0 = 1.84 #intercept for depression b1 = -.28 #b weight for L1 session b2 = .15 #b weight for L2 sexual identity b3 = -.06 #b weight for L2 Rel1 (D-R vs ND-R &amp; ND-U) b4 = 0.04 #b weight for the L2 Rel2 (ND-R vs ND-U) #the values used below are the +/- 3SD they produce continuous variables which later need to be transformed to categorical ones; admittedly this introduces a great deal of error/noise into the simulation #the article didn&#39;t include a correlation matrix or M/SDs so this was a clunky process ( Session = runif(n_client*n_session, -3.67, 3.12)) #calc L1 Session, values are the +/3 3SD ( SexualIdentity = rep(runif(n_session, -6.64, 6.94), each = n_session)) #calc L2 Sexual Identity, values are the +/3 3SD ( Religion1 = rep(runif(n_session, -3.46, 3.34), each = n_session)) #calc L2 Religion1, values are the +/3 3SD ( Religion2 = rep (runif(n_session, -3.44, 3.36), each = n_session)) #calc L2 Religion2, values are the +/3 3SD mu = 1.49 #intercept of empty model sds = 2.264 #this is the SD of the DV sd = 1 #this is the observation-level random effect variance that we set at 1 #( church = rep(LETTERS[1:n_church], each = n_mbrs) ) #this worked in the prior ( client = rep(LETTERS[1:n_client], each = n_session) ) #( session = numbers[1:(n_client*n_session)] ) ( clienteff = rnorm(n_client, 0, sds) ) ( clienteff = rep(clienteff, each = n_session) ) ( sessioneff = rnorm(n_client*n_session, 0, sd) ) ( Depression = b0 + b1*Session + b2*SexualIdentity + b3*Religion1 + b4*Religion2 + clienteff + sessioneff) ( dat = data.frame(client, clienteff, sessioneff, Session, SexualIdentity, Religion1, Religion2, Depression) ) library(dplyr) dat &lt;- dat %&gt;% mutate(ID = row_number()) #moving the ID number to the first column; requires dat &lt;- dat%&gt;%select(ID, everything()) Lefevor2017D &lt;- dat%&gt;% select(ID, client, Session, SexualIdentity, Religion1, Religion2, Depression) Lefevor2017D$ClientID &lt;- rep(c(1:12825), each = 5) #rounded Sexual Identity into dichotomous variable #85% were heterosexual, #Rel2 has contrast codes for dominant religion (DR, 0), nondominant religious (NDR, 1) and nondominant unspecified (NDU, -1) #Strategy is to figure out the raw score associated with the percentile rank of -1 and 0, to set the breakpoints for the coding #NDU coded as -1 #19.2+13.5+9.6 #NDU has bottom 42.3 percent #DR coded as 0, so quantile cut will be 42.3 + 52.7 = 95th #33.4 + 19.3 #52.7% of sample (according to article) was DR #must look up percentile ranks for 5% and 57.5% #NDR #2.3+1+1+.7 #NDR has 5% of sample #42.3+52.7 quantile(Lefevor2017D$Religion2, probs = c(.423, .95)) #effects coding the second Religion variable so that NDU = -1, DR = 0, NDR = 1 Lefevor2017D$Rel2L2 &lt;- ifelse(Lefevor2017D$Religion2 &lt;= -0.3304528 , -1, ifelse(Lefevor2017D$Religion2 &gt;= -0.3304529 &amp; Lefevor2017D$Religion2 &lt;= 2.4446784, 0,1)) #creating the religion variable where DR is 0 and NDR and NDU are both 1 Lefevor2017D$DRel0 &lt;- plyr::mapvalues(Lefevor2017D$Rel2L2, from = c(-1, 0, 1), to = c(1, 0, 1)) The following `from` values were not present in `x`: 1 #checking #DRel0_table &lt;- table(Lefevor2017D$DRel0) #prop.table(DRel0_table) #heterosexual is -1 #LGBQQ is 1 #quantile(Lefevor2017D$SexualIdentity, probs = c(.85)) Lefevor2017D$SexID &lt;- ifelse(Lefevor2017D$SexualIdentity &lt;= 5.747946, -1,1) Lefevor2017D$Het0 &lt;- plyr::mapvalues(Lefevor2017D$SexID, from = c(-1,1), to = c(0,1)) #Het0_table &lt;- table(Lefevor2017D$Het0) #prop.table(Het0_table)#to make sure that 85% are coded 0 for Het #creating a variable representing the session number for each client, in the article up to 20 sessions were allowed. #install.packages(&quot;scales&quot;) library(scales) #Right from the beginning I centered this so that 0 would represent intake Lefevor2017D$Session0 &lt;- as.integer(scales::rescale(Lefevor2017D$Session, to = c(0, 19))) #creating session waves (1 thru 5) by rank ordering within each person&#39;s variable the continuous variable Session that was created in the original simulation library(dplyr) Lefevor2017D &lt;- Lefevor2017D%&gt;% dplyr::group_by(ClientID) %&gt;% mutate(Index = rank(Session)) #selecting the simulated variables Lefevor2017D_sim &lt;- Lefevor2017D%&gt;% select(ClientID, Index, Session0, Depression, DRel0, Het0) #In the transition from long-to-wide, it seems like you can only do one L1 variable at a time #When there are multiple L1 and L2 vars, put all L2 vars on left of tilde #The wave/index function should come next; this should be finite (like integers of 1,2,3,4) with a maximum #Put the name of the SINGLE L1 variable in the concatonated list library(data.table) DLfvrWp1&lt;-reshape2::dcast(Lefevor2017D_sim, ClientID + DRel0 + Het0 ~ Index, value.var = c(&quot;Index&quot;)) #rename the anxiety variable DLfvrWp1&lt;- rename(DLfvrWp1, Index1 = &quot;1&quot;, Index2 = &quot;2&quot;, Index3 = &quot;3&quot;, Index4 = &quot;4&quot;, Index5 = &quot;5&quot;) DLfvrWp2&lt;-reshape2::dcast(Lefevor2017D_sim, ClientID ~ Index, value.var = c(&quot;Depression&quot;)) #rename the anxiety variable DLfvrWp2&lt;- rename(DLfvrWp2, Dep1 = &quot;1&quot;, Dep2 = &quot;2&quot;, Dep3 = &quot;3&quot;, Dep4 = &quot;4&quot;, Dep5 = &quot;5&quot;) #For remaining L1 variable, do them one at a time -- key them from the person-level ID and the wave/index. DLfvrWp3&lt;-reshape2::dcast(Lefevor2017D_sim, ClientID ~ Index, value.var = c(&quot;Session0&quot;)) DLfvrWp3&lt;- rename(DLfvrWp3, Sess1 = &quot;1&quot;, Sess2 = &quot;2&quot;, Sess3 = &quot;3&quot;, Sess4 = &quot;4&quot;, Sess5 = &quot;5&quot;) #Next, join the dataframes by the person-level ID #Only two can be joined at a time DLfvrWide &lt;- dplyr::full_join(DLfvrWp1, DLfvrWp2, by = c(&quot;ClientID&quot;)) DLfvrWide &lt;- dplyr::full_join(DLfvrWide, DLfvrWp3, by = c(&quot;ClientID&quot;)) The parallel dataset with depression as the outcome is called: DLfvrWide Here is script to save it as an outfile and then import it back into R. write.table(DLfvrWide, file=&quot;DLfvrWide.csv&quot;, sep=&quot;,&quot;, col.names=TRUE, row.names=FALSE) DLfvrWide &lt;- read.csv (&quot;DLfvrWide.csv&quot;, head = TRUE, sep = &quot;,&quot;) sessionInfo() R version 4.0.4 (2021-02-15) Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 10 x64 (build 18362) Matrix products: default locale: [1] LC_COLLATE=English_United States.1252 [2] LC_CTYPE=English_United States.1252 [3] LC_MONETARY=English_United States.1252 [4] LC_NUMERIC=C [5] LC_TIME=English_United States.1252 attached base packages: [1] stats graphics grDevices utils datasets methods base other attached packages: [1] lattice_0.20-41 data.table_1.14.0 [3] scales_1.1.1 sjPlot_2.8.7 [5] PerformanceAnalytics_2.0.4 xts_0.12.1 [7] zoo_1.8-9 robumeta_2.0 [9] lmerTest_3.1-3 forcats_0.5.1 [11] stringr_1.4.0 dplyr_1.0.5 [13] purrr_0.3.4 readr_1.4.0 [15] tidyr_1.1.3 tibble_3.1.1 [17] ggplot2_3.3.3 tidyverse_1.3.1 [19] sjstats_0.18.1 nlme_3.1-151 [21] lme4_1.1-26 Matrix_1.2-18 [23] psych_2.1.3 loaded via a namespace (and not attached): [1] TH.data_1.0-10 minqa_1.2.4 colorspace_2.0-0 [4] ellipsis_0.3.1 sjlabelled_1.1.7 estimability_1.3 [7] snakecase_0.11.0 parameters_0.13.0 fs_1.5.0 [10] rstudioapi_0.13 farver_2.1.0 glmmTMB_1.0.2.1 [13] fansi_0.4.2 mvtnorm_1.1-1 lubridate_1.7.10 [16] xml2_1.3.2 codetools_0.2-18 splines_4.0.4 [19] mnormt_2.0.2 knitr_1.33 sjmisc_2.8.6 [22] jsonlite_1.7.2 nloptr_1.2.2.2 ggeffects_1.1.0 [25] broom_0.7.6 dbplyr_2.1.1 effectsize_0.4.4-1 [28] compiler_4.0.4 httr_1.4.2 emmeans_1.6.0 [31] backports_1.2.1 assertthat_0.2.1 cli_2.5.0 [34] htmltools_0.5.1.1 tools_4.0.4 coda_0.19-4 [37] gtable_0.3.0 glue_1.4.2 reshape2_1.4.4 [40] Rcpp_1.0.6 cellranger_1.1.0 jquerylib_0.1.4 [43] vctrs_0.3.7 svglite_2.0.0 apaTables_2.0.8 [46] insight_0.13.2 xfun_0.22 rvest_1.0.0 [49] lifecycle_1.0.0 statmod_1.4.35 MASS_7.3-53.1 [52] hms_1.0.0 parallel_4.0.4 sandwich_3.0-0 [55] TMB_1.7.20 RColorBrewer_1.1-2 yaml_2.2.1 [58] sass_0.3.1 stringi_1.5.3 highr_0.9 [61] bayestestR_0.9.0 boot_1.3-27 rlang_0.4.11 [64] pkgconfig_2.0.3 systemfonts_1.0.1 evaluate_0.14 [67] labeling_0.4.2 tidyselect_1.1.1 plyr_1.8.6 [70] magrittr_2.0.1 bookdown_0.22 R6_2.5.0 [73] generics_0.1.0 multcomp_1.4-17 DBI_1.1.1 [76] mgcv_1.8-35 pillar_1.6.0 haven_2.4.1 [79] withr_2.4.2 survival_3.2-11 performance_0.7.1 [82] modelr_0.1.8 crayon_1.4.1 utf8_1.2.1 [85] tmvnsim_1.0-2 rmarkdown_2.7 grid_4.0.4 [88] readxl_1.3.1 reprex_2.0.0 digest_0.6.27 [91] xtable_1.8-4 numDeriv_2016.8-1.1 munsell_0.5.0 [94] bslib_0.2.4 quadprog_1.5-8 References "],["refs.html", "References", " References "]]
