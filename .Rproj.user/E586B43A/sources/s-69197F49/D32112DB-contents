---
title: "S&WCh3_Intro to Multilevel"
author: "Lynette H. Bikos, PhD, ABPP"
date: "05/03/2020"
output: word_document
always_allow_html: yes
csl: apa-single-spaced.csl
bibliography: MLM.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA) #keeps out the hashtags in the knits
```

```{r Clear environment}
# Clear your Global Environment
rm(list=ls())
```

![Opening imageof a field with all kinds of wildflowers (growth)](in_the_weeds.jpg){#id .class width=1000 height=400px}

**Screencast Playlist link:**  https://spu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?pid=40aa0cb6-7700-4999-86d7-abb00105c9e8


## navigating this lectuRette

About 1 hour and 30 minutes.  Add another 2ish hours to work through and digest the materials.

The focus of this lecture is specifying a multi-level model that includes both an L1 predictor of time and an L2 predictor of program/condition.  In-so-doing, we examine the conceptual and technical aspects of multilevel modeling and assemble the model (and explore the data) in a systematic and sequential manner.

### quiz pRep

* Be able to make speculations about what is happening with a dataset from the preliminary OLS exploration.
* This is the tough one -- get familiar with the L1 and L2 equations and all those symbols. This means, symbols and definitions for the lingo:  L1/L2, slopes/intercepts, fixed/random effects.
* Be able to interpret fixed and random effects from *lme4*/*lmer()* output (and/or the APA style table and Viewer output from the (*sjPlot*/*tabmodel()* table)

### planning for youR homewoRk

In this continuation/multi-week homework assignment your homework, please select a dataset (your own, from your RVT, or from the S&W datasets) that includes at a time-varying DV and at least 1 L2 variable.  Restructure the dataset, run the preliminary exploration, and then run/specify a model with time as a L1 predictor and the L2 variable as an L2 predictor. The RMD homework template will be in one of the lecture folders.


### Readings & ResouRces

* Singer, J. D., & Willett, J.B. (2003). *Applied longitudinal data anlaysis:  Modeling change and event occurrence*.  New York, NY:  Oxford University Press.  Full text available online at SPU library:  https://alliance-primo.hosted.exlibrisgroup.com/primo-explore/fulldisplay?docid=CP51259327920001451&context=L&vid=SPU&lang=en_US&search_scope=spu_alma_summit&adaptor=Local%20Search%20Engine&tab=default_tab&query=any,contains,applied%20longitudinal%20data%20analysis&mode=Basic
  - **Chapter 3:  Introducing the Multilevel Model for Change**, 
* Burchinal, M. R., Campbell, F. A., Bryant, D. M., Wasik, B. H., & Ramey, C. T. (1997). Early intervention and mediating processes in cognitive performance of children of low-income African American families. *Child Development, 68*(5), 935?954. https://doi-org.ezproxy.spu.edu/10.2307/1132043
  - Scan for background of motivating example.

The goal of S&W's chapter three [@singer_applied_2003]is to provide a single worked example from beginning to end that illustrate the steps of multi-level modeling (aka hierarchical linear modeling, linear mixed effects modeling, etc.)

* specifying a (simple but complete[ish]) model
  + linear change model for individual growth
  + time-structured data (identical collection schedule)
  + evaluation of ONE dichotomous time-invariant (L2) predictor
* fitting it to the data
* interpreting the results

A warning:  this is oversimplified.  As we move into S&W Ch4, you'll see how everything gets more complex.  The goal of Ch3 is to give you a cognitive roadmap.

```{r package installation, include=FALSE}
#will install the package if not already installed
if(!require(tidyverse)){install.packages("tidyverse")}
if(!require(psych)){install.packages("psych")}
if(!require(foreign)){install.packages("foreign")}
if(!require(lattice)){install.packages("lattice")}
if(!require(ggplot2)){install.packages("ggplot2")}
if(!require(nlme)){install.packages("nlme")}
if(!require(lmerTest)){install.packages("lmerTest")}
if(!require(lme4)){install.packages("lme4")}
if(!require(sjPlot)){install.packages("sjPlot")}
if(!require(broom)){install.packages("broom")}
if(!require(TMB)){install.packages("TMB")}
if(!require(stargazer)){install.packages("stargazer")}
```


# On Specifying Multilevel Models

**Statistical models** are mathematical representations of *population* behavior -- describing salient features of *hypothesized processes* of interest among individuals in a target population.  

* Implicit in this approach is that the *population model* explains/causes whatever we are going to find in the sample data.
  - Restated: *statistical models* are statements about the *population process* that generated the relations among the data.
* Statistical models include a variety of parameters:  intercepts, slopes, variances, and so forth.
* We fit our statistical model to sample data and estimate the population parameters' unknown values.  This results in "goodness-of-fit" indices (e.g., $R^2$ or residual variance) -- estimating the correspondence between the fitted model and sample data.
  + Well-fitting models allow us to draw conclusions (e.g,. make inferences; hence inferential statistics) about the direction and magnitude of the hypothesized effects to the population
  
Multilevel models for longitudinal data asks two general types of research questions.  This distinction is core to the rationale for this type of model specification.

* *level-1 [L1]*:  within person change, or how individuals change over time
* *level-2 [L2]*:  between-person differences, how these changes vary across individuals

## Motivating Example

Burchinal et al. [-@burchinal_early_1997] is the source of the motivating example. The overarching study evaluated the effects of early intervention on child development.  Our file includes data from 103 African-American infants born into low-income families.  At 6 months of age, 58 were randomly assigned to participate in an intensive early intervention program designed to enhance cognitive functioning; the remaining served as a no-treatment control group.  Each child was assessed 12 times between 6 and 96 months.

Chapter 3 walks us through a simplifed evaluation.  Looking at the data:

* ID is the child-identifier, occurs in 3 rows for each file
* AGE is a time-structured/wave-representation of the child's age in years:  1.0, 1.5, 2.0
  + a TIME variable re-centered age around 0.0, such that 0 = 1 year, 0.5 = 1.5 years, 1.0 = 2 years
* COG is the child's cognitive performance at each age/time/wave
* PROGRAM is a dichotomous variable 0 = control, 1 = treatment
* Note that the data is already in a long (person_period) format; this helps us focus on the concepts of MLM.  You would likely have to restructure your data before starting the analyses (demo'd in the prior lecture).

Let's look at the data:

**But first**

Let's load the data and start looking around.

Resources for working the Chapter 3 problem are found at the UCLA/IDRE site:  https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-3/

As well as an MLM demo site on GitHub:  https://github.com/nmldesjardins/MLM/tree/master/Lab%205_growth%20models

Dataset was only available in .dta -- for use in Stata.  The *foreign* package loads it easily.  On my computer this file looked like a .pdf/Adobe Acrobat file, but R read it in just fine.

*If you have difficulties, I did rewrite it as a .csv and you can use the usual procedure to import; I just thought we shoud learn/try something new.*
```{r quick peek at data}
library(foreign)
library(tidyverse)
library(psych)
ei_long <- foreign::read.dta("earlyint_pp.dta")
str(ei_long)
round(describe(ei_long),3)
```
The dataset already comes to us in the *long* (person-period) format, where each person has as many rows of data as they have observations within the dataset.

The mean for cog collapse across waves and person, representing the average cognition level for all children at all times.  Using the *describeBy()* function from the *psych* package we can see the cognition level, separately, across the 3 times.

```{r disaggregated descriptives}
describeBy(ei_long$cog,ei_long$time)
```

Last week our preliminary exploring was with the wide file.  It might make sense to restructure it, but we can also use a subsetting function to create little objects that represent the data by the age of child (12, 18, 24 months) and then get cognitive correlations between the ages.
```{r age correlations from long file}
c1<-subset(ei_long,time==0.0) #creates a subset of 1 year olds
c2<-subset(ei_long,time==0.5) #creates a subset of 1.5 years olds
c3<-subset(ei_long,time==1.0) # creates a subset of 2 year olds

cor(c1$cog,c2$cog,use="pair") #correlation between 1 and 1.5 year olds
cor(c2$cog,c3$cog,use="pair") #correlation between 1.5 and 2 year olds
cor(c1$cog,c3$cog,use="pair") #correlation between 1 and 3 year olds
```

It looks like there is a positive correlation for cognition between each age and the subsequent age. That is, the higher the correlation at age X the higher it remains at age Y.

## The Level-1 Submodel for Individual Change

**Individual growth model**, the *level-1* or L1 model, represents the change we expect each member of the population to experience during the time period under study.

In our example this is the individual change in cognitve performance that we hypothesize will occur during each child's second year of life.

We begin with a visual inspection of the empirical growth plots. 
This is a more visually attractive plot, it would have worked better if the IDs for the participants were sequential, instead they range between 68 and 985.  I offer the code for your use, later in life.

```{r indiv growth plots}
ggplot(ei_long, aes(x = time, y = cog, group=id, color = program)) +
  geom_line(alpha=.3) + labs(title="Cognitive Levels of Children in Second Year of Life") +
  theme(legend.position = "none")

```


```{r random selection of indiv plots}
set.seed(1966)
rando <- round(runif(60,68,985),0) # randomly selects 20 from values 68 to 985
indplot <- subset(ei_long, id %in% rando)
ggplot(indplot, aes(x=time, y=cog)) + geom_line(color="tomato") + 
  facet_wrap(~id) + 
  labs(x="Time", y="Cognition Score", title="Cognition Trajectories\n for a Random Sample of Students") + 
  theme(axis.text.x=element_blank(), axis.ticks.x=element_blank())
```

For another view of the individual plots.

```{r all indiv growth plots}
library(lattice)
library(ggplot2)

xyplot(cog~time | id, data=ei_long,
  panel = function(x, y){
    panel.xyplot(x, y)
    panel.lmline(x, y)
  }, ylim=c(50, 150), as.table=T)
```

Wow.  So it looks like declining cognitive performance over time.

* For some, smooth and systematic
* For others, scattered and irregular

S&W: "...although we might wish that we would be determining whether program participants experience a faster rate of *growth* it appears that we will actually be determining whether they experience a slower rate of *decline*" (p. 49).

We look at the data with an eye toward selecting and specifying the individual growth model.  We ask ourselves:

* What type of population individual growth model might have generated these sample data?
* Should it be linear or curvilinear with age?
* Does it appear smooth or jagged?
* Should it be continuous or disjointed?
* *Note*:  these last 2 ideas are things we can actually plot!

Recall in the prior lecture we further thought about the functional form with this 3-step process:

1.  Estimate a within-person regression model for each person.  
2.  Use summary statistics from all the within-person regression models into a separate data set. For a linear change model, the intercept and slope summarize their growth trajectory; the $R^2$ and residual variance statistics summarize the goodness of fit.
3.  Superimpose each person's fitted regression line on a plot of their empirical growth record.  

We approached it two ways...a quick glance to get some of the data, and then a more detailed regression.

```{r quick indiv regressions}
#using broom and dplyr, we create this object that knows to group the data by ID
library(broom)
by_ID <- group_by(ei_long, id)
#then we get a tidy regression for each model
do(by_ID,
   glance(lm(cog~time, data = .)))
```

We could also get "all the regressions."  Here's the code to do it, but I'm hashtagging it out, because it's a lot.  

```{r detailed OLS regressions}
#ei_ols <- function (ei_long){
  #summary(lm(cog ~ time, data = ei_long))
#}
#by(ei_long, ei_long$id, ei_ols)

```

Credit to "nmldesjardins" at the GitHub site for geting all this data (plotted individual trajectories representing slopes and intercepts AND the between-subjects variable) via a spaghetti plot!


```{r spaghetti plot}
spaghetti<-ggplot(data=ei_long, aes(y = cog, x = time)) # sets up initial plot
spaghetti + stat_smooth(method=lm,  			  # estimate a linear model with x and y from above
	aes(group=id, 								  # estimate separate models for each id	
	colour=factor(program)), 					  # plot people who were and were not in the program in different colors	
	se = F) +									  # don't print confidence intervals	
	ylab("Cognitive Function") + xlab("Age")      # set axis labels

```

Indeed, specifying a linear model seems consistent with this data (and, erring toward parsimony, is most common).


### A few minutes on equations in their relation to model building and the specification of the L1 submodel

*Credit to Melissa McTernan, PhD, who granted permission for me to use her lecture notes.  Notes are available on OSF from the WPA 2019 Statistics workshops/Linear Mixed Effects Models:  https://osf.io/epsmc/ *

Recall the model for a **simple linear regression**: 

$$Y_{i} = \beta_{0} + \beta_{1}x_{i} + \epsilon_{i}$$ 

The outcome $Y_{i}$ has a subscript "$i$", indicating that it is predicted for each individual. 

On the right side of the equation, we see that $Y_{i}$ is predicted by the individual's value on predictor variable $x$. The variable $x$ is a *linear* predictor of $Y$. You might be able to recognize that this equation resembles the equation of a line ($Y = mx+ b$). 

In regression, the linear equation includes an intercept ($\beta_{0}$) and a slope ($\beta_{1}$) parameter, as well as a residual error term ($\epsilon_{i}$) which represents individual uniqueness that is not explained by the model. The uniquenesses, ($\epsilon_{i}$), are typically assumed to follow a normal distirbution with mean $0$ and variance $\sigma^2$, or in statistical terms, $\epsilon_{i}$ ~$N(0, \sigma^2)$.

Importantly, the intercept and slope are both *fixed* in a basic linear regression model. You can recognize that the intercept and slope are fixed because they do not include a subscript $i$ or $j$ (as we will see later). The lack of a subscript indicates that these parameters each only take on a single value that is meant to represent the entire population intercept or slope, respectively. 

Now let's take a look at the most basic **multilevel model** and compare it to the simple linear regression model above:

$$ Y_{ij} = \beta_{0j} + \beta_{1j}x_{ij} + \epsilon_{ij} $$

Look familiar? The only difference in between this equation and the linear regression equation is that this one contains more subscripts. (But this simple update will give us so much more information, as you'll see!) For the purpose of defining the model, let's assume that the subscript $j$ represents a group of individuals. In the multilevel model, $i$ can take on any value in $(1, ..., N)$, where $N$ is the number of individuals in the study. The subscript $j$ may take on values in $(1, ..., J)$, where $J$ is the number of groups in the study. In this model, recognize that each group is allowed its own unique intercept and slope. You could read the entire model as: *"The outcome value for person $i$ in group $j$ is equal to the intercept for group $j$, plus the slope for group $j$ multiplied by the x-value for person $i$ in group $j$, plus some error that cannot be explained by the model for person $i$ in group $j$."* The errors in $\epsilon_{ij}$ are typically assumed to be independently and identically distributed $(iid)$ ~$N(0, \sigma^2)$. 

Now let's mix it up, just a bit more...S&W will tell you that our L1 submodel is
$$Y_{ij} = [\pi_{0i}+\pi _{1i}(AGE_{ij}-1)]+[\varepsilon_{ij}] $$ 
Here's what it means:

**The structural portion of the model**

* $Y_{ij}$ In the *population* from which this sample was drawn, $Y_{ij}$ is the value of COG for each child $i$ at time $j$.
  + In our dataset, $i$ ranges from 1 to 103; $j$ ranges from 1 to 3.  
* One tradition of MLM/HLM is that the symbol pi is used for longitudinal modeling because it represents "people"; gammas are used for cross-sectional MLM/HLM designs because they represent "groups."  More recently, I've noticed the generic use of the beta.  
  + $\pi_{0i}$ is the intercept or time 0 for person $i$
  + $\pi _{1i}(AGE_{ij}-1)$ is the slope of peron $i$ at age $j$ (centered around 0)
* the elements described so far (within the first set of brackets) are the *structural* part; the *structural* part is considered to be the "true score"
* this portion of the model lets us know that it is linear; we would add quadratic (or cubic, etc.) terms if it were curvilinear
* while our data is time-structured (evenly spaced waves, each) and balanced (3 each, no missing data) this model can handle deviations to both

**The stochastic portion of the model**

* $\varepsilon_{ij}$, in the second set of brackets is the *stochastic* part and represents the effect of random error associated with the measurement of individual $i$ at on occasion $j$ (i.e., measurement error).
  + SW propose that we think of $\varepsilon_{ij}$ as *level-1 residuals* where each residual represents that part of the child $i$ values of COG at time $j$ not predicted by his or her age, Why?
  + We'll learn later that specifying additional time-varying predictors (in addition to or in the place of AGE) can reduce unexplained variance

**Returning to our OLS-style exploration**

The spaghetti plot (ignoring the color-coding of intervention v. control) represents the results of using OLS methods to fit the L1 submodel in equation 3.1 for all 103 children (regressing COG on (AGE-1), separately by ID).  We have already noted that for most children, cognitive performance declines over time...some decline is more rapid than others.  Few children are showing improvements.

Next are three, separate, stem and leaf plots for the fitted intercepts, fitted slopes, and estimated residuals.

Recall that in a stem and leaf plot, the "stem" is a base, used to group the scores in a cluster and the "leaf" is the last digit of an individual score.
```{r stemleaf plot for intercepts}
#stem plot for fitted initial value
int <- by(ei_long, ei_long$id,
function(data) coefficients(lm(cog ~ time, data=data))[[1]] )
int <- unlist(int)
names(int) <- NULL
stem(int)
```
The above plot is of the intercepts (e.g., the child's *true* initial status). This means at age 1.0 (the first wave), the lowest score on the cognition test (with a mean of 100) was 57, the highest was 140.

According to the text, these appear to be centered near 110; meaning that at age 1 the average child in the sample has a score that is higher than the national average (100). Comparing this data to the descriptive above, the COG mean at age 1 was 111.  


```{r stem plot for fitted rate of change}
#stem plot for fitted rate of change
rate <- by(ei_long, ei_long$id,
function(data) coefficients(lm(cog ~ time, data=data))[[2]] )
rate <- unlist(rate)
names(rate) <- NULL
stem(rate)
```
Considering the stem/leaf nature of the plot, slopes range from a growth of 20 points per year to a decrease of -40 points per year.  Clearly, most are decreasing.  The text suggests that the fitted slopes are centered near -10.    

```{r stem plot for sigma sq}
#stem plot for sigma.sq
sig <- by(ei_long, ei_long$id,
function(data) (summary(lm(cog ~ time, data=data))$sigma)^2 )
sig <- unlist(sig)
names(sig) <- NULL
stem(sig)
```

Don't be fooled by that good sounding "red warning."  We expect the distribution of these statistics to be skewed because they are squared quantities and, therefore, bounded by zero.  When residual variance is near 0 (as it is for many in this model), the fitted trajectories are reasonable summaries of the observed data.  However,the skewed distribution of these residual variances suggests great variation in the quality of the OLS summaries across children.    When residual variance is larger, as it often is here, the fitted trajectories are poorer summaries -- the observed values of COG are further away from the fitted lines.

## The Level-2 Submodel for Systematic Interindividual Differences in Change

The L2 model codifies the relationship between interindividual differences in the change trajectories and time-invariant characteristics of the individual.  Stated other ways:

* With L1 models, individuals can only differ in intercepts and slopes
* Adding L2, we can ask specific questions about the relationship between the individual growth parameters and predictors

As we did in the preceding chapter, a helpful step is to create separate plots of OLS trajectories according to the child's program participation.

**Plot#1 is when program = 0 (no program participation)**
```{r L2 plot control}
#fitting the linear model by id, program=0
early.p0 <- ei_long[ei_long$program==0, ]

fit.p0 <- by(early.p0, early.p0$id,
function(data) fitted(lm(cog ~ time, data=data)))
fit.p0 <- unlist(fit.p0)
names(fit.p0) <- NULL

#appending the average for the whole group
lm.p0 <- fitted( lm(cog ~ time, data=early.p0) )
names(lm.p0) <- NULL
fit.p0 <- c(fit.p0, lm.p0[1:3])
age.p0 <- c(early.p0$time, c(0, .5, 1))
id.p0 <- c(early.p0$id, rep(1111, 3))

#plotting the linear fit by id
interaction.plot(age.p0, id.p0, fit.p0,
xlab="AGE", ylab="COG", ylim=c(50, 150))
```
Above we see pretty consistent decline.


**Plot #2 is when program = 1; early intervention**
```{r L2 plot intervention}
#fitting the linear model by id, program=1
early.p1 <- ei_long[ei_long$program==1, ]

fit.p1 <- by(early.p1, early.p1$id,
function(data) fitted.values(lm(cog ~ time, data=data)))
fit.p1 <- unlist(fit.p1)
names(fit.p1) <- NULL

#appending the average for the whole group
lm.p1 <- fitted( lm(cog ~ time, data=early.p1) )
names(lm.p1) <- NULL
fit.p1 <- c(fit.p1, lm.p1[1:3])
age.p1 <- c(early.p1$time, c(0, .5, 1))
id.p1 <- c(early.p1$id, rep(1111, 3))

#plotting the linear fit by id
interaction.plot(age.p1, id.p1, fit.p1,
xlab="AGE", ylab="COG", ylim=c(50, 150))
```
Above, there is still decline, but some obvious incline, as well.

Comparing the two, S&W observe:

* Program participants tend to have higher scores at age 1 and decline less over time (intercepts are higher; slopes are shallower)
* There is a great deal of of interindividual heterogeneity *within* groups; not all participants have higher intercepts than nonparticipants; not all nonparticipants have steeper slopes.
* Consequently, our L2 model needs to simultaneously account for both patterns (between group diferences in intercepts and slopes) and interindividual heterogeneity in patterns within groups.

We write the L2 submodel in separate parts, one for each L1 growth parameter. With a linear change individual growth model, we need two L2 submodels, 

* one for the intercept, $\pi_{0i}$   
* and one for the slope $\pi_{1i}$ 

Further, 

* each part must specify a relationship between an individual growth parameter and the predictor (i.e., program), and
* each model must allow individuals who share common predictor values to vary in their individual change trajectories (i.e., each L2 submodel must allow for stochastic variation in the individual growth parameters).

The resulting L2 submodels:

$$\pi_{0i} = \gamma _{00}+\gamma _{01}PROGRAM + \xi_{0i}$$ 
$$\pi_{1i} = \gamma _{10}+\gamma _{11}PROGRAM + \xi_{1i} $$

Taken together, these two components treat the intercept $\pi_{0i}$ and slope $\pi_{1i}$  of an individual's growth trajectory as L2 outcomes that may be associated with the predictor, PROGRAM.  Each component has its own residual ($\xi_{0i}$ and $\xi_{1i}$).  Between these two components, there are 7 population parameters:  the 4 regression parameters (the $\gamma$s) and 3 residual variance/covariance parameters.  Let's break it down:

**Structural components of the L2 submodel**

* *Fixed effects* capture systematic interindividual differences in change trajectory according to values of the L2 predictor(s).  These include:  $\gamma _{00}$,  $\gamma _{01}$, $\gamma _{10}$, and $\gamma _{11}$
  + Two of these are L2 intercepts:$\gamma _{00}$,$\gamma _{10}$
  + Two of these are L2 slopes:  $\gamma _{01}$,$\gamma _{11}$  We note that slopes are generally of greater interest because they represent the effect of the predictors (in our case, PROGRAM) on the individual growth parameters
  
We interpret the L2 parameters much like we do in regular regression; we just need to remember that they describe *variation in outcomes* that are, themselves, L1 growth parameters.

A common way to interpret L2 fixed effects is to identify a *prototypical individual* and then sub in/out values.  For example, we might first set PROGRAM = 0 in both parts of the equation and swap in/out values.  Then repeat for PROGRAM = 1.

**Stochastic components of the L2 submodel**

The residuals ($\xi_{0i}$, $\xi_{1i}$) represent those portions of the L2 outcomes (the individual growth parameters) that remain unexplained by the L2 predictor(s).  As is common for interpreting residuals, we are more interested in their population variances and covariance (labeled $\sigma _{0}^{2}$, $\sigma _{1}^{2})$, and $\sigma _{01}$).
*Note: Statistical traditions have different naming conventions for these variance components.  Raudenbush and Bryk (2002) and consequently the viewer that we will later use prefer $\tau _{00}$, $\tau _{11}$, and $\tau _{01}$, respectively).*

For example, if child *i* is a member of the non-treatment group, the L2 residuals represent deviations between their true initial status and annual rate of change from the population average intercept $\gamma _{00}$ and slope $\gamma _{10}$ for nonparticipants.

Because L2 residuals represent deviations between individual growth parameters and their respective population averages, their variances ($\sigma _{0}^{2}$ and $\sigma _{1}^{2})$) summarize the population variation in true individual intercept and slope around these averages.  Because they describe the portions of the intercepts and slopes *left over* after accounting for the effect(s) of the model predictor(s), they are *conditional residual variances*; conditional on the true initial status and true annual rate of change, respectively.  These variance parameters become CRITICAL and allow us to address the question, "How much heterogeneity in true change remains after accounting for the effects of program participation?"

Because we realize there may be a possible association between initial status and individual rates of change, we permit the L2 residuals to be correlated. The resulting population covariance captures the association between true individual intercepts and slopes. This is also *conditional*, thus $\sigma _{01}^{2}$ summarizes the magnitude and direction of the association between true initial status and true annual rate of change, controlling for program participation.  The question we are functionally asking, "Controlling for program participation, are true initial status and true rate of change related?"

## Fitting the Multilevel Model for Change 

### But first, understanding maximum likelihood (ML) methods in the context of multilevel modeling

S&W cover this with more depth...I'm hitting the high points.

Conceptually, ML estimates are *guesses* for the values of the unknown population parameters that maximize the probability of observing a particular sample of data.

In the context of our motivating example, they are the estimates of the fixed effects and variance components that make it *most likely* that we would have observed the specific patterns of change found in the 103 children.

The first step is the construction of a *likelihood function* -- an expression that describes the probability of observing the sample data as a function of the model's unknown parameters.  Subsequently, the algorithm numerically examines the relative performance of potentially competing estimates until those that maximize the likelihood function are found.

In our example, the likelihood function is a function of the probability that we would observe the particular temporal pattern of COG values found in the dataset.  The goal is estimates of the fixed effects and variance components whose values maximize the probability of this specific pattern.

Likelihood functions are expressed as the product of probabilities (or probability densities). Only in ML as we use it, our packages use *log-likelihood functions*.

* In cross-sectional data, each sample member contributes one term related to the probability that *that* person has his or her observed data
* In longitudinal data, each person contributes several terms (as many terms as s/he has records in the dataset) to the likelihood function.

*Iterations* are critical in ML. All software programs that provide ML estimates for MLM begin by generating reasonable "starting" values -- usually by applying something like the OLS methods that we are rejecting.  In successive iterations the program gradually refines these as it searches for the log-likelihood function's maximum.  When this search converges (and the difference between successive estimates is trivially small), the resulting estimates are output.  When algorithms fail to converge, you repeat the search, allowing more iterations (or you respecify the model).

Once ML estimates have converged, the computer estimates their associated sampling variation in the form of *asymptotic standard errors (ase)*. *Asymptotic* is a central definer of ML.  This means that in practice -- in any actual analysis of a real sample -- the properties hold only *approximately*.  The larger the sample, the more likely they are to hold.  

Because of all this... ML estimates have three desirable properties

1.  They are *asymptotically unbiased (consistent)* -- they converge on the unknown true values of population parameters
2.  They are *asymptotically normally distributed* -- their sampling distributions are approximately normal with known variance, and
3.  They are *asymptotically efficient* -- their standard errors are smaller than those derived by other methods
4.  A bonus:  any function of ML estimates is also an ML estimate.  This means that predicted growth trajectories (constructed from ML estimates of initial status and rates of change) are ML estimates of the true trajectories.

So...to restate all that stuff above in plainer English, here's why we like ML:

* the estimates are consistent and efficient,
* they make use of well-established normal theory,
* they can generate decent estimates of more complex quantities.


### Specifying and running the model

There are two notable packages for running LME models in R. The *nlme* package ("nlme" = "nonlinear mixed effects") was the first fully developed and popularized package for mixed-effects analysis. More recently, the *lme4* package was developed. The two packages are very similar. Some differences are that *nlme* still has better functionality for nonlinear models, but *lme4*  is more advanced when it comes to estimation methods, and therefore is often more efficient.

It seems like modelers switch back and forth between the two to get the estimates they want.  As we learn more about multi-level modeling, we'll learn that model building generally occurs systematically and sequentially.  BUT, this chapter's example is all-at-once, so, I'll demo whole model in both packages.

First, *nlme*.  It is apparently glitchy about convergences.  Therefore, I created the "ctrl" object (telling it what optimizer to use) and then inserted that into the statement.  This can't be ideal, but it's what was recommended.

```{r nlme output}
library(nlme)
ctrl <- lmeControl(opt='optim');
nlme_mod<- lme(cog~time*program, data = ei_long, random = ~time | id, control=ctrl, method = "ML")
summary(nlme_mod)
intervals(nlme_mod)
```

Now with *lme4*.

It appears that *lmer()* function (commonly used) does not report p values.  For my table, I used the ones from *lme()*.
```{r lme4 output}
library(lme4)
library(lmerTest) #used to get an approximation of p values for fixed effects
lme4_mod <- lmer(cog ~ time*program + (1 + time|id), data=ei_long, REML=FALSE)
summary(lme4_mod)

```

###Interpretation assisted by formulae, table, and figure

*tab_model()* creates tables that will be displayed either in the viewer-pane or in a variety of other ways (e.g, .doc, .html).

```{r tab_model for viewer}
#install.packages("sjPlot")
#install.packages('TMB', type = 'source')
library(sjPlot)
tab_model(lme4_mod, p.style = "asterisk", show.ci = FALSE, use.viewer=TRUE)
```

```{r tab_model for doc}
#Although you cannot use them both in the same you can swap use.viewer=TRUE with tab_mod_table.doc to get a word document table saved to your file
tab_model(lme4_mod, p.style = "asterisk", show.ci = FALSE, file ="lme4_mod.doc")

```

```{r plot_model}
plot_model(lme4_mod, type="int")
```


**Fixed effects, first**
We begin our interpretation by focusing on the fixed effects parameters of the L2 submodel.  They interpret much like any old regression equation, with one exception:  the L2 "outcomes" that these fixed effects describe are the L1 individual growth parameters, themselves.

Recall the formula for the L1 model:  
$$Y_{ij} = [\pi_{0i}+\pi _{1i}(AGE_{ij}-1)]+[\varepsilon_{ij}] $$

The fixed effects of the L2 submodel provide the estimates for $\pi_{0i}$ (L1 intercept) and $\pi _{1i}(AGE_{ij}-1)$ (L1 slope).

Substituting in the estimates from our analysis, we get:

$$\pi_{0i} = 107.84+6.85PROGRAM_{i}$$
$$\pi_{1i} = -21.13+5.27PROGRAM$$

$\pi_{0i}$ describes the effect of *PROGRAM* on initial status.
$\pi _{1i})$  describes the effect of annual rates of change.

Some observations:

* Cognition score at age 1 is 107.84 for the average child in the control group.
* The average cognition score at age 1 for participants in the early intevention program is 6.85 points higher (114.69).
  + If the national norm is 100, both groups are higher.
  + Does this raise concern about the *randomization* proces?  Probably not, the intervention began when children were 6 months old; that is, *before* the first wave of data collection.
* Cognition scores for the average child in the control group decrease by 21.13 points each year (recall, decreases are in units of 1.0).
* Cognition scores for the average child in the treatment program decrease by 15.86 points per year (-21.13 + 5.27)
  + The cognitive functioning of both groups declines over time
  + As we suspected in our early exploration, the intervention slows the rate of decline
* The *p* values for each of these indicates they are statistically significantlly different than 0
  + The calculation of *p* values is increasingly controversial.  They were provided in the *lme4* output, but not in the *nlme* output -- sources indicate that they were not provided because the package author(s) think we should quit focusing on them.
  
We can portray these in formulae and plotted trajectories:

**When PROGRAM = 0**
$$\pi_{0i} = 107.84+6.85(0)=107.84$$
$$\pi_{1i} = -21.13+5.27(0)=-21.13$$

**When PROGRAM = 1**
$$\pi_{0i} = 107.84+6.85(1)=114.69$$
$$\pi_{1i} = -21.13+5.27(1)=-15.86$$

**Next, variance components**

Albeit incredibly cool, interpreting variance components are more tricky since their numeric values have little absolute meaning and there are no corresponding graphs/figures.

Variance components assess the amount of outcome variability left-over/remaining at either L1 or L2 after fitting the multilevel model.

$\sigma _{\varepsilon}^{2}$ is an L1 variance component that summarizes the population variability in an average person's outcome values around *his or own* change trajectory.  We find this value (74.76, *SD* = 8.646) in the *lme4* output under Random Effects/Residuals (or simply as $\sigma^{2}$ in the *sjPlot* output in our Viewer). The null hypothesis for this test would be that the variance componet would equal 0.  We use this parameter to determine if there is variance remaining to explain.

Strategies for making relative comparisons to residual variances in other models are discussed in S&W's Chapter 3. S&W acknowledge that the use of "single parameter tests" (e.g., *p*, *z*, *t* values; and even *CI*s) to test the significance of variance tests are highly controversial. To discourage their use, they are not provided in *lme4* and *nlme*.  However, in the program that S&W used to generate the output a z value (7.17, which is greater than +/- 1.96) indicated that the $\sigma _{\varepsilon}^{2}$ value of 74.76 is statistically significant from zero.  This means that we might add suitable time-varying predictors (e.g., # books in child's home, amount of parent/child interaction) to the L1 submodel.

$\sigma _{0}^{2}$ is an L2 variance component (found in *lme4* output under Random Effects/id(intercept); or as $\tau _{00}$ in the *sjPlot* output in our Viewer) that summarizes between-person variance in the intial status (the intercept) after accounting for the effects of program participation.   Its value is 123.97 (*SD* = 11.13).  Again our R packages do not provide associated significance tests.  We see that the corresponding *z* value in S&W's Table 3.3 is 4.55.  Since this is greater than 1.96 we can reject the null hypothesis that this variance is 0.00.  This suggests that we might include additional predictors (both time-invariant and time-varying) to the multi-level model.

$\sigma _{1}^{2}$ is an L2 variance component (found in *lme4* output under Random Effects/id/time); or in the *sjPlot* in the Viewer as $\tau _{11}$).  This variance component summarizes between-person variance in the annual rate of change (slope) after accounting for the effects of program participation.  Its value is 10.09 (*SD* = 3.18).  S&W provide a slightly value different value (12.29); their associated *z* value is 0.40.  Because it is < |1.96| we interpret that PROGRAM explains all the potenitially predictable variation between children in their annual rates of change.  Thus, there is no justification for adding additional predictors to this component of the model.

S&W add a fourth variance component that is not provided by *lme4*.  This parameter, $\sigma _{01}$ ($\tau _{01}$ in parallel terminology) provides the covariance between intercepts (initial status) and rate of change (slopes) after the effects of the other variables (in our case, PROGRAM) have been removed. I'm still on the hunt for this! In the S&W text this value was -36.41 with a *z* of -1.60.  This non-significant value means that, accounting for the effects of PROGRAM, there is no association between initial status and annual rate of change.


Here we see those findings:

* Children in the intervention started with higher cognition scores (but they had already been in the program for 6 months [yes, this is a problem in the research design])
* Cognition scores declined for both groups.
* Being in the intervention appears to dampen the negative slope in cognition decline.

**The APA Style Table**  The output is a tab_model output is a good start

## Writing it Up

**Method** (these are the paragraphs I wrote; I almost always use some minor variation of them)

**Sample Size, Power, and Precision**
Sample size is a critical yet complex issue in multilevel models.  Power in the multilevel model is a function of the number of clusters (in our case, the number of participants), the number of units per cluster (e.g., the number of repeated measures), the intraclass correlation, and the effect size (McCoach, 2010).  McCoach's summary of the literature suggested that while "a bare minimum of 10 clusters" (p. 129) could be sufficient, at least 30 clusters are required to produce unbiased estimates of variance components, and at least 100 clusters are necessary to have reasonable estimates of the standard errors of the level-two variance components. Additionally, the number of repeated measures and degree of missingness in the longitudinal design can be problematic.  Our dataset had 309 repeated observations (level 1 units) from 103 participants (clusters/level 2 units). Especially because it is a balanced design (no missing data at any wave), we believe we satisfied the minimum recommendations for sample size.

**Results**

Longitudinal studies produce data with a hierarchical structure in which the repeated measures (level 1 [L1]) are clustered within individuals (level 2 [L2]).  Multilevel modeling (MLM) with the R packages *nlme* (v. 3.1-145) and *lme4* (v. 1.1-21) was appropriate to use in this analysis because it allows for the dependent nature of the repeated measures data Using HLM, Thus, we simultaneously estimated within- and between-person effects. Intercepts (i.e., the initial level of a variable) were the cognition scores at age 1.0 and slopes represented changes in the dependent variable during the first year of life. Data was modeled with a linear mixed effects approach with maximum likelihood.


**Preliminary Analyses**

*Data Preparation and Missing Data* (a mangy draft)  Our data set included all three waves (ages 1, 1.5, and 2) for 103 children.  We used a structured form of time (evenly spaced at the exact ages) and our dataset was balanced (three waves were available for all study participants).  *Of course they likely had to do something to get to this amazing circumstance, so they should say what.*

*Bivariate correlations, means, SDs*

*Distributional characteristics, assumptions, etc.* (another mangy draft) Our preliminary anlaysis included extensive exploratory analyses recommented by Singer and Willett (2003).  Not reported here (but available in *whatever OSF frame or as a supplement to the journal*) this included (a) plotting empirical growth plots for a random sample (20%) of the the sample, (b) creating within-person regression models for each person in the dataset and superimposing each person's fitted regression line on the plot of his/her empircal growth record, and (c) examing the fit of these regressions by examinng the $R^2$ statistic and an indivdiual estimated residual variance. Further analysis explored differences in the trajectories as a function of PROGRAM participation.  Specifically, we plotted raw and fitted trajectories separately for program and nonprogram participants. Our observations indicated that it would be appropriate to proceed by specifying a linear growth trajectory.

**Primary Analyses**
*Note:  There is stuff missing...we'll get to it in S&W Chapter 3*
We simultaneously evaluated the fit of a linear growth trajectory across the three waves of data (representing ages 1, 1.5, and 2 years old) with PROGRAM entered at L2.  Results are presented in Table 1, illustrated in Figure 1, and represented in the formulae, below:

$$\pi_{0i} = 107.84+6.85PROGRAM_{i}$$
$$\pi_{1i} = -21.13+5.27PROGRAM$$

Results indicate that at age 1 the cognition score was 107.84 for the average child in the control group and 114.69 for children in the intervention group. For the average child in the control group, cognition scores decreased by 21.13 points during the year. The decline was statistically, significantly less (15.86 points) for children in the early intervention condition. An examination of the variance components suggest that there is remaining variance to explain in the L1 submodel (i.e., variability around one's own change trajectory) and in the between-person variance associated with the the intial status.  Thus, there is support for additing additional L1 and L2 variables to the model.  

### Post Script
Although the data we observed did not show gains, *really* longitudinal research has evidenced more promising projects.
The data we analyzed was associated with the Abecedarian Project.  More results here:  https://abc.fpg.unc.edu/abecedarian-project


NPR's Shankar Vedantam has a 3.5 minute report on a similar study. ttps://www.npr.org/2019/05/23/726035330/since-the-1960s-researchers-track-perry-preschool-project-participants



#Bonus Track: 

![Image of a filmstrip](film-strip-1.jpg){#id .class width=620 height=211}

###Alternative format for data
I really wanted a .csv file so I exported our file. 
```{r write outfile}
write.csv(ei_long, file = "earlyint_pp.csv")
```

This worked mostly fine except it added a column, named "X" with an ID for each row. If this proved problematic (it shouldn't) or annoying (yes) you could I tried to use *dplyr*'s select function to delete that variable/column.  Here's the code you would need (hashtagged out so it doesn't interfere with other work)

```{r filter out extra variable}
#select (ei_dat, -c(X))
```


Trying to make a table with the package *stargazer*.  More instructions, here:  https://cran.r-project.org/web/packages/stargazer/vignettes/stargazer.pdf
```{r stargazer output}
#install.packages("stargazer")
library(stargazer)
stargazer(nlme_mod, title = "Effects of Early Intervention Programming on Cognition", type = "html", single.row = TRUE, no.space = TRUE, out = "ei_table.doc")
```







```{r sessionInfo}
sessionInfo()
```

# References


